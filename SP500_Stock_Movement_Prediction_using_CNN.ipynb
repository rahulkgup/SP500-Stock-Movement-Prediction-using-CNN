{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S&P 500 Stock Movement Prediction using Deep Learning\n",
    "\n",
    "Stock market, now 25 Trillion, is one pivotal player in US economy. Predicting stock returns, using either company’s financials or quantitative factors, has been considerd one of the most challenging and rewarding work, due to the noise and volatile features of the time series [1]. In the past decades, both academia and industries have done extensive studies using machine-learning models to predict financial time series, such as support vector machine [2], and neural network [3]. In this project, we would like to attempt to predict stocks returns with cutting-edge technology in deep learning.\n",
    "\n",
    "<br>\n",
    "\n",
    "GitHub repository link: https://github.com/rahulkgup/SP500-Stock-Movement-Prediction-using-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import functools as ft\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It’s all about data\n",
    "\n",
    "### Market Data (Downloaded)\n",
    "\n",
    "To avoid the cost (primarily in terms of money) of downloading market indices at the run-time, we have already downloaded the historical data of around 30 years for S&P500 indices.  \n",
    "\n",
    "To download all the market data we need for our training and testing for this model, we have used <a id='https://intrinio.com/'>Intrinio.com</a>, a Financial Data Platform. \n",
    "\n",
    "Downloaded historical ticker data holds following columns:\n",
    "DATE, OPEN, HIGH, LOW, CLOSE, VOLUME, EX_DIVIDEND, SPLIT_RATIO, ADJ_OPEN, ADJ_HIGH, ADJ_LOW, ADJ_CLOSE, ADJ_VOLUME, ADJ_FACTOR\n",
    "\n",
    "\n",
    "Run the following cell to load the raw indices data of particular ticker's dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>RESULT_COUNT: 8654</th>\n",
       "      <th>PAGE_SIZE: 10000</th>\n",
       "      <th>CURRENT_PAGE: 1</th>\n",
       "      <th>TOTAL_PAGES: 1</th>\n",
       "      <th>API_CALL_CREDITS: 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th>OPEN</th>\n",
       "      <th>HIGH</th>\n",
       "      <th>LOW</th>\n",
       "      <th>CLOSE</th>\n",
       "      <th>VOLUME</th>\n",
       "      <th>EX_DIVIDEND</th>\n",
       "      <th>SPLIT_RATIO</th>\n",
       "      <th>ADJ_OPEN</th>\n",
       "      <td>ADJ_HIGH</td>\n",
       "      <td>ADJ_LOW</td>\n",
       "      <td>ADJ_CLOSE</td>\n",
       "      <td>ADJ_VOLUME</td>\n",
       "      <td>ADJ_FACTOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-27</th>\n",
       "      <th>109.55</th>\n",
       "      <th>110.1599</th>\n",
       "      <th>109.13</th>\n",
       "      <th>109.4</th>\n",
       "      <th>8642514.0</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>109.55</th>\n",
       "      <td>110.1599</td>\n",
       "      <td>109.13</td>\n",
       "      <td>109.4</td>\n",
       "      <td>8642514.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-26</th>\n",
       "      <th>109.97</th>\n",
       "      <th>110.82</th>\n",
       "      <th>109.34</th>\n",
       "      <th>110.1</th>\n",
       "      <th>10297133.0</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>109.97</th>\n",
       "      <td>110.82</td>\n",
       "      <td>109.34</td>\n",
       "      <td>110.1</td>\n",
       "      <td>10297133.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-25</th>\n",
       "      <th>110.27</th>\n",
       "      <th>110.53</th>\n",
       "      <th>108.6</th>\n",
       "      <th>109.99</th>\n",
       "      <th>13546110.0</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>110.27</th>\n",
       "      <td>110.53</td>\n",
       "      <td>108.6</td>\n",
       "      <td>109.99</td>\n",
       "      <td>13546110.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-24</th>\n",
       "      <th>111.75</th>\n",
       "      <th>112.9</th>\n",
       "      <th>109.59</th>\n",
       "      <th>110.41</th>\n",
       "      <th>16452412.0</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>111.75</th>\n",
       "      <td>112.9</td>\n",
       "      <td>109.59</td>\n",
       "      <td>110.41</td>\n",
       "      <td>16452412.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                     RESULT_COUNT: 8654  \\\n",
       "DATE       OPEN   HIGH     LOW    CLOSE  VOLUME     EX_DIVIDEND SPLIT_RATIO ADJ_OPEN           ADJ_HIGH   \n",
       "2018-04-27 109.55 110.1599 109.13 109.4  8642514.0  0.0         1.0         109.55             110.1599   \n",
       "2018-04-26 109.97 110.82   109.34 110.1  10297133.0 0.0         1.0         109.97               110.82   \n",
       "2018-04-25 110.27 110.53   108.6  109.99 13546110.0 0.0         1.0         110.27               110.53   \n",
       "2018-04-24 111.75 112.9    109.59 110.41 16452412.0 0.0         1.0         111.75                112.9   \n",
       "\n",
       "                                                                                     PAGE_SIZE: 10000  \\\n",
       "DATE       OPEN   HIGH     LOW    CLOSE  VOLUME     EX_DIVIDEND SPLIT_RATIO ADJ_OPEN          ADJ_LOW   \n",
       "2018-04-27 109.55 110.1599 109.13 109.4  8642514.0  0.0         1.0         109.55             109.13   \n",
       "2018-04-26 109.97 110.82   109.34 110.1  10297133.0 0.0         1.0         109.97             109.34   \n",
       "2018-04-25 110.27 110.53   108.6  109.99 13546110.0 0.0         1.0         110.27              108.6   \n",
       "2018-04-24 111.75 112.9    109.59 110.41 16452412.0 0.0         1.0         111.75             109.59   \n",
       "\n",
       "                                                                                     CURRENT_PAGE: 1  \\\n",
       "DATE       OPEN   HIGH     LOW    CLOSE  VOLUME     EX_DIVIDEND SPLIT_RATIO ADJ_OPEN       ADJ_CLOSE   \n",
       "2018-04-27 109.55 110.1599 109.13 109.4  8642514.0  0.0         1.0         109.55             109.4   \n",
       "2018-04-26 109.97 110.82   109.34 110.1  10297133.0 0.0         1.0         109.97             110.1   \n",
       "2018-04-25 110.27 110.53   108.6  109.99 13546110.0 0.0         1.0         110.27            109.99   \n",
       "2018-04-24 111.75 112.9    109.59 110.41 16452412.0 0.0         1.0         111.75            110.41   \n",
       "\n",
       "                                                                                     TOTAL_PAGES: 1  \\\n",
       "DATE       OPEN   HIGH     LOW    CLOSE  VOLUME     EX_DIVIDEND SPLIT_RATIO ADJ_OPEN     ADJ_VOLUME   \n",
       "2018-04-27 109.55 110.1599 109.13 109.4  8642514.0  0.0         1.0         109.55        8642514.0   \n",
       "2018-04-26 109.97 110.82   109.34 110.1  10297133.0 0.0         1.0         109.97       10297133.0   \n",
       "2018-04-25 110.27 110.53   108.6  109.99 13546110.0 0.0         1.0         110.27       13546110.0   \n",
       "2018-04-24 111.75 112.9    109.59 110.41 16452412.0 0.0         1.0         111.75       16452412.0   \n",
       "\n",
       "                                                                                     API_CALL_CREDITS: 1  \n",
       "DATE       OPEN   HIGH     LOW    CLOSE  VOLUME     EX_DIVIDEND SPLIT_RATIO ADJ_OPEN          ADJ_FACTOR  \n",
       "2018-04-27 109.55 110.1599 109.13 109.4  8642514.0  0.0         1.0         109.55                     1  \n",
       "2018-04-26 109.97 110.82   109.34 110.1  10297133.0 0.0         1.0         109.97                     1  \n",
       "2018-04-25 110.27 110.53   108.6  109.99 13546110.0 0.0         1.0         110.27                     1  \n",
       "2018-04-24 111.75 112.9    109.59 110.41 16452412.0 0.0         1.0         111.75                     1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticker = \"jpm\"\n",
    "\n",
    "dirc = \"data\"\n",
    "separator = \"/\"\n",
    "path = dirc + separator + ticker + separator \n",
    "\n",
    "#with open(path + ticker.upper() + \".csv\", 'r') as f:\n",
    "    #raw_data = list(csv.reader(f, delimiter=';'))    \n",
    "#print(raw_data[1:3])\n",
    "\n",
    "df = pd.read_csv(path + ticker.upper() + \".csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "\n",
    "For the model we will be using below information only: \n",
    "\n",
    "OPEN, HIGH, LOW, CLOSE, VOLUME, ADJ_OPEN, ADJ_HIGH, ADJ_LOW, ADJ_CLOSE, ADJ_VOLUME\n",
    "\n",
    "So we'll be ignoring following features for training our model:\n",
    "\n",
    "DATE, EX_DIVIDEND, SPLIT_RATIO, ADJ_FACTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OPEN</th>\n",
       "      <th>HIGH</th>\n",
       "      <th>LOW</th>\n",
       "      <th>CLOSE</th>\n",
       "      <th>VOLUME</th>\n",
       "      <th>ADJ_OPEN</th>\n",
       "      <th>ADJ_HIGH</th>\n",
       "      <th>ADJ_LOW</th>\n",
       "      <th>ADJ_CLOSE</th>\n",
       "      <th>ADJ_VOLUME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>109.55</td>\n",
       "      <td>110.1599</td>\n",
       "      <td>109.13</td>\n",
       "      <td>109.40</td>\n",
       "      <td>8642514.0</td>\n",
       "      <td>109.55</td>\n",
       "      <td>110.1599</td>\n",
       "      <td>109.13</td>\n",
       "      <td>109.40</td>\n",
       "      <td>8642514.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>109.97</td>\n",
       "      <td>110.8200</td>\n",
       "      <td>109.34</td>\n",
       "      <td>110.10</td>\n",
       "      <td>10297133.0</td>\n",
       "      <td>109.97</td>\n",
       "      <td>110.8200</td>\n",
       "      <td>109.34</td>\n",
       "      <td>110.10</td>\n",
       "      <td>10297133.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>110.27</td>\n",
       "      <td>110.5300</td>\n",
       "      <td>108.60</td>\n",
       "      <td>109.99</td>\n",
       "      <td>13546110.0</td>\n",
       "      <td>110.27</td>\n",
       "      <td>110.5300</td>\n",
       "      <td>108.60</td>\n",
       "      <td>109.99</td>\n",
       "      <td>13546110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>111.75</td>\n",
       "      <td>112.9000</td>\n",
       "      <td>109.59</td>\n",
       "      <td>110.41</td>\n",
       "      <td>16452412.0</td>\n",
       "      <td>111.75</td>\n",
       "      <td>112.9000</td>\n",
       "      <td>109.59</td>\n",
       "      <td>110.41</td>\n",
       "      <td>16452412.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>111.57</td>\n",
       "      <td>111.9500</td>\n",
       "      <td>110.63</td>\n",
       "      <td>110.93</td>\n",
       "      <td>11285181.0</td>\n",
       "      <td>111.57</td>\n",
       "      <td>111.9500</td>\n",
       "      <td>110.63</td>\n",
       "      <td>110.93</td>\n",
       "      <td>11285181.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     OPEN      HIGH     LOW   CLOSE      VOLUME  ADJ_OPEN  ADJ_HIGH  ADJ_LOW  \\\n",
       "0  109.55  110.1599  109.13  109.40   8642514.0    109.55  110.1599   109.13   \n",
       "1  109.97  110.8200  109.34  110.10  10297133.0    109.97  110.8200   109.34   \n",
       "2  110.27  110.5300  108.60  109.99  13546110.0    110.27  110.5300   108.60   \n",
       "3  111.75  112.9000  109.59  110.41  16452412.0    111.75  112.9000   109.59   \n",
       "4  111.57  111.9500  110.63  110.93  11285181.0    111.57  111.9500   110.63   \n",
       "\n",
       "   ADJ_CLOSE  ADJ_VOLUME  \n",
       "0     109.40   8642514.0  \n",
       "1     110.10  10297133.0  \n",
       "2     109.99  13546110.0  \n",
       "3     110.41  16452412.0  \n",
       "4     110.93  11285181.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticker = \"jpm2\"\n",
    "\n",
    "dirc = \"data\"\n",
    "separator = \"/\"\n",
    "path = dirc + separator + ticker + separator \n",
    "\n",
    "with open(path + ticker.upper() + \".csv\", 'r') as f:\n",
    "    raw_data = list(csv.reader(f, delimiter=';'))\n",
    "\n",
    "features_removed = ['DATE','EX_DIVIDEND','SPLIT_RATIO','ADJ_FACTOR']\n",
    "index_to_ignore = [0,6,7,13]  # corresponding indices of above features\n",
    "\n",
    "df = pd.read_csv(path + ticker.upper() + \".csv\")\n",
    "df.drop(features_removed, axis=1).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading\n",
    "\n",
    "For the model we will be loading all the available data in a given directory that can be for a single stock, a particular sector or all S&P 500 tickers: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading stocks data from dataset already downloaded from Intrinio.com\n",
      "Importing data took 0.092820s\n"
     ]
    }
   ],
   "source": [
    "def load_csv(fname, delimiter=\",\"):\n",
    "  data = np.genfromtxt(fname, delimiter=delimiter, skip_header=2)  \n",
    "  data = np.delete(data, index_to_ignore, axis=1) \n",
    "  return data\n",
    "\n",
    "# stock data loading\n",
    "def load_stock_data(path, columns=10):\n",
    "  print('Loading stocks data from dataset already downloaded from Intrinio.com')\n",
    "\n",
    "  # read a directory of data\n",
    "  stocks_set = np.zeros([0,columns])\n",
    "  for dir_item in os.listdir(path):\n",
    "    dir_item_path = os.path.join(path, dir_item)\n",
    "    if os.path.isfile(dir_item_path):\n",
    "      data = load_csv(dir_item_path)\n",
    "      stocks_set = np.concatenate((stocks_set, data), axis=0)\n",
    " \n",
    "  return stocks_set\n",
    "\n",
    "# Import data\n",
    "tic = time.time()\n",
    "data = load_stock_data(\"data/jpm/\")\n",
    "toc = time.time()\n",
    "print('Importing data took %fs' % (toc - tic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation \n",
    "\n",
    "With data augmentation we are increasing the number of movement patterns. The more the data, the better model will be, at least in principle :)\n",
    "\n",
    "Converting data into small set of matrix to make them similar (to the images like) one that we feed into CNN model. [4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing stocks data of few years will take a while, please stay tuned...\n",
      "Processing data took 513.966892s\n"
     ]
    }
   ],
   "source": [
    "# Valutation Day \n",
    "T=0    # the day algorithm/model runs \n",
    "\n",
    "# Training for forcasting # of days in future/advance\n",
    "stock_movement_on_day = T + 30\n",
    "moving_window = 256\n",
    "channels = 10\n",
    "\n",
    "# process a data into input and label arrays\n",
    "def data_preprocess(data, moving_window, stock_movement_on_day, columns):\n",
    "  print('Preprocessing stocks data of few years will take a while, please stay tuned...')\n",
    "\n",
    "  stock_set = np.zeros([0,moving_window,columns])\n",
    "  label_set = np.zeros([0,2])\n",
    "  for idx in range(data.shape[0] - (moving_window + stock_movement_on_day)):\n",
    "    stock_set = np.concatenate((stock_set, np.expand_dims(data[range(idx, idx + (moving_window)), :], axis=0)), axis=0)\n",
    "\n",
    "    if data[idx + (moving_window + stock_movement_on_day), 3] > data[idx + (moving_window), 3]:\n",
    "      lbl = [[1.0, 0.0]]\n",
    "    else:\n",
    "      lbl = [[0.0, 1.0]]\n",
    "    label_set = np.concatenate((label_set, lbl), axis=0)\n",
    "  \n",
    "  return stock_set, label_set\n",
    "\n",
    "# Call data_preprocess\n",
    "tic = time.time()\n",
    "stocks_set, labels_set = data_preprocess(data, moving_window, stock_movement_on_day, channels)\n",
    "toc = time.time()\n",
    "print('Processing data took %fs' % (toc - tic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize Time Series Data\n",
    "\n",
    "Normalization is a rescaling of the data from the original range so that all values are within the range of 0 and 1. Normalization can be useful as our stock data has input values with differing scales. \n",
    "\n",
    "For Normalization we need the feature wise minimum and maximum observable values from the . You may be able to estimate these values from your available data. \n",
    "\n",
    "However, if your time series is trending up or down, estimating these expected values may be difficult and normalization may not be the best method to use on your problem.\n",
    "\n",
    "A value is normalized as follows:\n",
    "\n",
    "y = (x - min) / (max - min)\n",
    "\n",
    "Where the minimum and maximum values pertain to the value x being normalized.\n",
    "\n",
    "\n",
    "In the cell below, we implement the normalize function to take in ticker's data, x, and return it as a normalized Numpy array. The return object should be the same shape as x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the data\n",
    "def normalize_data(stocks_set):\n",
    "  stocks_set_ = np.zeros(stocks_set.shape)\n",
    "  for i in range(len(stocks_set)):\n",
    "    min = stocks_set[i].min(axis=0)\n",
    "    max = stocks_set[i].max(axis=0)\n",
    "    stocks_set_[i] = (stocks_set[i] - min) / (max - min)\n",
    "  return stocks_set_\n",
    "\n",
    "#normalize\n",
    "stocks_set = normalize_data(stocks_set)\n",
    "\n",
    "#print(stocks_set[0:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle and Split the dataset\n",
    "\n",
    "Now we will shuffle and the dataset split into training, validation, and testing datasets. Shuffling is useful in order to avoid any element of bias/patterns in the split datasets before training the ML model. One important concept though is that data need to be shuffled first before split and not the otherwise. This helps to prevent  prevent overfitting and provide tool for cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shapes (x, y): (5857, 256, 10) (5857, 2)\n",
      "Validation shapes (x, y): (1256, 256, 10) (1256, 2)\n",
      "Test shapes (x, y): (1255, 256, 10) (1255, 2)\n"
     ]
    }
   ],
   "source": [
    "# Spilt and shuffle\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(stocks_set, labels_set, test_size=0.3, shuffle=True)\n",
    "test_x, val_x, test_y, val_y = train_test_split(test_x, test_y, test_size=0.5, shuffle=True)\n",
    "  \n",
    "print(\"Train shapes (x, y):\", train_x.shape, train_y.shape)\n",
    "print(\"Validation shapes (x, y):\", val_x.shape, val_y.shape)\n",
    "print(\"Test shapes (x, y):\", test_x.shape, test_y.shape)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batches\n",
    "\n",
    "Here is just a simple way to do batches. We've written it so that it includes all the data. Sometimes you'll throw out some data at the end to make sure you have full batches. Here we just extend the last batch to include the remaining data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(x, y, n_batches=10):\n",
    "    \"\"\" Return a generator that yields batches from arrays x and y. \"\"\"\n",
    "    batch_size = len(x)//n_batches\n",
    "    \n",
    "    #print(\"batch_size:\", batch_size)    \n",
    "    for ii in range(0, n_batches*batch_size, batch_size):\n",
    "        # If we're not on the last batch, grab data with size batch_size\n",
    "        if ii != (n_batches-1)*batch_size:\n",
    "            X, Y = x[ii: ii+batch_size], y[ii: ii+batch_size] \n",
    "        # On the last batch, grab the rest of the data\n",
    "        else:\n",
    "            X, Y = x[ii:], y[ii:]\n",
    "        # I love generators\n",
    "        yield X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Net Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods to define layers\n",
    "\n",
    "Instead of convolving a 2D image, we convolved a 1D image, since stock data would be created as an 1D tensor. \n",
    "\n",
    "After several convolutional layers and batchnorms later, we arrive at a tensor sized [batch_size, 2, 1024], which we then run through several softmax layers and finally a sigmoid activation to result in a tensor sized [batch_size, 2], with two values, one representing the bullish confidence, and the other one the bearish confidence. [4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv1d(input, output_dim,\n",
    "           conv_w=9, conv_s=2,\n",
    "           padding=\"SAME\", name=\"conv1d\",\n",
    "           stddev=0.02, bias=True):\n",
    "  with tf.variable_scope(name):\n",
    "    w = tf.get_variable('w', [conv_w, input.get_shape().as_list()[-1], output_dim],\n",
    "      initializer=tf.truncated_normal_initializer(stddev=stddev))\n",
    "    c = tf.nn.conv1d(input, w, conv_s, padding=padding)\n",
    "\n",
    "    if bias:\n",
    "      b = tf.get_variable('b', [output_dim], initializer=tf.constant_initializer(0.0))\n",
    "      return c + b\n",
    "\n",
    "    return c\n",
    "\n",
    "def batchnorm(input, name=\"batchnorm\", is_2d=False):\n",
    "  with tf.variable_scope(name):\n",
    "    input = tf.identity(input)\n",
    "    channels = input.get_shape()[-1]\n",
    "    offset = tf.get_variable(\"offset\", [channels],\n",
    "                              dtype=tf.float32,\n",
    "                              initializer=tf.zeros_initializer())\n",
    "    scale = tf.get_variable(\"scale\", [channels],\n",
    "                            dtype=tf.float32,\n",
    "                            initializer=tf.random_normal_initializer(1.0, 0.02))\n",
    "    if is_2d:\n",
    "      mean, variance = tf.nn.moments(input, axes=[0, 1, 2], keep_dims=False)\n",
    "    else:\n",
    "      mean, variance = tf.nn.moments(input, axes=[0, 1], keep_dims=False)\n",
    "    variance_epsilon = 1e-5\n",
    "    normalized = tf.nn.batch_normalization(input, mean, variance, offset, scale,\n",
    "                                           variance_epsilon=variance_epsilon)\n",
    "    return normalized\n",
    "\n",
    "def max_pool(input, ksize=2, pool_stride=2, padding=\"SAME\", name=\"max_pool\"):\n",
    "  with tf.variable_scope(name):\n",
    "    return tf.nn.max_pool(\n",
    "        input,\n",
    "        ksize=[1,ksize,ksize,1],\n",
    "        strides=[1,pool_stride,pool_stride,1],\n",
    "        padding=padding)\n",
    "\n",
    "def fully_connected(input, output_dim, name=\"fc\", stddev=0.02):\n",
    "  with tf.variable_scope(name):\n",
    "    unfolded_dim = ft.reduce(lambda x, y: x*y, input.get_shape().as_list()[1:])\n",
    "    w = tf.get_variable('w',\n",
    "      [unfolded_dim, output_dim],\n",
    "      initializer=tf.truncated_normal_initializer(stddev=stddev))\n",
    "    b = tf.get_variable('b', [output_dim], initializer=tf.constant_initializer(0.0))\n",
    "    input_flat = tf.reshape(input, [-1, unfolded_dim])\n",
    "\n",
    "    return tf.matmul(input_flat, w) + b\n",
    "\n",
    "def lrelu(x, a):\n",
    "  with tf.name_scope(\"lrelu\"):\n",
    "    x = tf.identity(x)\n",
    "    return (0.5 * (1 + a)) * x + (0.5 * (1 - a)) * tf.abs(x)\n",
    "\n",
    "def relu(x, name=\"relu\"):\n",
    "  return tf.nn.relu(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SP500_CNN:\n",
    "  def __init__(self,\n",
    "    image,\n",
    "    label,\n",
    "    dropout=0.5,\n",
    "    filter_num=128):\n",
    "\n",
    "    self.image = image\n",
    "    self.label = label\n",
    "    self.dropout = dropout\n",
    "    self.filter_num = filter_num\n",
    "\n",
    "  def build(self):\n",
    "      #input image\n",
    "      input_image = self.image\n",
    "\n",
    "      layers = []\n",
    "\n",
    "      # conv_1 \n",
    "      with tf.variable_scope(\"conv_1\"):\n",
    "        output = relu(conv1d(input_image, self.filter_num, name='conv_1'))\n",
    "        layers.append(output)\n",
    "\n",
    "      # conv_2 - conv_8\n",
    "      layer_specs = [\n",
    "        (self.filter_num * 2, 0.5),  \n",
    "        (self.filter_num * 4, 0.5),  \n",
    "        (self.filter_num * 4, 0.5),   \n",
    "        (self.filter_num * 8, 0.5),\n",
    "        (self.filter_num * 8, 0.5),  \n",
    "        (self.filter_num * 8, 0.5),  \n",
    "        (self.filter_num * 8, 0.5)  \n",
    "      ]\n",
    "\n",
    "      # adding layers\n",
    "      for _, (out_channels, dropout) in enumerate(layer_specs):\n",
    "        with tf.variable_scope(\"conv_%d\" % (len(layers) + 1)):\n",
    "          rectified = lrelu(layers[-1], 0.2)\n",
    "\n",
    "          # [batch, in_width, in_channels] \n",
    "          convolved = conv1d(rectified, out_channels)\n",
    "\n",
    "          # batchnormalize convolved\n",
    "          output = batchnorm(convolved, is_2d=False)\n",
    "\n",
    "          # dropout\n",
    "          if dropout > 0.0:\n",
    "            output = tf.nn.dropout(output, keep_prob=1 - dropout)\n",
    "\n",
    "          layers.append(output)\n",
    "\n",
    "      #fc1\n",
    "      h_fc1 = relu(fully_connected(layers[-1], 256, name='fc1'))\n",
    "\n",
    "      #dropout\n",
    "      h_fc1_drop = tf.nn.dropout(h_fc1, self.dropout)\n",
    "\n",
    "      #fc2\n",
    "      fc_layer = fully_connected(h_fc1_drop, 2, name='fc2')\n",
    "\n",
    "      return fc_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intializing Variables\n",
    "\n",
    "Here, we are initializing variable required during out training and testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "epochs = 100\n",
    "n_batches = 20\n",
    "iteration = 0\n",
    "lr_rate = 1e-3\n",
    "\n",
    "# Reset graph\n",
    "tf.reset_default_graph() \n",
    "\n",
    "# Construct graph\n",
    "image = tf.placeholder(tf.float32, [None, moving_window, channels])\n",
    "label = tf.placeholder(tf.float32, [None, 2])\n",
    "dropout = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build/Instantiate Model\n",
    "\n",
    "Method to build the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SP500_CNN(image, label, dropout=dropout)\n",
    "fcnet = model.build()\n",
    "\n",
    "logits = tf.sigmoid(fcnet)\n",
    "\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(labels=label, logits=logits)\n",
    "loss = tf.reduce_mean(cross_entropy) \n",
    "\n",
    "optimize = tf.train.AdamOptimizer(lr_rate).minimize(loss)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(label, 1), tf.argmax(logits, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Here, we'll train the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100 Iteration: 0 Training loss: 0.69531 Train Acc: 0.50717\n",
      "Epoch: 1/100 Iteration: 1 Training loss: 0.69419 Train Acc: 0.52070\n",
      "Epoch: 1/100 Iteration: 2 Training loss: 0.69318 Train Acc: 0.53264\n",
      "Epoch: 1/100 Iteration: 3 Training loss: 0.68380 Train Acc: 0.53264\n",
      "Epoch: 1/100 Iteration: 4 Training loss: 0.68664 Train Acc: 0.54618\n",
      "Epoch: 1/100 Iteration: 5 Validation Acc: 0.5581\n",
      "Epoch: 1/100 Iteration: 5 Training loss: 0.68372 Train Acc: 0.55414\n",
      "Epoch: 1/100 Iteration: 6 Training loss: 0.68860 Train Acc: 0.56449\n",
      "Epoch: 1/100 Iteration: 7 Training loss: 0.69068 Train Acc: 0.59395\n",
      "Epoch: 1/100 Iteration: 8 Training loss: 0.70314 Train Acc: 0.57245\n",
      "Epoch: 1/100 Iteration: 9 Training loss: 0.68094 Train Acc: 0.54538\n",
      "Epoch: 1/100 Iteration: 10 Validation Acc: 0.5549\n",
      "Epoch: 1/100 Iteration: 10 Training loss: 0.68183 Train Acc: 0.56529\n",
      "Epoch: 1/100 Iteration: 11 Training loss: 0.66903 Train Acc: 0.58121\n",
      "Epoch: 1/100 Iteration: 12 Training loss: 0.67178 Train Acc: 0.54299\n",
      "Epoch: 1/100 Iteration: 13 Training loss: 0.66125 Train Acc: 0.57564\n",
      "Epoch: 1/100 Iteration: 14 Training loss: 0.65532 Train Acc: 0.56210\n",
      "Epoch: 1/100 Iteration: 15 Validation Acc: 0.5701\n",
      "Epoch: 1/100 Iteration: 15 Training loss: 0.65802 Train Acc: 0.57245\n",
      "Epoch: 1/100 Iteration: 16 Training loss: 0.68047 Train Acc: 0.57166\n",
      "Epoch: 1/100 Iteration: 17 Training loss: 0.65113 Train Acc: 0.56768\n",
      "Epoch: 1/100 Iteration: 18 Training loss: 0.65235 Train Acc: 0.57325\n",
      "Epoch: 1/100 Iteration: 19 Training loss: 0.66434 Train Acc: 0.57882\n",
      "Epoch: 1/100 Iteration: 20 Validation Acc: 0.5764\n",
      "Epoch: 2/100 Iteration: 20 Training loss: 0.68951 Train Acc: 0.55812\n",
      "Epoch: 2/100 Iteration: 21 Training loss: 0.67691 Train Acc: 0.57803\n",
      "Epoch: 2/100 Iteration: 22 Training loss: 0.66759 Train Acc: 0.57723\n",
      "Epoch: 2/100 Iteration: 23 Training loss: 0.66676 Train Acc: 0.58201\n",
      "Epoch: 2/100 Iteration: 24 Training loss: 0.68170 Train Acc: 0.60430\n",
      "Epoch: 2/100 Iteration: 25 Validation Acc: 0.5971\n",
      "Epoch: 2/100 Iteration: 25 Training loss: 0.65097 Train Acc: 0.61465\n",
      "Epoch: 2/100 Iteration: 26 Training loss: 0.67276 Train Acc: 0.61863\n",
      "Epoch: 2/100 Iteration: 27 Training loss: 0.68027 Train Acc: 0.60828\n",
      "Epoch: 2/100 Iteration: 28 Training loss: 0.68494 Train Acc: 0.59475\n",
      "Epoch: 2/100 Iteration: 29 Training loss: 0.67431 Train Acc: 0.57723\n",
      "Epoch: 2/100 Iteration: 30 Validation Acc: 0.5748\n",
      "Epoch: 2/100 Iteration: 30 Training loss: 0.68342 Train Acc: 0.57006\n",
      "Epoch: 2/100 Iteration: 31 Training loss: 0.64528 Train Acc: 0.57166\n",
      "Epoch: 2/100 Iteration: 32 Training loss: 0.65397 Train Acc: 0.56529\n",
      "Epoch: 2/100 Iteration: 33 Training loss: 0.65591 Train Acc: 0.57325\n",
      "Epoch: 2/100 Iteration: 34 Training loss: 0.66059 Train Acc: 0.58917\n",
      "Epoch: 2/100 Iteration: 35 Validation Acc: 0.5995\n",
      "Epoch: 2/100 Iteration: 35 Training loss: 0.64746 Train Acc: 0.59713\n",
      "Epoch: 2/100 Iteration: 36 Training loss: 0.67649 Train Acc: 0.60430\n",
      "Epoch: 2/100 Iteration: 37 Training loss: 0.63407 Train Acc: 0.60828\n",
      "Epoch: 2/100 Iteration: 38 Training loss: 0.64277 Train Acc: 0.60589\n",
      "Epoch: 2/100 Iteration: 39 Training loss: 0.66226 Train Acc: 0.60191\n",
      "Epoch: 2/100 Iteration: 40 Validation Acc: 0.6059\n",
      "Epoch: 3/100 Iteration: 40 Training loss: 0.67227 Train Acc: 0.60669\n",
      "Epoch: 3/100 Iteration: 41 Training loss: 0.64930 Train Acc: 0.61226\n",
      "Epoch: 3/100 Iteration: 42 Training loss: 0.65384 Train Acc: 0.60908\n",
      "Epoch: 3/100 Iteration: 43 Training loss: 0.64367 Train Acc: 0.61624\n",
      "Epoch: 3/100 Iteration: 44 Training loss: 0.67275 Train Acc: 0.61783\n",
      "Epoch: 3/100 Iteration: 45 Validation Acc: 0.6226\n",
      "Epoch: 3/100 Iteration: 45 Training loss: 0.64872 Train Acc: 0.62261\n",
      "Epoch: 3/100 Iteration: 46 Training loss: 0.64764 Train Acc: 0.62580\n",
      "Epoch: 3/100 Iteration: 47 Training loss: 0.65458 Train Acc: 0.62898\n",
      "Epoch: 3/100 Iteration: 48 Training loss: 0.63576 Train Acc: 0.63694\n",
      "Epoch: 3/100 Iteration: 49 Training loss: 0.66989 Train Acc: 0.63535\n",
      "Epoch: 3/100 Iteration: 50 Validation Acc: 0.6314\n",
      "Epoch: 3/100 Iteration: 50 Training loss: 0.66166 Train Acc: 0.62420\n",
      "Epoch: 3/100 Iteration: 51 Training loss: 0.62024 Train Acc: 0.62341\n",
      "Epoch: 3/100 Iteration: 52 Training loss: 0.62426 Train Acc: 0.62818\n",
      "Epoch: 3/100 Iteration: 53 Training loss: 0.63402 Train Acc: 0.62500\n",
      "Epoch: 3/100 Iteration: 54 Training loss: 0.62764 Train Acc: 0.64729\n",
      "Epoch: 3/100 Iteration: 55 Validation Acc: 0.6449\n",
      "Epoch: 3/100 Iteration: 55 Training loss: 0.62202 Train Acc: 0.64729\n",
      "Epoch: 3/100 Iteration: 56 Training loss: 0.67140 Train Acc: 0.64650\n",
      "Epoch: 3/100 Iteration: 57 Training loss: 0.61783 Train Acc: 0.64411\n",
      "Epoch: 3/100 Iteration: 58 Training loss: 0.64095 Train Acc: 0.65366\n",
      "Epoch: 3/100 Iteration: 59 Training loss: 0.63967 Train Acc: 0.64650\n",
      "Epoch: 3/100 Iteration: 60 Validation Acc: 0.6489\n",
      "Epoch: 4/100 Iteration: 60 Training loss: 0.64860 Train Acc: 0.65207\n",
      "Epoch: 4/100 Iteration: 61 Training loss: 0.63706 Train Acc: 0.63694\n",
      "Epoch: 4/100 Iteration: 62 Training loss: 0.62313 Train Acc: 0.64570\n",
      "Epoch: 4/100 Iteration: 63 Training loss: 0.62054 Train Acc: 0.65127\n",
      "Epoch: 4/100 Iteration: 64 Training loss: 0.60970 Train Acc: 0.67675\n",
      "Epoch: 4/100 Iteration: 65 Validation Acc: 0.6855\n",
      "Epoch: 4/100 Iteration: 65 Training loss: 0.60534 Train Acc: 0.67197\n",
      "Epoch: 4/100 Iteration: 66 Training loss: 0.65653 Train Acc: 0.67596\n",
      "Epoch: 4/100 Iteration: 67 Training loss: 0.66447 Train Acc: 0.66322\n",
      "Epoch: 4/100 Iteration: 68 Training loss: 0.64003 Train Acc: 0.66959\n",
      "Epoch: 4/100 Iteration: 69 Training loss: 0.63963 Train Acc: 0.68073\n",
      "Epoch: 4/100 Iteration: 70 Validation Acc: 0.6752\n",
      "Epoch: 4/100 Iteration: 70 Training loss: 0.66534 Train Acc: 0.65048\n",
      "Epoch: 4/100 Iteration: 71 Training loss: 0.59513 Train Acc: 0.65844\n",
      "Epoch: 4/100 Iteration: 72 Training loss: 0.61790 Train Acc: 0.64729\n",
      "Epoch: 4/100 Iteration: 73 Training loss: 0.63376 Train Acc: 0.65127\n",
      "Epoch: 4/100 Iteration: 74 Training loss: 0.62723 Train Acc: 0.66879\n",
      "Epoch: 4/100 Iteration: 75 Validation Acc: 0.6561\n",
      "Epoch: 4/100 Iteration: 75 Training loss: 0.60087 Train Acc: 0.68073\n",
      "Epoch: 4/100 Iteration: 76 Training loss: 0.64857 Train Acc: 0.66162\n",
      "Epoch: 4/100 Iteration: 77 Training loss: 0.61284 Train Acc: 0.64331\n",
      "Epoch: 4/100 Iteration: 78 Training loss: 0.62939 Train Acc: 0.65048\n",
      "Epoch: 4/100 Iteration: 79 Training loss: 0.62279 Train Acc: 0.65764\n",
      "Epoch: 4/100 Iteration: 80 Validation Acc: 0.6592\n",
      "Epoch: 5/100 Iteration: 80 Training loss: 0.64622 Train Acc: 0.67516\n",
      "Epoch: 5/100 Iteration: 81 Training loss: 0.60745 Train Acc: 0.70064\n",
      "Epoch: 5/100 Iteration: 82 Training loss: 0.59441 Train Acc: 0.67755\n",
      "Epoch: 5/100 Iteration: 83 Training loss: 0.61132 Train Acc: 0.68232\n",
      "Epoch: 5/100 Iteration: 84 Training loss: 0.61413 Train Acc: 0.69347\n",
      "Epoch: 5/100 Iteration: 85 Validation Acc: 0.7022\n",
      "Epoch: 5/100 Iteration: 85 Training loss: 0.58899 Train Acc: 0.69666\n",
      "Epoch: 5/100 Iteration: 86 Training loss: 0.59146 Train Acc: 0.70701\n",
      "Epoch: 5/100 Iteration: 87 Training loss: 0.61092 Train Acc: 0.71338\n",
      "Epoch: 5/100 Iteration: 88 Training loss: 0.60402 Train Acc: 0.69825\n",
      "Epoch: 5/100 Iteration: 89 Training loss: 0.61982 Train Acc: 0.69904\n",
      "Epoch: 5/100 Iteration: 90 Validation Acc: 0.6919\n",
      "Epoch: 5/100 Iteration: 90 Training loss: 0.60228 Train Acc: 0.69984\n",
      "Epoch: 5/100 Iteration: 91 Training loss: 0.58226 Train Acc: 0.70382\n",
      "Epoch: 5/100 Iteration: 92 Training loss: 0.59229 Train Acc: 0.70780\n",
      "Epoch: 5/100 Iteration: 93 Training loss: 0.60508 Train Acc: 0.69745\n",
      "Epoch: 5/100 Iteration: 94 Training loss: 0.59241 Train Acc: 0.69984\n",
      "Epoch: 5/100 Iteration: 95 Validation Acc: 0.7142\n",
      "Epoch: 5/100 Iteration: 95 Training loss: 0.57892 Train Acc: 0.71258\n",
      "Epoch: 5/100 Iteration: 96 Training loss: 0.61744 Train Acc: 0.69506\n",
      "Epoch: 5/100 Iteration: 97 Training loss: 0.59313 Train Acc: 0.70939\n",
      "Epoch: 5/100 Iteration: 98 Training loss: 0.61091 Train Acc: 0.69427\n",
      "Epoch: 5/100 Iteration: 99 Training loss: 0.55801 Train Acc: 0.68551\n",
      "Epoch: 5/100 Iteration: 100 Validation Acc: 0.6744\n",
      "Epoch: 6/100 Iteration: 100 Training loss: 0.61593 Train Acc: 0.69745\n",
      "Epoch: 6/100 Iteration: 101 Training loss: 0.57671 Train Acc: 0.70701\n",
      "Epoch: 6/100 Iteration: 102 Training loss: 0.55755 Train Acc: 0.73248\n",
      "Epoch: 6/100 Iteration: 103 Training loss: 0.56437 Train Acc: 0.71258\n",
      "Epoch: 6/100 Iteration: 104 Training loss: 0.58246 Train Acc: 0.73248\n",
      "Epoch: 6/100 Iteration: 105 Validation Acc: 0.7269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/100 Iteration: 105 Training loss: 0.56207 Train Acc: 0.72213\n",
      "Epoch: 6/100 Iteration: 106 Training loss: 0.57529 Train Acc: 0.72134\n",
      "Epoch: 6/100 Iteration: 107 Training loss: 0.60054 Train Acc: 0.71656\n",
      "Epoch: 6/100 Iteration: 108 Training loss: 0.59794 Train Acc: 0.72452\n",
      "Epoch: 6/100 Iteration: 109 Training loss: 0.58790 Train Acc: 0.71497\n",
      "Epoch: 6/100 Iteration: 110 Validation Acc: 0.7205\n",
      "Epoch: 6/100 Iteration: 110 Training loss: 0.57174 Train Acc: 0.71576\n",
      "Epoch: 6/100 Iteration: 111 Training loss: 0.56656 Train Acc: 0.71656\n",
      "Epoch: 6/100 Iteration: 112 Training loss: 0.57201 Train Acc: 0.71576\n",
      "Epoch: 6/100 Iteration: 113 Training loss: 0.58247 Train Acc: 0.71815\n",
      "Epoch: 6/100 Iteration: 114 Training loss: 0.56248 Train Acc: 0.71975\n",
      "Epoch: 6/100 Iteration: 115 Validation Acc: 0.7269\n",
      "Epoch: 6/100 Iteration: 115 Training loss: 0.56231 Train Acc: 0.73089\n",
      "Epoch: 6/100 Iteration: 116 Training loss: 0.58782 Train Acc: 0.72452\n",
      "Epoch: 6/100 Iteration: 117 Training loss: 0.58712 Train Acc: 0.70621\n",
      "Epoch: 6/100 Iteration: 118 Training loss: 0.58614 Train Acc: 0.70780\n",
      "Epoch: 6/100 Iteration: 119 Training loss: 0.56322 Train Acc: 0.71656\n",
      "Epoch: 6/100 Iteration: 120 Validation Acc: 0.7078\n",
      "Epoch: 7/100 Iteration: 120 Training loss: 0.59182 Train Acc: 0.70462\n",
      "Epoch: 7/100 Iteration: 121 Training loss: 0.58517 Train Acc: 0.72691\n",
      "Epoch: 7/100 Iteration: 122 Training loss: 0.56616 Train Acc: 0.72532\n",
      "Epoch: 7/100 Iteration: 123 Training loss: 0.57740 Train Acc: 0.72850\n",
      "Epoch: 7/100 Iteration: 124 Training loss: 0.57100 Train Acc: 0.71975\n",
      "Epoch: 7/100 Iteration: 125 Validation Acc: 0.7309\n",
      "Epoch: 7/100 Iteration: 125 Training loss: 0.58169 Train Acc: 0.69984\n",
      "Epoch: 7/100 Iteration: 126 Training loss: 0.60396 Train Acc: 0.72054\n",
      "Epoch: 7/100 Iteration: 127 Training loss: 0.60888 Train Acc: 0.72850\n",
      "Epoch: 7/100 Iteration: 128 Training loss: 0.57204 Train Acc: 0.73169\n",
      "Epoch: 7/100 Iteration: 129 Training loss: 0.58281 Train Acc: 0.72930\n",
      "Epoch: 7/100 Iteration: 130 Validation Acc: 0.7309\n",
      "Epoch: 7/100 Iteration: 130 Training loss: 0.55902 Train Acc: 0.72771\n",
      "Epoch: 7/100 Iteration: 131 Training loss: 0.53002 Train Acc: 0.70382\n",
      "Epoch: 7/100 Iteration: 132 Training loss: 0.56094 Train Acc: 0.70462\n",
      "Epoch: 7/100 Iteration: 133 Training loss: 0.59831 Train Acc: 0.71576\n",
      "Epoch: 7/100 Iteration: 134 Training loss: 0.57001 Train Acc: 0.71178\n",
      "Epoch: 7/100 Iteration: 135 Validation Acc: 0.7261\n",
      "Epoch: 7/100 Iteration: 135 Training loss: 0.56391 Train Acc: 0.72054\n",
      "Epoch: 7/100 Iteration: 136 Training loss: 0.59520 Train Acc: 0.71975\n",
      "Epoch: 7/100 Iteration: 137 Training loss: 0.56670 Train Acc: 0.71258\n",
      "Epoch: 7/100 Iteration: 138 Training loss: 0.58176 Train Acc: 0.71178\n",
      "Epoch: 7/100 Iteration: 139 Training loss: 0.55266 Train Acc: 0.72452\n",
      "Epoch: 7/100 Iteration: 140 Validation Acc: 0.7158\n",
      "Epoch: 8/100 Iteration: 140 Training loss: 0.57403 Train Acc: 0.73089\n",
      "Epoch: 8/100 Iteration: 141 Training loss: 0.55749 Train Acc: 0.71975\n",
      "Epoch: 8/100 Iteration: 142 Training loss: 0.54146 Train Acc: 0.71417\n",
      "Epoch: 8/100 Iteration: 143 Training loss: 0.54181 Train Acc: 0.72691\n",
      "Epoch: 8/100 Iteration: 144 Training loss: 0.56913 Train Acc: 0.71895\n",
      "Epoch: 8/100 Iteration: 145 Validation Acc: 0.7078\n",
      "Epoch: 8/100 Iteration: 145 Training loss: 0.55784 Train Acc: 0.71736\n",
      "Epoch: 8/100 Iteration: 146 Training loss: 0.57492 Train Acc: 0.72452\n",
      "Epoch: 8/100 Iteration: 147 Training loss: 0.60214 Train Acc: 0.72452\n",
      "Epoch: 8/100 Iteration: 148 Training loss: 0.57489 Train Acc: 0.73965\n",
      "Epoch: 8/100 Iteration: 149 Training loss: 0.56926 Train Acc: 0.72373\n",
      "Epoch: 8/100 Iteration: 150 Validation Acc: 0.7317\n",
      "Epoch: 8/100 Iteration: 150 Training loss: 0.58102 Train Acc: 0.71975\n",
      "Epoch: 8/100 Iteration: 151 Training loss: 0.53525 Train Acc: 0.71338\n",
      "Epoch: 8/100 Iteration: 152 Training loss: 0.57478 Train Acc: 0.70701\n",
      "Epoch: 8/100 Iteration: 153 Training loss: 0.56379 Train Acc: 0.71576\n",
      "Epoch: 8/100 Iteration: 154 Training loss: 0.56744 Train Acc: 0.72054\n",
      "Epoch: 8/100 Iteration: 155 Validation Acc: 0.7253\n",
      "Epoch: 8/100 Iteration: 155 Training loss: 0.53489 Train Acc: 0.72930\n",
      "Epoch: 8/100 Iteration: 156 Training loss: 0.59037 Train Acc: 0.72373\n",
      "Epoch: 8/100 Iteration: 157 Training loss: 0.56206 Train Acc: 0.72452\n",
      "Epoch: 8/100 Iteration: 158 Training loss: 0.54445 Train Acc: 0.72691\n",
      "Epoch: 8/100 Iteration: 159 Training loss: 0.54250 Train Acc: 0.73089\n",
      "Epoch: 8/100 Iteration: 160 Validation Acc: 0.7277\n",
      "Epoch: 9/100 Iteration: 160 Training loss: 0.58486 Train Acc: 0.73965\n",
      "Epoch: 9/100 Iteration: 161 Training loss: 0.54505 Train Acc: 0.73885\n",
      "Epoch: 9/100 Iteration: 162 Training loss: 0.54402 Train Acc: 0.73169\n",
      "Epoch: 9/100 Iteration: 163 Training loss: 0.51442 Train Acc: 0.74682\n",
      "Epoch: 9/100 Iteration: 164 Training loss: 0.54357 Train Acc: 0.74443\n",
      "Epoch: 9/100 Iteration: 165 Validation Acc: 0.7396\n",
      "Epoch: 9/100 Iteration: 165 Training loss: 0.54258 Train Acc: 0.73089\n",
      "Epoch: 9/100 Iteration: 166 Training loss: 0.54264 Train Acc: 0.73169\n",
      "Epoch: 9/100 Iteration: 167 Training loss: 0.53499 Train Acc: 0.73408\n",
      "Epoch: 9/100 Iteration: 168 Training loss: 0.54323 Train Acc: 0.71258\n",
      "Epoch: 9/100 Iteration: 169 Training loss: 0.57320 Train Acc: 0.72850\n",
      "Epoch: 9/100 Iteration: 170 Validation Acc: 0.7293\n",
      "Epoch: 9/100 Iteration: 170 Training loss: 0.56723 Train Acc: 0.74841\n",
      "Epoch: 9/100 Iteration: 171 Training loss: 0.52291 Train Acc: 0.72930\n",
      "Epoch: 9/100 Iteration: 172 Training loss: 0.53439 Train Acc: 0.74761\n",
      "Epoch: 9/100 Iteration: 173 Training loss: 0.54374 Train Acc: 0.74522\n",
      "Epoch: 9/100 Iteration: 174 Training loss: 0.53950 Train Acc: 0.74761\n",
      "Epoch: 9/100 Iteration: 175 Validation Acc: 0.7349\n",
      "Epoch: 9/100 Iteration: 175 Training loss: 0.53922 Train Acc: 0.73169\n",
      "Epoch: 9/100 Iteration: 176 Training loss: 0.55896 Train Acc: 0.74682\n",
      "Epoch: 9/100 Iteration: 177 Training loss: 0.54735 Train Acc: 0.73567\n",
      "Epoch: 9/100 Iteration: 178 Training loss: 0.54329 Train Acc: 0.74522\n",
      "Epoch: 9/100 Iteration: 179 Training loss: 0.52053 Train Acc: 0.74283\n",
      "Epoch: 9/100 Iteration: 180 Validation Acc: 0.7365\n",
      "Epoch: 10/100 Iteration: 180 Training loss: 0.54721 Train Acc: 0.74124\n",
      "Epoch: 10/100 Iteration: 181 Training loss: 0.54503 Train Acc: 0.75717\n",
      "Epoch: 10/100 Iteration: 182 Training loss: 0.51624 Train Acc: 0.74045\n",
      "Epoch: 10/100 Iteration: 183 Training loss: 0.53076 Train Acc: 0.73328\n",
      "Epoch: 10/100 Iteration: 184 Training loss: 0.55635 Train Acc: 0.75159\n",
      "Epoch: 10/100 Iteration: 185 Validation Acc: 0.7500\n",
      "Epoch: 10/100 Iteration: 185 Training loss: 0.55758 Train Acc: 0.74682\n",
      "Epoch: 10/100 Iteration: 186 Training loss: 0.51656 Train Acc: 0.74443\n",
      "Epoch: 10/100 Iteration: 187 Training loss: 0.53406 Train Acc: 0.74761\n",
      "Epoch: 10/100 Iteration: 188 Training loss: 0.55703 Train Acc: 0.73965\n",
      "Epoch: 10/100 Iteration: 189 Training loss: 0.56826 Train Acc: 0.73169\n",
      "Epoch: 10/100 Iteration: 190 Validation Acc: 0.7412\n",
      "Epoch: 10/100 Iteration: 190 Training loss: 0.56159 Train Acc: 0.73248\n",
      "Epoch: 10/100 Iteration: 191 Training loss: 0.52665 Train Acc: 0.76354\n",
      "Epoch: 10/100 Iteration: 192 Training loss: 0.52126 Train Acc: 0.75717\n",
      "Epoch: 10/100 Iteration: 193 Training loss: 0.54099 Train Acc: 0.74761\n",
      "Epoch: 10/100 Iteration: 194 Training loss: 0.55618 Train Acc: 0.74045\n",
      "Epoch: 10/100 Iteration: 195 Validation Acc: 0.7484\n",
      "Epoch: 10/100 Iteration: 195 Training loss: 0.53166 Train Acc: 0.73965\n",
      "Epoch: 10/100 Iteration: 196 Training loss: 0.55677 Train Acc: 0.73726\n",
      "Epoch: 10/100 Iteration: 197 Training loss: 0.52498 Train Acc: 0.74045\n",
      "Epoch: 10/100 Iteration: 198 Training loss: 0.51739 Train Acc: 0.75637\n",
      "Epoch: 10/100 Iteration: 199 Training loss: 0.53589 Train Acc: 0.73487\n",
      "Epoch: 10/100 Iteration: 200 Validation Acc: 0.7460\n",
      "Epoch: 11/100 Iteration: 200 Training loss: 0.55169 Train Acc: 0.74522\n",
      "Epoch: 11/100 Iteration: 201 Training loss: 0.52946 Train Acc: 0.75637\n",
      "Epoch: 11/100 Iteration: 202 Training loss: 0.52736 Train Acc: 0.76274\n",
      "Epoch: 11/100 Iteration: 203 Training loss: 0.49553 Train Acc: 0.76831\n",
      "Epoch: 11/100 Iteration: 204 Training loss: 0.51119 Train Acc: 0.76911\n",
      "Epoch: 11/100 Iteration: 205 Validation Acc: 0.7763\n",
      "Epoch: 11/100 Iteration: 205 Training loss: 0.54305 Train Acc: 0.77946\n",
      "Epoch: 11/100 Iteration: 206 Training loss: 0.51655 Train Acc: 0.76990\n",
      "Epoch: 11/100 Iteration: 207 Training loss: 0.56955 Train Acc: 0.76513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11/100 Iteration: 208 Training loss: 0.53297 Train Acc: 0.75955\n",
      "Epoch: 11/100 Iteration: 209 Training loss: 0.55699 Train Acc: 0.75318\n",
      "Epoch: 11/100 Iteration: 210 Validation Acc: 0.7556\n",
      "Epoch: 11/100 Iteration: 210 Training loss: 0.53382 Train Acc: 0.75398\n",
      "Epoch: 11/100 Iteration: 211 Training loss: 0.50969 Train Acc: 0.75000\n",
      "Epoch: 11/100 Iteration: 212 Training loss: 0.52123 Train Acc: 0.74443\n",
      "Epoch: 11/100 Iteration: 213 Training loss: 0.52428 Train Acc: 0.73248\n",
      "Epoch: 11/100 Iteration: 214 Training loss: 0.54555 Train Acc: 0.72532\n",
      "Epoch: 11/100 Iteration: 215 Validation Acc: 0.7357\n",
      "Epoch: 11/100 Iteration: 215 Training loss: 0.55578 Train Acc: 0.73328\n",
      "Epoch: 11/100 Iteration: 216 Training loss: 0.55326 Train Acc: 0.73885\n",
      "Epoch: 11/100 Iteration: 217 Training loss: 0.52192 Train Acc: 0.75080\n",
      "Epoch: 11/100 Iteration: 218 Training loss: 0.54238 Train Acc: 0.75159\n",
      "Epoch: 11/100 Iteration: 219 Training loss: 0.52676 Train Acc: 0.75318\n",
      "Epoch: 11/100 Iteration: 220 Validation Acc: 0.7588\n",
      "Epoch: 12/100 Iteration: 220 Training loss: 0.55384 Train Acc: 0.75239\n",
      "Epoch: 12/100 Iteration: 221 Training loss: 0.50668 Train Acc: 0.75955\n",
      "Epoch: 12/100 Iteration: 222 Training loss: 0.53588 Train Acc: 0.75637\n",
      "Epoch: 12/100 Iteration: 223 Training loss: 0.53705 Train Acc: 0.77627\n",
      "Epoch: 12/100 Iteration: 224 Training loss: 0.53360 Train Acc: 0.77946\n",
      "Epoch: 12/100 Iteration: 225 Validation Acc: 0.7874\n",
      "Epoch: 12/100 Iteration: 225 Training loss: 0.51058 Train Acc: 0.79299\n",
      "Epoch: 12/100 Iteration: 226 Training loss: 0.51199 Train Acc: 0.78424\n",
      "Epoch: 12/100 Iteration: 227 Training loss: 0.53760 Train Acc: 0.77627\n",
      "Epoch: 12/100 Iteration: 228 Training loss: 0.49721 Train Acc: 0.77627\n",
      "Epoch: 12/100 Iteration: 229 Training loss: 0.51012 Train Acc: 0.77548\n",
      "Epoch: 12/100 Iteration: 230 Validation Acc: 0.7715\n",
      "Epoch: 12/100 Iteration: 230 Training loss: 0.52277 Train Acc: 0.75876\n",
      "Epoch: 12/100 Iteration: 231 Training loss: 0.51997 Train Acc: 0.74841\n",
      "Epoch: 12/100 Iteration: 232 Training loss: 0.53350 Train Acc: 0.75717\n",
      "Epoch: 12/100 Iteration: 233 Training loss: 0.53138 Train Acc: 0.75239\n",
      "Epoch: 12/100 Iteration: 234 Training loss: 0.51143 Train Acc: 0.77548\n",
      "Epoch: 12/100 Iteration: 235 Validation Acc: 0.7643\n",
      "Epoch: 12/100 Iteration: 235 Training loss: 0.50376 Train Acc: 0.77389\n",
      "Epoch: 12/100 Iteration: 236 Training loss: 0.52226 Train Acc: 0.76274\n",
      "Epoch: 12/100 Iteration: 237 Training loss: 0.50237 Train Acc: 0.77548\n",
      "Epoch: 12/100 Iteration: 238 Training loss: 0.50339 Train Acc: 0.78344\n",
      "Epoch: 12/100 Iteration: 239 Training loss: 0.49682 Train Acc: 0.76911\n",
      "Epoch: 12/100 Iteration: 240 Validation Acc: 0.7604\n",
      "Epoch: 13/100 Iteration: 240 Training loss: 0.53636 Train Acc: 0.75637\n",
      "Epoch: 13/100 Iteration: 241 Training loss: 0.49747 Train Acc: 0.76990\n",
      "Epoch: 13/100 Iteration: 242 Training loss: 0.49775 Train Acc: 0.76672\n",
      "Epoch: 13/100 Iteration: 243 Training loss: 0.50382 Train Acc: 0.76990\n",
      "Epoch: 13/100 Iteration: 244 Training loss: 0.48059 Train Acc: 0.77150\n",
      "Epoch: 13/100 Iteration: 245 Validation Acc: 0.7803\n",
      "Epoch: 13/100 Iteration: 245 Training loss: 0.53106 Train Acc: 0.77548\n",
      "Epoch: 13/100 Iteration: 246 Training loss: 0.53052 Train Acc: 0.78662\n",
      "Epoch: 13/100 Iteration: 247 Training loss: 0.52090 Train Acc: 0.79220\n",
      "Epoch: 13/100 Iteration: 248 Training loss: 0.47617 Train Acc: 0.80175\n",
      "Epoch: 13/100 Iteration: 249 Training loss: 0.52519 Train Acc: 0.79220\n",
      "Epoch: 13/100 Iteration: 250 Validation Acc: 0.7898\n",
      "Epoch: 13/100 Iteration: 250 Training loss: 0.49995 Train Acc: 0.78742\n",
      "Epoch: 13/100 Iteration: 251 Training loss: 0.48420 Train Acc: 0.77946\n",
      "Epoch: 13/100 Iteration: 252 Training loss: 0.50555 Train Acc: 0.76354\n",
      "Epoch: 13/100 Iteration: 253 Training loss: 0.48552 Train Acc: 0.76354\n",
      "Epoch: 13/100 Iteration: 254 Training loss: 0.51585 Train Acc: 0.76990\n",
      "Epoch: 13/100 Iteration: 255 Validation Acc: 0.7659\n",
      "Epoch: 13/100 Iteration: 255 Training loss: 0.53850 Train Acc: 0.76592\n",
      "Epoch: 13/100 Iteration: 256 Training loss: 0.52833 Train Acc: 0.78424\n",
      "Epoch: 13/100 Iteration: 257 Training loss: 0.49755 Train Acc: 0.77946\n",
      "Epoch: 13/100 Iteration: 258 Training loss: 0.49599 Train Acc: 0.78185\n",
      "Epoch: 13/100 Iteration: 259 Training loss: 0.46304 Train Acc: 0.80175\n",
      "Epoch: 13/100 Iteration: 260 Validation Acc: 0.7922\n",
      "Epoch: 14/100 Iteration: 260 Training loss: 0.49819 Train Acc: 0.79220\n",
      "Epoch: 14/100 Iteration: 261 Training loss: 0.47547 Train Acc: 0.77468\n",
      "Epoch: 14/100 Iteration: 262 Training loss: 0.48414 Train Acc: 0.76831\n",
      "Epoch: 14/100 Iteration: 263 Training loss: 0.50487 Train Acc: 0.78105\n",
      "Epoch: 14/100 Iteration: 264 Training loss: 0.48411 Train Acc: 0.78105\n",
      "Epoch: 14/100 Iteration: 265 Validation Acc: 0.7707\n",
      "Epoch: 14/100 Iteration: 265 Training loss: 0.50091 Train Acc: 0.76513\n",
      "Epoch: 14/100 Iteration: 266 Training loss: 0.52122 Train Acc: 0.77229\n",
      "Epoch: 14/100 Iteration: 267 Training loss: 0.53129 Train Acc: 0.76513\n",
      "Epoch: 14/100 Iteration: 268 Training loss: 0.50102 Train Acc: 0.78025\n",
      "Epoch: 14/100 Iteration: 269 Training loss: 0.54502 Train Acc: 0.78025\n",
      "Epoch: 14/100 Iteration: 270 Validation Acc: 0.7747\n",
      "Epoch: 14/100 Iteration: 270 Training loss: 0.49456 Train Acc: 0.77946\n",
      "Epoch: 14/100 Iteration: 271 Training loss: 0.48943 Train Acc: 0.78105\n",
      "Epoch: 14/100 Iteration: 272 Training loss: 0.48356 Train Acc: 0.78344\n",
      "Epoch: 14/100 Iteration: 273 Training loss: 0.47655 Train Acc: 0.78344\n",
      "Epoch: 14/100 Iteration: 274 Training loss: 0.49787 Train Acc: 0.78822\n",
      "Epoch: 14/100 Iteration: 275 Validation Acc: 0.7882\n",
      "Epoch: 14/100 Iteration: 275 Training loss: 0.51092 Train Acc: 0.78503\n",
      "Epoch: 14/100 Iteration: 276 Training loss: 0.53574 Train Acc: 0.77468\n",
      "Epoch: 14/100 Iteration: 277 Training loss: 0.47746 Train Acc: 0.78185\n",
      "Epoch: 14/100 Iteration: 278 Training loss: 0.51498 Train Acc: 0.77627\n",
      "Epoch: 14/100 Iteration: 279 Training loss: 0.48801 Train Acc: 0.78822\n",
      "Epoch: 14/100 Iteration: 280 Validation Acc: 0.7699\n",
      "Epoch: 15/100 Iteration: 280 Training loss: 0.51085 Train Acc: 0.77946\n",
      "Epoch: 15/100 Iteration: 281 Training loss: 0.47648 Train Acc: 0.76513\n",
      "Epoch: 15/100 Iteration: 282 Training loss: 0.49292 Train Acc: 0.78742\n",
      "Epoch: 15/100 Iteration: 283 Training loss: 0.48358 Train Acc: 0.78742\n",
      "Epoch: 15/100 Iteration: 284 Training loss: 0.47558 Train Acc: 0.79299\n",
      "Epoch: 15/100 Iteration: 285 Validation Acc: 0.7818\n",
      "Epoch: 15/100 Iteration: 285 Training loss: 0.51732 Train Acc: 0.80414\n",
      "Epoch: 15/100 Iteration: 286 Training loss: 0.48811 Train Acc: 0.79936\n",
      "Epoch: 15/100 Iteration: 287 Training loss: 0.49186 Train Acc: 0.78025\n",
      "Epoch: 15/100 Iteration: 288 Training loss: 0.49370 Train Acc: 0.76274\n",
      "Epoch: 15/100 Iteration: 289 Training loss: 0.51511 Train Acc: 0.78503\n",
      "Epoch: 15/100 Iteration: 290 Validation Acc: 0.7811\n",
      "Epoch: 15/100 Iteration: 290 Training loss: 0.51391 Train Acc: 0.77787\n",
      "Epoch: 15/100 Iteration: 291 Training loss: 0.47939 Train Acc: 0.77389\n",
      "Epoch: 15/100 Iteration: 292 Training loss: 0.49257 Train Acc: 0.78105\n",
      "Epoch: 15/100 Iteration: 293 Training loss: 0.50533 Train Acc: 0.78981\n",
      "Epoch: 15/100 Iteration: 294 Training loss: 0.52046 Train Acc: 0.79140\n",
      "Epoch: 15/100 Iteration: 295 Validation Acc: 0.8018\n",
      "Epoch: 15/100 Iteration: 295 Training loss: 0.49815 Train Acc: 0.77866\n",
      "Epoch: 15/100 Iteration: 296 Training loss: 0.51286 Train Acc: 0.78105\n",
      "Epoch: 15/100 Iteration: 297 Training loss: 0.47376 Train Acc: 0.80255\n",
      "Epoch: 15/100 Iteration: 298 Training loss: 0.50553 Train Acc: 0.78981\n",
      "Epoch: 15/100 Iteration: 299 Training loss: 0.46784 Train Acc: 0.78822\n",
      "Epoch: 15/100 Iteration: 300 Validation Acc: 0.7890\n",
      "Epoch: 16/100 Iteration: 300 Training loss: 0.50702 Train Acc: 0.80096\n",
      "Epoch: 16/100 Iteration: 301 Training loss: 0.46964 Train Acc: 0.78822\n",
      "Epoch: 16/100 Iteration: 302 Training loss: 0.49174 Train Acc: 0.77309\n",
      "Epoch: 16/100 Iteration: 303 Training loss: 0.47043 Train Acc: 0.77150\n",
      "Epoch: 16/100 Iteration: 304 Training loss: 0.50346 Train Acc: 0.76513\n",
      "Epoch: 16/100 Iteration: 305 Validation Acc: 0.7596\n",
      "Epoch: 16/100 Iteration: 305 Training loss: 0.52047 Train Acc: 0.76433\n",
      "Epoch: 16/100 Iteration: 306 Training loss: 0.51072 Train Acc: 0.76911\n",
      "Epoch: 16/100 Iteration: 307 Training loss: 0.50910 Train Acc: 0.77707\n",
      "Epoch: 16/100 Iteration: 308 Training loss: 0.51304 Train Acc: 0.78662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16/100 Iteration: 309 Training loss: 0.51319 Train Acc: 0.78742\n",
      "Epoch: 16/100 Iteration: 310 Validation Acc: 0.7962\n",
      "Epoch: 16/100 Iteration: 310 Training loss: 0.49784 Train Acc: 0.79936\n",
      "Epoch: 16/100 Iteration: 311 Training loss: 0.48717 Train Acc: 0.80653\n",
      "Epoch: 16/100 Iteration: 312 Training loss: 0.46670 Train Acc: 0.80334\n",
      "Epoch: 16/100 Iteration: 313 Training loss: 0.49068 Train Acc: 0.79857\n",
      "Epoch: 16/100 Iteration: 314 Training loss: 0.49709 Train Acc: 0.77627\n",
      "Epoch: 16/100 Iteration: 315 Validation Acc: 0.7803\n",
      "Epoch: 16/100 Iteration: 315 Training loss: 0.48728 Train Acc: 0.78822\n",
      "Epoch: 16/100 Iteration: 316 Training loss: 0.53257 Train Acc: 0.76752\n",
      "Epoch: 16/100 Iteration: 317 Training loss: 0.51195 Train Acc: 0.76752\n",
      "Epoch: 16/100 Iteration: 318 Training loss: 0.51254 Train Acc: 0.76433\n",
      "Epoch: 16/100 Iteration: 319 Training loss: 0.51575 Train Acc: 0.76990\n",
      "Epoch: 16/100 Iteration: 320 Validation Acc: 0.7803\n",
      "Epoch: 17/100 Iteration: 320 Training loss: 0.52702 Train Acc: 0.78503\n",
      "Epoch: 17/100 Iteration: 321 Training loss: 0.49486 Train Acc: 0.78742\n",
      "Epoch: 17/100 Iteration: 322 Training loss: 0.49481 Train Acc: 0.78901\n",
      "Epoch: 17/100 Iteration: 323 Training loss: 0.49975 Train Acc: 0.80732\n",
      "Epoch: 17/100 Iteration: 324 Training loss: 0.49037 Train Acc: 0.80016\n",
      "Epoch: 17/100 Iteration: 325 Validation Acc: 0.7930\n",
      "Epoch: 17/100 Iteration: 325 Training loss: 0.50056 Train Acc: 0.81210\n",
      "Epoch: 17/100 Iteration: 326 Training loss: 0.49220 Train Acc: 0.79220\n",
      "Epoch: 17/100 Iteration: 327 Training loss: 0.51367 Train Acc: 0.79299\n",
      "Epoch: 17/100 Iteration: 328 Training loss: 0.48479 Train Acc: 0.78583\n",
      "Epoch: 17/100 Iteration: 329 Training loss: 0.50375 Train Acc: 0.79379\n",
      "Epoch: 17/100 Iteration: 330 Validation Acc: 0.7890\n",
      "Epoch: 17/100 Iteration: 330 Training loss: 0.50528 Train Acc: 0.80016\n",
      "Epoch: 17/100 Iteration: 331 Training loss: 0.48619 Train Acc: 0.79936\n",
      "Epoch: 17/100 Iteration: 332 Training loss: 0.48295 Train Acc: 0.78742\n",
      "Epoch: 17/100 Iteration: 333 Training loss: 0.49322 Train Acc: 0.79538\n",
      "Epoch: 17/100 Iteration: 334 Training loss: 0.50011 Train Acc: 0.79857\n",
      "Epoch: 17/100 Iteration: 335 Validation Acc: 0.7763\n",
      "Epoch: 17/100 Iteration: 335 Training loss: 0.49639 Train Acc: 0.79299\n",
      "Epoch: 17/100 Iteration: 336 Training loss: 0.48951 Train Acc: 0.79618\n",
      "Epoch: 17/100 Iteration: 337 Training loss: 0.46763 Train Acc: 0.81051\n",
      "Epoch: 17/100 Iteration: 338 Training loss: 0.47608 Train Acc: 0.79777\n",
      "Epoch: 17/100 Iteration: 339 Training loss: 0.47632 Train Acc: 0.80653\n",
      "Epoch: 17/100 Iteration: 340 Validation Acc: 0.7962\n",
      "Epoch: 18/100 Iteration: 340 Training loss: 0.48812 Train Acc: 0.81369\n",
      "Epoch: 18/100 Iteration: 341 Training loss: 0.48997 Train Acc: 0.81608\n",
      "Epoch: 18/100 Iteration: 342 Training loss: 0.46241 Train Acc: 0.79936\n",
      "Epoch: 18/100 Iteration: 343 Training loss: 0.48732 Train Acc: 0.80573\n",
      "Epoch: 18/100 Iteration: 344 Training loss: 0.45581 Train Acc: 0.81051\n",
      "Epoch: 18/100 Iteration: 345 Validation Acc: 0.8065\n",
      "Epoch: 18/100 Iteration: 345 Training loss: 0.49659 Train Acc: 0.80096\n",
      "Epoch: 18/100 Iteration: 346 Training loss: 0.48110 Train Acc: 0.80653\n",
      "Epoch: 18/100 Iteration: 347 Training loss: 0.49907 Train Acc: 0.79618\n",
      "Epoch: 18/100 Iteration: 348 Training loss: 0.45848 Train Acc: 0.80892\n",
      "Epoch: 18/100 Iteration: 349 Training loss: 0.51233 Train Acc: 0.81369\n",
      "Epoch: 18/100 Iteration: 350 Validation Acc: 0.8105\n",
      "Epoch: 18/100 Iteration: 350 Training loss: 0.47926 Train Acc: 0.81131\n",
      "Epoch: 18/100 Iteration: 351 Training loss: 0.46684 Train Acc: 0.79936\n",
      "Epoch: 18/100 Iteration: 352 Training loss: 0.46410 Train Acc: 0.79140\n",
      "Epoch: 18/100 Iteration: 353 Training loss: 0.45704 Train Acc: 0.79936\n",
      "Epoch: 18/100 Iteration: 354 Training loss: 0.50410 Train Acc: 0.79459\n",
      "Epoch: 18/100 Iteration: 355 Validation Acc: 0.8033\n",
      "Epoch: 18/100 Iteration: 355 Training loss: 0.51218 Train Acc: 0.79777\n",
      "Epoch: 18/100 Iteration: 356 Training loss: 0.54007 Train Acc: 0.81369\n",
      "Epoch: 18/100 Iteration: 357 Training loss: 0.49463 Train Acc: 0.80096\n",
      "Epoch: 18/100 Iteration: 358 Training loss: 0.48319 Train Acc: 0.80096\n",
      "Epoch: 18/100 Iteration: 359 Training loss: 0.48084 Train Acc: 0.80812\n",
      "Epoch: 18/100 Iteration: 360 Validation Acc: 0.8010\n",
      "Epoch: 19/100 Iteration: 360 Training loss: 0.51360 Train Acc: 0.81210\n",
      "Epoch: 19/100 Iteration: 361 Training loss: 0.50062 Train Acc: 0.81529\n",
      "Epoch: 19/100 Iteration: 362 Training loss: 0.47123 Train Acc: 0.81051\n",
      "Epoch: 19/100 Iteration: 363 Training loss: 0.47712 Train Acc: 0.81688\n",
      "Epoch: 19/100 Iteration: 364 Training loss: 0.42795 Train Acc: 0.81210\n",
      "Epoch: 19/100 Iteration: 365 Validation Acc: 0.8057\n",
      "Epoch: 19/100 Iteration: 365 Training loss: 0.47844 Train Acc: 0.81210\n",
      "Epoch: 19/100 Iteration: 366 Training loss: 0.47720 Train Acc: 0.81051\n",
      "Epoch: 19/100 Iteration: 367 Training loss: 0.50150 Train Acc: 0.80971\n",
      "Epoch: 19/100 Iteration: 368 Training loss: 0.46074 Train Acc: 0.80494\n",
      "Epoch: 19/100 Iteration: 369 Training loss: 0.47204 Train Acc: 0.80494\n",
      "Epoch: 19/100 Iteration: 370 Validation Acc: 0.8033\n",
      "Epoch: 19/100 Iteration: 370 Training loss: 0.45548 Train Acc: 0.80971\n",
      "Epoch: 19/100 Iteration: 371 Training loss: 0.46540 Train Acc: 0.81369\n",
      "Epoch: 19/100 Iteration: 372 Training loss: 0.49005 Train Acc: 0.80255\n",
      "Epoch: 19/100 Iteration: 373 Training loss: 0.48308 Train Acc: 0.80653\n",
      "Epoch: 19/100 Iteration: 374 Training loss: 0.49089 Train Acc: 0.80334\n",
      "Epoch: 19/100 Iteration: 375 Validation Acc: 0.8065\n",
      "Epoch: 19/100 Iteration: 375 Training loss: 0.47119 Train Acc: 0.79857\n",
      "Epoch: 19/100 Iteration: 376 Training loss: 0.50612 Train Acc: 0.80255\n",
      "Epoch: 19/100 Iteration: 377 Training loss: 0.48882 Train Acc: 0.81131\n",
      "Epoch: 19/100 Iteration: 378 Training loss: 0.46551 Train Acc: 0.81051\n",
      "Epoch: 19/100 Iteration: 379 Training loss: 0.46462 Train Acc: 0.79220\n",
      "Epoch: 19/100 Iteration: 380 Validation Acc: 0.7954\n",
      "Epoch: 20/100 Iteration: 380 Training loss: 0.48407 Train Acc: 0.79618\n",
      "Epoch: 20/100 Iteration: 381 Training loss: 0.48602 Train Acc: 0.78901\n",
      "Epoch: 20/100 Iteration: 382 Training loss: 0.48039 Train Acc: 0.77070\n",
      "Epoch: 20/100 Iteration: 383 Training loss: 0.50235 Train Acc: 0.79618\n",
      "Epoch: 20/100 Iteration: 384 Training loss: 0.46362 Train Acc: 0.80096\n",
      "Epoch: 20/100 Iteration: 385 Validation Acc: 0.8041\n",
      "Epoch: 20/100 Iteration: 385 Training loss: 0.48840 Train Acc: 0.80016\n",
      "Epoch: 20/100 Iteration: 386 Training loss: 0.51077 Train Acc: 0.80573\n",
      "Epoch: 20/100 Iteration: 387 Training loss: 0.46515 Train Acc: 0.81051\n",
      "Epoch: 20/100 Iteration: 388 Training loss: 0.48002 Train Acc: 0.80414\n",
      "Epoch: 20/100 Iteration: 389 Training loss: 0.49781 Train Acc: 0.81290\n",
      "Epoch: 20/100 Iteration: 390 Validation Acc: 0.8089\n",
      "Epoch: 20/100 Iteration: 390 Training loss: 0.48470 Train Acc: 0.79459\n",
      "Epoch: 20/100 Iteration: 391 Training loss: 0.48229 Train Acc: 0.80494\n",
      "Epoch: 20/100 Iteration: 392 Training loss: 0.45810 Train Acc: 0.80334\n",
      "Epoch: 20/100 Iteration: 393 Training loss: 0.45880 Train Acc: 0.80494\n",
      "Epoch: 20/100 Iteration: 394 Training loss: 0.47712 Train Acc: 0.80573\n",
      "Epoch: 20/100 Iteration: 395 Validation Acc: 0.8081\n",
      "Epoch: 20/100 Iteration: 395 Training loss: 0.46929 Train Acc: 0.79220\n",
      "Epoch: 20/100 Iteration: 396 Training loss: 0.51372 Train Acc: 0.80096\n",
      "Epoch: 20/100 Iteration: 397 Training loss: 0.43597 Train Acc: 0.78822\n",
      "Epoch: 20/100 Iteration: 398 Training loss: 0.48648 Train Acc: 0.80892\n",
      "Epoch: 20/100 Iteration: 399 Training loss: 0.47186 Train Acc: 0.80732\n",
      "Epoch: 20/100 Iteration: 400 Validation Acc: 0.8010\n",
      "Epoch: 21/100 Iteration: 400 Training loss: 0.45768 Train Acc: 0.80971\n",
      "Epoch: 21/100 Iteration: 401 Training loss: 0.50566 Train Acc: 0.79618\n",
      "Epoch: 21/100 Iteration: 402 Training loss: 0.46731 Train Acc: 0.78264\n",
      "Epoch: 21/100 Iteration: 403 Training loss: 0.45726 Train Acc: 0.79697\n",
      "Epoch: 21/100 Iteration: 404 Training loss: 0.45620 Train Acc: 0.78981\n",
      "Epoch: 21/100 Iteration: 405 Validation Acc: 0.8049\n",
      "Epoch: 21/100 Iteration: 405 Training loss: 0.49255 Train Acc: 0.79936\n",
      "Epoch: 21/100 Iteration: 406 Training loss: 0.50900 Train Acc: 0.81449\n",
      "Epoch: 21/100 Iteration: 407 Training loss: 0.49959 Train Acc: 0.80175\n",
      "Epoch: 21/100 Iteration: 408 Training loss: 0.43624 Train Acc: 0.81051\n",
      "Epoch: 21/100 Iteration: 409 Training loss: 0.48922 Train Acc: 0.80016\n",
      "Epoch: 21/100 Iteration: 410 Validation Acc: 0.8081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21/100 Iteration: 410 Training loss: 0.46210 Train Acc: 0.81768\n",
      "Epoch: 21/100 Iteration: 411 Training loss: 0.47740 Train Acc: 0.80334\n",
      "Epoch: 21/100 Iteration: 412 Training loss: 0.46572 Train Acc: 0.80494\n",
      "Epoch: 21/100 Iteration: 413 Training loss: 0.47269 Train Acc: 0.80892\n",
      "Epoch: 21/100 Iteration: 414 Training loss: 0.47284 Train Acc: 0.80096\n",
      "Epoch: 21/100 Iteration: 415 Validation Acc: 0.8169\n",
      "Epoch: 21/100 Iteration: 415 Training loss: 0.48180 Train Acc: 0.80096\n",
      "Epoch: 21/100 Iteration: 416 Training loss: 0.50340 Train Acc: 0.80494\n",
      "Epoch: 21/100 Iteration: 417 Training loss: 0.44586 Train Acc: 0.80971\n",
      "Epoch: 21/100 Iteration: 418 Training loss: 0.46276 Train Acc: 0.80971\n",
      "Epoch: 21/100 Iteration: 419 Training loss: 0.47381 Train Acc: 0.81290\n",
      "Epoch: 21/100 Iteration: 420 Validation Acc: 0.8018\n",
      "Epoch: 22/100 Iteration: 420 Training loss: 0.47959 Train Acc: 0.81529\n",
      "Epoch: 22/100 Iteration: 421 Training loss: 0.45740 Train Acc: 0.80971\n",
      "Epoch: 22/100 Iteration: 422 Training loss: 0.46753 Train Acc: 0.82404\n",
      "Epoch: 22/100 Iteration: 423 Training loss: 0.46785 Train Acc: 0.81051\n",
      "Epoch: 22/100 Iteration: 424 Training loss: 0.45259 Train Acc: 0.80573\n",
      "Epoch: 22/100 Iteration: 425 Validation Acc: 0.7954\n",
      "Epoch: 22/100 Iteration: 425 Training loss: 0.48288 Train Acc: 0.81688\n",
      "Epoch: 22/100 Iteration: 426 Training loss: 0.47720 Train Acc: 0.80812\n",
      "Epoch: 22/100 Iteration: 427 Training loss: 0.47646 Train Acc: 0.81449\n",
      "Epoch: 22/100 Iteration: 428 Training loss: 0.45617 Train Acc: 0.80812\n",
      "Epoch: 22/100 Iteration: 429 Training loss: 0.47187 Train Acc: 0.80971\n",
      "Epoch: 22/100 Iteration: 430 Validation Acc: 0.8153\n",
      "Epoch: 22/100 Iteration: 430 Training loss: 0.47243 Train Acc: 0.79857\n",
      "Epoch: 22/100 Iteration: 431 Training loss: 0.47353 Train Acc: 0.80653\n",
      "Epoch: 22/100 Iteration: 432 Training loss: 0.45809 Train Acc: 0.80414\n",
      "Epoch: 22/100 Iteration: 433 Training loss: 0.46286 Train Acc: 0.81369\n",
      "Epoch: 22/100 Iteration: 434 Training loss: 0.50110 Train Acc: 0.82006\n",
      "Epoch: 22/100 Iteration: 435 Validation Acc: 0.8121\n",
      "Epoch: 22/100 Iteration: 435 Training loss: 0.45871 Train Acc: 0.82643\n",
      "Epoch: 22/100 Iteration: 436 Training loss: 0.50643 Train Acc: 0.82086\n",
      "Epoch: 22/100 Iteration: 437 Training loss: 0.46167 Train Acc: 0.81688\n",
      "Epoch: 22/100 Iteration: 438 Training loss: 0.45573 Train Acc: 0.80414\n",
      "Epoch: 22/100 Iteration: 439 Training loss: 0.45094 Train Acc: 0.82723\n",
      "Epoch: 22/100 Iteration: 440 Validation Acc: 0.8217\n",
      "Epoch: 23/100 Iteration: 440 Training loss: 0.48865 Train Acc: 0.81608\n",
      "Epoch: 23/100 Iteration: 441 Training loss: 0.46534 Train Acc: 0.81847\n",
      "Epoch: 23/100 Iteration: 442 Training loss: 0.46037 Train Acc: 0.81210\n",
      "Epoch: 23/100 Iteration: 443 Training loss: 0.43457 Train Acc: 0.81768\n",
      "Epoch: 23/100 Iteration: 444 Training loss: 0.41890 Train Acc: 0.83360\n",
      "Epoch: 23/100 Iteration: 445 Validation Acc: 0.8145\n",
      "Epoch: 23/100 Iteration: 445 Training loss: 0.46784 Train Acc: 0.82325\n",
      "Epoch: 23/100 Iteration: 446 Training loss: 0.45399 Train Acc: 0.82404\n",
      "Epoch: 23/100 Iteration: 447 Training loss: 0.44679 Train Acc: 0.81688\n",
      "Epoch: 23/100 Iteration: 448 Training loss: 0.44125 Train Acc: 0.82723\n",
      "Epoch: 23/100 Iteration: 449 Training loss: 0.46351 Train Acc: 0.82882\n",
      "Epoch: 23/100 Iteration: 450 Validation Acc: 0.8137\n",
      "Epoch: 23/100 Iteration: 450 Training loss: 0.44520 Train Acc: 0.82245\n",
      "Epoch: 23/100 Iteration: 451 Training loss: 0.46503 Train Acc: 0.82166\n",
      "Epoch: 23/100 Iteration: 452 Training loss: 0.46969 Train Acc: 0.82245\n",
      "Epoch: 23/100 Iteration: 453 Training loss: 0.44834 Train Acc: 0.82006\n",
      "Epoch: 23/100 Iteration: 454 Training loss: 0.47385 Train Acc: 0.81449\n",
      "Epoch: 23/100 Iteration: 455 Validation Acc: 0.8177\n",
      "Epoch: 23/100 Iteration: 455 Training loss: 0.45859 Train Acc: 0.81210\n",
      "Epoch: 23/100 Iteration: 456 Training loss: 0.50174 Train Acc: 0.81051\n",
      "Epoch: 23/100 Iteration: 457 Training loss: 0.44288 Train Acc: 0.81369\n",
      "Epoch: 23/100 Iteration: 458 Training loss: 0.48836 Train Acc: 0.79777\n",
      "Epoch: 23/100 Iteration: 459 Training loss: 0.45328 Train Acc: 0.81369\n",
      "Epoch: 23/100 Iteration: 460 Validation Acc: 0.8073\n",
      "Epoch: 24/100 Iteration: 460 Training loss: 0.47759 Train Acc: 0.80414\n",
      "Epoch: 24/100 Iteration: 461 Training loss: 0.46118 Train Acc: 0.81290\n",
      "Epoch: 24/100 Iteration: 462 Training loss: 0.43453 Train Acc: 0.81608\n",
      "Epoch: 24/100 Iteration: 463 Training loss: 0.45296 Train Acc: 0.81847\n",
      "Epoch: 24/100 Iteration: 464 Training loss: 0.41097 Train Acc: 0.81051\n",
      "Epoch: 24/100 Iteration: 465 Validation Acc: 0.8240\n",
      "Epoch: 24/100 Iteration: 465 Training loss: 0.47628 Train Acc: 0.81210\n",
      "Epoch: 24/100 Iteration: 466 Training loss: 0.50432 Train Acc: 0.81608\n",
      "Epoch: 24/100 Iteration: 467 Training loss: 0.47125 Train Acc: 0.81369\n",
      "Epoch: 24/100 Iteration: 468 Training loss: 0.43740 Train Acc: 0.83121\n",
      "Epoch: 24/100 Iteration: 469 Training loss: 0.45207 Train Acc: 0.82086\n",
      "Epoch: 24/100 Iteration: 470 Validation Acc: 0.8217\n",
      "Epoch: 24/100 Iteration: 470 Training loss: 0.44139 Train Acc: 0.82564\n",
      "Epoch: 24/100 Iteration: 471 Training loss: 0.46335 Train Acc: 0.83041\n",
      "Epoch: 24/100 Iteration: 472 Training loss: 0.43203 Train Acc: 0.81290\n",
      "Epoch: 24/100 Iteration: 473 Training loss: 0.44151 Train Acc: 0.81369\n",
      "Epoch: 24/100 Iteration: 474 Training loss: 0.45272 Train Acc: 0.82006\n",
      "Epoch: 24/100 Iteration: 475 Validation Acc: 0.8272\n",
      "Epoch: 24/100 Iteration: 475 Training loss: 0.45861 Train Acc: 0.81927\n",
      "Epoch: 24/100 Iteration: 476 Training loss: 0.50170 Train Acc: 0.82245\n",
      "Epoch: 24/100 Iteration: 477 Training loss: 0.44464 Train Acc: 0.83280\n",
      "Epoch: 24/100 Iteration: 478 Training loss: 0.43556 Train Acc: 0.82245\n",
      "Epoch: 24/100 Iteration: 479 Training loss: 0.45045 Train Acc: 0.82643\n",
      "Epoch: 24/100 Iteration: 480 Validation Acc: 0.8352\n",
      "Epoch: 25/100 Iteration: 480 Training loss: 0.44925 Train Acc: 0.83280\n",
      "Epoch: 25/100 Iteration: 481 Training loss: 0.45343 Train Acc: 0.83917\n",
      "Epoch: 25/100 Iteration: 482 Training loss: 0.44520 Train Acc: 0.84475\n",
      "Epoch: 25/100 Iteration: 483 Training loss: 0.43543 Train Acc: 0.84076\n",
      "Epoch: 25/100 Iteration: 484 Training loss: 0.42368 Train Acc: 0.82325\n",
      "Epoch: 25/100 Iteration: 485 Validation Acc: 0.8352\n",
      "Epoch: 25/100 Iteration: 485 Training loss: 0.47678 Train Acc: 0.82404\n",
      "Epoch: 25/100 Iteration: 486 Training loss: 0.45934 Train Acc: 0.83997\n",
      "Epoch: 25/100 Iteration: 487 Training loss: 0.46432 Train Acc: 0.82882\n",
      "Epoch: 25/100 Iteration: 488 Training loss: 0.44941 Train Acc: 0.82484\n",
      "Epoch: 25/100 Iteration: 489 Training loss: 0.46439 Train Acc: 0.82245\n",
      "Epoch: 25/100 Iteration: 490 Validation Acc: 0.8296\n",
      "Epoch: 25/100 Iteration: 490 Training loss: 0.46179 Train Acc: 0.82086\n",
      "Epoch: 25/100 Iteration: 491 Training loss: 0.47110 Train Acc: 0.83041\n",
      "Epoch: 25/100 Iteration: 492 Training loss: 0.47091 Train Acc: 0.82166\n",
      "Epoch: 25/100 Iteration: 493 Training loss: 0.43918 Train Acc: 0.82325\n",
      "Epoch: 25/100 Iteration: 494 Training loss: 0.49527 Train Acc: 0.81688\n",
      "Epoch: 25/100 Iteration: 495 Validation Acc: 0.8121\n",
      "Epoch: 25/100 Iteration: 495 Training loss: 0.45354 Train Acc: 0.81449\n",
      "Epoch: 25/100 Iteration: 496 Training loss: 0.51551 Train Acc: 0.81768\n",
      "Epoch: 25/100 Iteration: 497 Training loss: 0.44743 Train Acc: 0.81927\n",
      "Epoch: 25/100 Iteration: 498 Training loss: 0.46785 Train Acc: 0.82006\n",
      "Epoch: 25/100 Iteration: 499 Training loss: 0.45237 Train Acc: 0.81608\n",
      "Epoch: 25/100 Iteration: 500 Validation Acc: 0.8169\n",
      "Epoch: 26/100 Iteration: 500 Training loss: 0.46775 Train Acc: 0.82484\n",
      "Epoch: 26/100 Iteration: 501 Training loss: 0.45924 Train Acc: 0.82803\n",
      "Epoch: 26/100 Iteration: 502 Training loss: 0.44741 Train Acc: 0.83201\n",
      "Epoch: 26/100 Iteration: 503 Training loss: 0.44727 Train Acc: 0.82404\n",
      "Epoch: 26/100 Iteration: 504 Training loss: 0.44757 Train Acc: 0.81051\n",
      "Epoch: 26/100 Iteration: 505 Validation Acc: 0.8161\n",
      "Epoch: 26/100 Iteration: 505 Training loss: 0.47292 Train Acc: 0.81369\n",
      "Epoch: 26/100 Iteration: 506 Training loss: 0.47271 Train Acc: 0.80653\n",
      "Epoch: 26/100 Iteration: 507 Training loss: 0.46004 Train Acc: 0.82086\n",
      "Epoch: 26/100 Iteration: 508 Training loss: 0.43261 Train Acc: 0.80653\n",
      "Epoch: 26/100 Iteration: 509 Training loss: 0.47728 Train Acc: 0.81608\n",
      "Epoch: 26/100 Iteration: 510 Validation Acc: 0.8153\n",
      "Epoch: 26/100 Iteration: 510 Training loss: 0.45505 Train Acc: 0.81847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26/100 Iteration: 511 Training loss: 0.43392 Train Acc: 0.80414\n",
      "Epoch: 26/100 Iteration: 512 Training loss: 0.45280 Train Acc: 0.80175\n",
      "Epoch: 26/100 Iteration: 513 Training loss: 0.43574 Train Acc: 0.80096\n",
      "Epoch: 26/100 Iteration: 514 Training loss: 0.44868 Train Acc: 0.81369\n",
      "Epoch: 26/100 Iteration: 515 Validation Acc: 0.8217\n",
      "Epoch: 26/100 Iteration: 515 Training loss: 0.46419 Train Acc: 0.81051\n",
      "Epoch: 26/100 Iteration: 516 Training loss: 0.48274 Train Acc: 0.81847\n",
      "Epoch: 26/100 Iteration: 517 Training loss: 0.44392 Train Acc: 0.82166\n",
      "Epoch: 26/100 Iteration: 518 Training loss: 0.44208 Train Acc: 0.82245\n",
      "Epoch: 26/100 Iteration: 519 Training loss: 0.44097 Train Acc: 0.82882\n",
      "Epoch: 26/100 Iteration: 520 Validation Acc: 0.8185\n",
      "Epoch: 27/100 Iteration: 520 Training loss: 0.46438 Train Acc: 0.82006\n",
      "Epoch: 27/100 Iteration: 521 Training loss: 0.45505 Train Acc: 0.80892\n",
      "Epoch: 27/100 Iteration: 522 Training loss: 0.44806 Train Acc: 0.82166\n",
      "Epoch: 27/100 Iteration: 523 Training loss: 0.44244 Train Acc: 0.82564\n",
      "Epoch: 27/100 Iteration: 524 Training loss: 0.42619 Train Acc: 0.83917\n",
      "Epoch: 27/100 Iteration: 525 Validation Acc: 0.8256\n",
      "Epoch: 27/100 Iteration: 525 Training loss: 0.46492 Train Acc: 0.82962\n",
      "Epoch: 27/100 Iteration: 526 Training loss: 0.46800 Train Acc: 0.82484\n",
      "Epoch: 27/100 Iteration: 527 Training loss: 0.46853 Train Acc: 0.83280\n",
      "Epoch: 27/100 Iteration: 528 Training loss: 0.45096 Train Acc: 0.81927\n",
      "Epoch: 27/100 Iteration: 529 Training loss: 0.45686 Train Acc: 0.82404\n",
      "Epoch: 27/100 Iteration: 530 Validation Acc: 0.8193\n",
      "Epoch: 27/100 Iteration: 530 Training loss: 0.46863 Train Acc: 0.80334\n",
      "Epoch: 27/100 Iteration: 531 Training loss: 0.45764 Train Acc: 0.80334\n",
      "Epoch: 27/100 Iteration: 532 Training loss: 0.44702 Train Acc: 0.80494\n",
      "Epoch: 27/100 Iteration: 533 Training loss: 0.48653 Train Acc: 0.80971\n",
      "Epoch: 27/100 Iteration: 534 Training loss: 0.48830 Train Acc: 0.80812\n",
      "Epoch: 27/100 Iteration: 535 Validation Acc: 0.8256\n",
      "Epoch: 27/100 Iteration: 535 Training loss: 0.46714 Train Acc: 0.81847\n",
      "Epoch: 27/100 Iteration: 536 Training loss: 0.47807 Train Acc: 0.82564\n",
      "Epoch: 27/100 Iteration: 537 Training loss: 0.40435 Train Acc: 0.82166\n",
      "Epoch: 27/100 Iteration: 538 Training loss: 0.45167 Train Acc: 0.82643\n",
      "Epoch: 27/100 Iteration: 539 Training loss: 0.43605 Train Acc: 0.81608\n",
      "Epoch: 27/100 Iteration: 540 Validation Acc: 0.8177\n",
      "Epoch: 28/100 Iteration: 540 Training loss: 0.46708 Train Acc: 0.82962\n",
      "Epoch: 28/100 Iteration: 541 Training loss: 0.47593 Train Acc: 0.80732\n",
      "Epoch: 28/100 Iteration: 542 Training loss: 0.43391 Train Acc: 0.83121\n",
      "Epoch: 28/100 Iteration: 543 Training loss: 0.42999 Train Acc: 0.82166\n",
      "Epoch: 28/100 Iteration: 544 Training loss: 0.43463 Train Acc: 0.83121\n",
      "Epoch: 28/100 Iteration: 545 Validation Acc: 0.8248\n",
      "Epoch: 28/100 Iteration: 545 Training loss: 0.49208 Train Acc: 0.82723\n",
      "Epoch: 28/100 Iteration: 546 Training loss: 0.47133 Train Acc: 0.83041\n",
      "Epoch: 28/100 Iteration: 547 Training loss: 0.47661 Train Acc: 0.82803\n",
      "Epoch: 28/100 Iteration: 548 Training loss: 0.45839 Train Acc: 0.83121\n",
      "Epoch: 28/100 Iteration: 549 Training loss: 0.46808 Train Acc: 0.84156\n",
      "Epoch: 28/100 Iteration: 550 Validation Acc: 0.8232\n",
      "Epoch: 28/100 Iteration: 550 Training loss: 0.42752 Train Acc: 0.83041\n",
      "Epoch: 28/100 Iteration: 551 Training loss: 0.44747 Train Acc: 0.82882\n",
      "Epoch: 28/100 Iteration: 552 Training loss: 0.46268 Train Acc: 0.80892\n",
      "Epoch: 28/100 Iteration: 553 Training loss: 0.46380 Train Acc: 0.82643\n",
      "Epoch: 28/100 Iteration: 554 Training loss: 0.46945 Train Acc: 0.82006\n",
      "Epoch: 28/100 Iteration: 555 Validation Acc: 0.8193\n",
      "Epoch: 28/100 Iteration: 555 Training loss: 0.47660 Train Acc: 0.82564\n",
      "Epoch: 28/100 Iteration: 556 Training loss: 0.47210 Train Acc: 0.84713\n",
      "Epoch: 28/100 Iteration: 557 Training loss: 0.45055 Train Acc: 0.83360\n",
      "Epoch: 28/100 Iteration: 558 Training loss: 0.41878 Train Acc: 0.83599\n",
      "Epoch: 28/100 Iteration: 559 Training loss: 0.43716 Train Acc: 0.82962\n",
      "Epoch: 28/100 Iteration: 560 Validation Acc: 0.8463\n",
      "Epoch: 29/100 Iteration: 560 Training loss: 0.45820 Train Acc: 0.84475\n",
      "Epoch: 29/100 Iteration: 561 Training loss: 0.45245 Train Acc: 0.82803\n",
      "Epoch: 29/100 Iteration: 562 Training loss: 0.42251 Train Acc: 0.82723\n",
      "Epoch: 29/100 Iteration: 563 Training loss: 0.44777 Train Acc: 0.81608\n",
      "Epoch: 29/100 Iteration: 564 Training loss: 0.42756 Train Acc: 0.83280\n",
      "Epoch: 29/100 Iteration: 565 Validation Acc: 0.8296\n",
      "Epoch: 29/100 Iteration: 565 Training loss: 0.46182 Train Acc: 0.83201\n",
      "Epoch: 29/100 Iteration: 566 Training loss: 0.46212 Train Acc: 0.83519\n",
      "Epoch: 29/100 Iteration: 567 Training loss: 0.46255 Train Acc: 0.82245\n",
      "Epoch: 29/100 Iteration: 568 Training loss: 0.45740 Train Acc: 0.83678\n",
      "Epoch: 29/100 Iteration: 569 Training loss: 0.46818 Train Acc: 0.82404\n",
      "Epoch: 29/100 Iteration: 570 Validation Acc: 0.8352\n",
      "Epoch: 29/100 Iteration: 570 Training loss: 0.44284 Train Acc: 0.82325\n",
      "Epoch: 29/100 Iteration: 571 Training loss: 0.44963 Train Acc: 0.83201\n",
      "Epoch: 29/100 Iteration: 572 Training loss: 0.45374 Train Acc: 0.80892\n",
      "Epoch: 29/100 Iteration: 573 Training loss: 0.43450 Train Acc: 0.81529\n",
      "Epoch: 29/100 Iteration: 574 Training loss: 0.48673 Train Acc: 0.81449\n",
      "Epoch: 29/100 Iteration: 575 Validation Acc: 0.8129\n",
      "Epoch: 29/100 Iteration: 575 Training loss: 0.46639 Train Acc: 0.82484\n",
      "Epoch: 29/100 Iteration: 576 Training loss: 0.47422 Train Acc: 0.83678\n",
      "Epoch: 29/100 Iteration: 577 Training loss: 0.47458 Train Acc: 0.82325\n",
      "Epoch: 29/100 Iteration: 578 Training loss: 0.45553 Train Acc: 0.83201\n",
      "Epoch: 29/100 Iteration: 579 Training loss: 0.42013 Train Acc: 0.83917\n",
      "Epoch: 29/100 Iteration: 580 Validation Acc: 0.8232\n",
      "Epoch: 30/100 Iteration: 580 Training loss: 0.45044 Train Acc: 0.82882\n",
      "Epoch: 30/100 Iteration: 581 Training loss: 0.46630 Train Acc: 0.81927\n",
      "Epoch: 30/100 Iteration: 582 Training loss: 0.45920 Train Acc: 0.83997\n",
      "Epoch: 30/100 Iteration: 583 Training loss: 0.44127 Train Acc: 0.83280\n",
      "Epoch: 30/100 Iteration: 584 Training loss: 0.41820 Train Acc: 0.82882\n",
      "Epoch: 30/100 Iteration: 585 Validation Acc: 0.8416\n",
      "Epoch: 30/100 Iteration: 585 Training loss: 0.48180 Train Acc: 0.83758\n",
      "Epoch: 30/100 Iteration: 586 Training loss: 0.45983 Train Acc: 0.83121\n",
      "Epoch: 30/100 Iteration: 587 Training loss: 0.45621 Train Acc: 0.83838\n",
      "Epoch: 30/100 Iteration: 588 Training loss: 0.45090 Train Acc: 0.85032\n",
      "Epoch: 30/100 Iteration: 589 Training loss: 0.46683 Train Acc: 0.84713\n",
      "Epoch: 30/100 Iteration: 590 Validation Acc: 0.8209\n",
      "Epoch: 30/100 Iteration: 590 Training loss: 0.46096 Train Acc: 0.84315\n",
      "Epoch: 30/100 Iteration: 591 Training loss: 0.43282 Train Acc: 0.82962\n",
      "Epoch: 30/100 Iteration: 592 Training loss: 0.46441 Train Acc: 0.83360\n",
      "Epoch: 30/100 Iteration: 593 Training loss: 0.43308 Train Acc: 0.83439\n",
      "Epoch: 30/100 Iteration: 594 Training loss: 0.46982 Train Acc: 0.85111\n",
      "Epoch: 30/100 Iteration: 595 Validation Acc: 0.8376\n",
      "Epoch: 30/100 Iteration: 595 Training loss: 0.45910 Train Acc: 0.84713\n",
      "Epoch: 30/100 Iteration: 596 Training loss: 0.46348 Train Acc: 0.83360\n",
      "Epoch: 30/100 Iteration: 597 Training loss: 0.42152 Train Acc: 0.83280\n",
      "Epoch: 30/100 Iteration: 598 Training loss: 0.44393 Train Acc: 0.84475\n",
      "Epoch: 30/100 Iteration: 599 Training loss: 0.42953 Train Acc: 0.83997\n",
      "Epoch: 30/100 Iteration: 600 Validation Acc: 0.8296\n",
      "Epoch: 31/100 Iteration: 600 Training loss: 0.45216 Train Acc: 0.84634\n",
      "Epoch: 31/100 Iteration: 601 Training loss: 0.44314 Train Acc: 0.84315\n",
      "Epoch: 31/100 Iteration: 602 Training loss: 0.42682 Train Acc: 0.83360\n",
      "Epoch: 31/100 Iteration: 603 Training loss: 0.42396 Train Acc: 0.84793\n",
      "Epoch: 31/100 Iteration: 604 Training loss: 0.39566 Train Acc: 0.84076\n",
      "Epoch: 31/100 Iteration: 605 Validation Acc: 0.8455\n",
      "Epoch: 31/100 Iteration: 605 Training loss: 0.45476 Train Acc: 0.83838\n",
      "Epoch: 31/100 Iteration: 606 Training loss: 0.45468 Train Acc: 0.83041\n",
      "Epoch: 31/100 Iteration: 607 Training loss: 0.45652 Train Acc: 0.83360\n",
      "Epoch: 31/100 Iteration: 608 Training loss: 0.41492 Train Acc: 0.84236\n",
      "Epoch: 31/100 Iteration: 609 Training loss: 0.47292 Train Acc: 0.83201\n",
      "Epoch: 31/100 Iteration: 610 Validation Acc: 0.8288\n",
      "Epoch: 31/100 Iteration: 610 Training loss: 0.44500 Train Acc: 0.82006\n",
      "Epoch: 31/100 Iteration: 611 Training loss: 0.42553 Train Acc: 0.83599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31/100 Iteration: 612 Training loss: 0.43930 Train Acc: 0.82245\n",
      "Epoch: 31/100 Iteration: 613 Training loss: 0.42390 Train Acc: 0.83599\n",
      "Epoch: 31/100 Iteration: 614 Training loss: 0.47449 Train Acc: 0.83201\n",
      "Epoch: 31/100 Iteration: 615 Validation Acc: 0.8408\n",
      "Epoch: 31/100 Iteration: 615 Training loss: 0.44567 Train Acc: 0.83758\n",
      "Epoch: 31/100 Iteration: 616 Training loss: 0.44456 Train Acc: 0.83997\n",
      "Epoch: 31/100 Iteration: 617 Training loss: 0.44033 Train Acc: 0.84076\n",
      "Epoch: 31/100 Iteration: 618 Training loss: 0.43253 Train Acc: 0.83758\n",
      "Epoch: 31/100 Iteration: 619 Training loss: 0.42604 Train Acc: 0.83041\n",
      "Epoch: 31/100 Iteration: 620 Validation Acc: 0.8376\n",
      "Epoch: 32/100 Iteration: 620 Training loss: 0.45574 Train Acc: 0.82564\n",
      "Epoch: 32/100 Iteration: 621 Training loss: 0.46268 Train Acc: 0.84475\n",
      "Epoch: 32/100 Iteration: 622 Training loss: 0.43935 Train Acc: 0.82803\n",
      "Epoch: 32/100 Iteration: 623 Training loss: 0.43427 Train Acc: 0.83838\n",
      "Epoch: 32/100 Iteration: 624 Training loss: 0.41603 Train Acc: 0.83917\n",
      "Epoch: 32/100 Iteration: 625 Validation Acc: 0.8439\n",
      "Epoch: 32/100 Iteration: 625 Training loss: 0.46611 Train Acc: 0.83599\n",
      "Epoch: 32/100 Iteration: 626 Training loss: 0.45766 Train Acc: 0.84793\n",
      "Epoch: 32/100 Iteration: 627 Training loss: 0.44000 Train Acc: 0.84315\n",
      "Epoch: 32/100 Iteration: 628 Training loss: 0.41958 Train Acc: 0.83838\n",
      "Epoch: 32/100 Iteration: 629 Training loss: 0.44982 Train Acc: 0.84236\n",
      "Epoch: 32/100 Iteration: 630 Validation Acc: 0.8455\n",
      "Epoch: 32/100 Iteration: 630 Training loss: 0.45089 Train Acc: 0.84236\n",
      "Epoch: 32/100 Iteration: 631 Training loss: 0.41483 Train Acc: 0.84952\n",
      "Epoch: 32/100 Iteration: 632 Training loss: 0.43768 Train Acc: 0.81688\n",
      "Epoch: 32/100 Iteration: 633 Training loss: 0.43209 Train Acc: 0.82245\n",
      "Epoch: 32/100 Iteration: 634 Training loss: 0.48625 Train Acc: 0.83280\n",
      "Epoch: 32/100 Iteration: 635 Validation Acc: 0.8408\n",
      "Epoch: 32/100 Iteration: 635 Training loss: 0.42422 Train Acc: 0.84554\n",
      "Epoch: 32/100 Iteration: 636 Training loss: 0.46724 Train Acc: 0.84076\n",
      "Epoch: 32/100 Iteration: 637 Training loss: 0.43650 Train Acc: 0.84315\n",
      "Epoch: 32/100 Iteration: 638 Training loss: 0.43866 Train Acc: 0.84076\n",
      "Epoch: 32/100 Iteration: 639 Training loss: 0.42558 Train Acc: 0.84076\n",
      "Epoch: 32/100 Iteration: 640 Validation Acc: 0.8384\n",
      "Epoch: 33/100 Iteration: 640 Training loss: 0.45164 Train Acc: 0.82643\n",
      "Epoch: 33/100 Iteration: 641 Training loss: 0.45391 Train Acc: 0.84475\n",
      "Epoch: 33/100 Iteration: 642 Training loss: 0.43209 Train Acc: 0.83997\n",
      "Epoch: 33/100 Iteration: 643 Training loss: 0.41218 Train Acc: 0.85510\n",
      "Epoch: 33/100 Iteration: 644 Training loss: 0.40749 Train Acc: 0.85032\n",
      "Epoch: 33/100 Iteration: 645 Validation Acc: 0.8527\n",
      "Epoch: 33/100 Iteration: 645 Training loss: 0.45170 Train Acc: 0.85271\n",
      "Epoch: 33/100 Iteration: 646 Training loss: 0.44427 Train Acc: 0.84793\n",
      "Epoch: 33/100 Iteration: 647 Training loss: 0.42812 Train Acc: 0.83997\n",
      "Epoch: 33/100 Iteration: 648 Training loss: 0.44550 Train Acc: 0.83997\n",
      "Epoch: 33/100 Iteration: 649 Training loss: 0.47464 Train Acc: 0.83599\n",
      "Epoch: 33/100 Iteration: 650 Validation Acc: 0.8256\n",
      "Epoch: 33/100 Iteration: 650 Training loss: 0.43069 Train Acc: 0.83917\n",
      "Epoch: 33/100 Iteration: 651 Training loss: 0.43100 Train Acc: 0.82882\n",
      "Epoch: 33/100 Iteration: 652 Training loss: 0.45230 Train Acc: 0.83519\n",
      "Epoch: 33/100 Iteration: 653 Training loss: 0.44592 Train Acc: 0.83360\n",
      "Epoch: 33/100 Iteration: 654 Training loss: 0.45122 Train Acc: 0.83678\n",
      "Epoch: 33/100 Iteration: 655 Validation Acc: 0.8424\n",
      "Epoch: 33/100 Iteration: 655 Training loss: 0.44010 Train Acc: 0.83997\n",
      "Epoch: 33/100 Iteration: 656 Training loss: 0.45971 Train Acc: 0.83439\n",
      "Epoch: 33/100 Iteration: 657 Training loss: 0.41913 Train Acc: 0.84315\n",
      "Epoch: 33/100 Iteration: 658 Training loss: 0.42814 Train Acc: 0.84873\n",
      "Epoch: 33/100 Iteration: 659 Training loss: 0.43280 Train Acc: 0.83997\n",
      "Epoch: 33/100 Iteration: 660 Validation Acc: 0.8432\n",
      "Epoch: 34/100 Iteration: 660 Training loss: 0.45935 Train Acc: 0.83917\n",
      "Epoch: 34/100 Iteration: 661 Training loss: 0.43323 Train Acc: 0.84156\n",
      "Epoch: 34/100 Iteration: 662 Training loss: 0.42935 Train Acc: 0.83758\n",
      "Epoch: 34/100 Iteration: 663 Training loss: 0.44534 Train Acc: 0.83201\n",
      "Epoch: 34/100 Iteration: 664 Training loss: 0.38768 Train Acc: 0.84076\n",
      "Epoch: 34/100 Iteration: 665 Validation Acc: 0.8463\n",
      "Epoch: 34/100 Iteration: 665 Training loss: 0.45221 Train Acc: 0.83280\n",
      "Epoch: 34/100 Iteration: 666 Training loss: 0.45559 Train Acc: 0.84395\n",
      "Epoch: 34/100 Iteration: 667 Training loss: 0.47458 Train Acc: 0.83360\n",
      "Epoch: 34/100 Iteration: 668 Training loss: 0.43754 Train Acc: 0.82564\n",
      "Epoch: 34/100 Iteration: 669 Training loss: 0.48061 Train Acc: 0.83678\n",
      "Epoch: 34/100 Iteration: 670 Validation Acc: 0.8304\n",
      "Epoch: 34/100 Iteration: 670 Training loss: 0.46937 Train Acc: 0.83280\n",
      "Epoch: 34/100 Iteration: 671 Training loss: 0.43826 Train Acc: 0.82086\n",
      "Epoch: 34/100 Iteration: 672 Training loss: 0.45555 Train Acc: 0.82723\n",
      "Epoch: 34/100 Iteration: 673 Training loss: 0.42921 Train Acc: 0.82086\n",
      "Epoch: 34/100 Iteration: 674 Training loss: 0.47444 Train Acc: 0.83439\n",
      "Epoch: 34/100 Iteration: 675 Validation Acc: 0.8360\n",
      "Epoch: 34/100 Iteration: 675 Training loss: 0.47201 Train Acc: 0.82962\n",
      "Epoch: 34/100 Iteration: 676 Training loss: 0.46052 Train Acc: 0.83201\n",
      "Epoch: 34/100 Iteration: 677 Training loss: 0.42624 Train Acc: 0.83678\n",
      "Epoch: 34/100 Iteration: 678 Training loss: 0.45767 Train Acc: 0.82245\n",
      "Epoch: 34/100 Iteration: 679 Training loss: 0.43622 Train Acc: 0.83041\n",
      "Epoch: 34/100 Iteration: 680 Validation Acc: 0.8352\n",
      "Epoch: 35/100 Iteration: 680 Training loss: 0.44975 Train Acc: 0.82803\n",
      "Epoch: 35/100 Iteration: 681 Training loss: 0.45375 Train Acc: 0.83917\n",
      "Epoch: 35/100 Iteration: 682 Training loss: 0.44504 Train Acc: 0.83838\n",
      "Epoch: 35/100 Iteration: 683 Training loss: 0.45645 Train Acc: 0.84634\n",
      "Epoch: 35/100 Iteration: 684 Training loss: 0.43077 Train Acc: 0.85032\n",
      "Epoch: 35/100 Iteration: 685 Validation Acc: 0.8416\n",
      "Epoch: 35/100 Iteration: 685 Training loss: 0.44706 Train Acc: 0.85032\n",
      "Epoch: 35/100 Iteration: 686 Training loss: 0.47697 Train Acc: 0.85032\n",
      "Epoch: 35/100 Iteration: 687 Training loss: 0.43506 Train Acc: 0.84395\n",
      "Epoch: 35/100 Iteration: 688 Training loss: 0.42850 Train Acc: 0.85271\n",
      "Epoch: 35/100 Iteration: 689 Training loss: 0.45888 Train Acc: 0.83838\n",
      "Epoch: 35/100 Iteration: 690 Validation Acc: 0.8503\n",
      "Epoch: 35/100 Iteration: 690 Training loss: 0.43939 Train Acc: 0.84315\n",
      "Epoch: 35/100 Iteration: 691 Training loss: 0.41912 Train Acc: 0.83439\n",
      "Epoch: 35/100 Iteration: 692 Training loss: 0.42778 Train Acc: 0.83917\n",
      "Epoch: 35/100 Iteration: 693 Training loss: 0.44928 Train Acc: 0.83041\n",
      "Epoch: 35/100 Iteration: 694 Training loss: 0.44583 Train Acc: 0.83599\n",
      "Epoch: 35/100 Iteration: 695 Validation Acc: 0.8392\n",
      "Epoch: 35/100 Iteration: 695 Training loss: 0.44080 Train Acc: 0.84236\n",
      "Epoch: 35/100 Iteration: 696 Training loss: 0.47138 Train Acc: 0.84634\n",
      "Epoch: 35/100 Iteration: 697 Training loss: 0.41878 Train Acc: 0.85271\n",
      "Epoch: 35/100 Iteration: 698 Training loss: 0.43789 Train Acc: 0.84713\n",
      "Epoch: 35/100 Iteration: 699 Training loss: 0.41807 Train Acc: 0.85350\n",
      "Epoch: 35/100 Iteration: 700 Validation Acc: 0.8424\n",
      "Epoch: 36/100 Iteration: 700 Training loss: 0.44660 Train Acc: 0.84634\n",
      "Epoch: 36/100 Iteration: 701 Training loss: 0.43418 Train Acc: 0.85987\n",
      "Epoch: 36/100 Iteration: 702 Training loss: 0.42908 Train Acc: 0.84554\n",
      "Epoch: 36/100 Iteration: 703 Training loss: 0.43654 Train Acc: 0.84395\n",
      "Epoch: 36/100 Iteration: 704 Training loss: 0.39705 Train Acc: 0.85828\n",
      "Epoch: 36/100 Iteration: 705 Validation Acc: 0.8583\n",
      "Epoch: 36/100 Iteration: 705 Training loss: 0.44375 Train Acc: 0.85908\n",
      "Epoch: 36/100 Iteration: 706 Training loss: 0.44537 Train Acc: 0.86067\n",
      "Epoch: 36/100 Iteration: 707 Training loss: 0.44141 Train Acc: 0.86306\n",
      "Epoch: 36/100 Iteration: 708 Training loss: 0.41440 Train Acc: 0.85111\n",
      "Epoch: 36/100 Iteration: 709 Training loss: 0.43745 Train Acc: 0.85589\n",
      "Epoch: 36/100 Iteration: 710 Validation Acc: 0.8495\n",
      "Epoch: 36/100 Iteration: 710 Training loss: 0.41651 Train Acc: 0.85748\n",
      "Epoch: 36/100 Iteration: 711 Training loss: 0.42469 Train Acc: 0.84873\n",
      "Epoch: 36/100 Iteration: 712 Training loss: 0.42349 Train Acc: 0.86306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36/100 Iteration: 713 Training loss: 0.41638 Train Acc: 0.85908\n",
      "Epoch: 36/100 Iteration: 714 Training loss: 0.42488 Train Acc: 0.85828\n",
      "Epoch: 36/100 Iteration: 715 Validation Acc: 0.8487\n",
      "Epoch: 36/100 Iteration: 715 Training loss: 0.44438 Train Acc: 0.84952\n",
      "Epoch: 36/100 Iteration: 716 Training loss: 0.47398 Train Acc: 0.85589\n",
      "Epoch: 36/100 Iteration: 717 Training loss: 0.41655 Train Acc: 0.85032\n",
      "Epoch: 36/100 Iteration: 718 Training loss: 0.42215 Train Acc: 0.84076\n",
      "Epoch: 36/100 Iteration: 719 Training loss: 0.42986 Train Acc: 0.84873\n",
      "Epoch: 36/100 Iteration: 720 Validation Acc: 0.8567\n",
      "Epoch: 37/100 Iteration: 720 Training loss: 0.43484 Train Acc: 0.85271\n",
      "Epoch: 37/100 Iteration: 721 Training loss: 0.44359 Train Acc: 0.85111\n",
      "Epoch: 37/100 Iteration: 722 Training loss: 0.39823 Train Acc: 0.84315\n",
      "Epoch: 37/100 Iteration: 723 Training loss: 0.42113 Train Acc: 0.84952\n",
      "Epoch: 37/100 Iteration: 724 Training loss: 0.41567 Train Acc: 0.85271\n",
      "Epoch: 37/100 Iteration: 725 Validation Acc: 0.8511\n",
      "Epoch: 37/100 Iteration: 725 Training loss: 0.43064 Train Acc: 0.85111\n",
      "Epoch: 37/100 Iteration: 726 Training loss: 0.45918 Train Acc: 0.85669\n",
      "Epoch: 37/100 Iteration: 727 Training loss: 0.43650 Train Acc: 0.84952\n",
      "Epoch: 37/100 Iteration: 728 Training loss: 0.40814 Train Acc: 0.85748\n",
      "Epoch: 37/100 Iteration: 729 Training loss: 0.45400 Train Acc: 0.85669\n",
      "Epoch: 37/100 Iteration: 730 Validation Acc: 0.8519\n",
      "Epoch: 37/100 Iteration: 730 Training loss: 0.40658 Train Acc: 0.86624\n",
      "Epoch: 37/100 Iteration: 731 Training loss: 0.44093 Train Acc: 0.85271\n",
      "Epoch: 37/100 Iteration: 732 Training loss: 0.42520 Train Acc: 0.85510\n",
      "Epoch: 37/100 Iteration: 733 Training loss: 0.40819 Train Acc: 0.85510\n",
      "Epoch: 37/100 Iteration: 734 Training loss: 0.42867 Train Acc: 0.85987\n",
      "Epoch: 37/100 Iteration: 735 Validation Acc: 0.8519\n",
      "Epoch: 37/100 Iteration: 735 Training loss: 0.44212 Train Acc: 0.85510\n",
      "Epoch: 37/100 Iteration: 736 Training loss: 0.46414 Train Acc: 0.85111\n",
      "Epoch: 37/100 Iteration: 737 Training loss: 0.42859 Train Acc: 0.85669\n",
      "Epoch: 37/100 Iteration: 738 Training loss: 0.41825 Train Acc: 0.85430\n",
      "Epoch: 37/100 Iteration: 739 Training loss: 0.41167 Train Acc: 0.85430\n",
      "Epoch: 37/100 Iteration: 740 Validation Acc: 0.8623\n",
      "Epoch: 38/100 Iteration: 740 Training loss: 0.44131 Train Acc: 0.85191\n",
      "Epoch: 38/100 Iteration: 741 Training loss: 0.43493 Train Acc: 0.85350\n",
      "Epoch: 38/100 Iteration: 742 Training loss: 0.41475 Train Acc: 0.86146\n",
      "Epoch: 38/100 Iteration: 743 Training loss: 0.42167 Train Acc: 0.84873\n",
      "Epoch: 38/100 Iteration: 744 Training loss: 0.43709 Train Acc: 0.85669\n",
      "Epoch: 38/100 Iteration: 745 Validation Acc: 0.8455\n",
      "Epoch: 38/100 Iteration: 745 Training loss: 0.44072 Train Acc: 0.84076\n",
      "Epoch: 38/100 Iteration: 746 Training loss: 0.43976 Train Acc: 0.84634\n",
      "Epoch: 38/100 Iteration: 747 Training loss: 0.42473 Train Acc: 0.85271\n",
      "Epoch: 38/100 Iteration: 748 Training loss: 0.42046 Train Acc: 0.84554\n",
      "Epoch: 38/100 Iteration: 749 Training loss: 0.44258 Train Acc: 0.84634\n",
      "Epoch: 38/100 Iteration: 750 Validation Acc: 0.8336\n",
      "Epoch: 38/100 Iteration: 750 Training loss: 0.44592 Train Acc: 0.84634\n",
      "Epoch: 38/100 Iteration: 751 Training loss: 0.43560 Train Acc: 0.83678\n",
      "Epoch: 38/100 Iteration: 752 Training loss: 0.43550 Train Acc: 0.83041\n",
      "Epoch: 38/100 Iteration: 753 Training loss: 0.41949 Train Acc: 0.83997\n",
      "Epoch: 38/100 Iteration: 754 Training loss: 0.45902 Train Acc: 0.85111\n",
      "Epoch: 38/100 Iteration: 755 Validation Acc: 0.8439\n",
      "Epoch: 38/100 Iteration: 755 Training loss: 0.45263 Train Acc: 0.84634\n",
      "Epoch: 38/100 Iteration: 756 Training loss: 0.44635 Train Acc: 0.84236\n",
      "Epoch: 38/100 Iteration: 757 Training loss: 0.42891 Train Acc: 0.84713\n",
      "Epoch: 38/100 Iteration: 758 Training loss: 0.42225 Train Acc: 0.85669\n",
      "Epoch: 38/100 Iteration: 759 Training loss: 0.41200 Train Acc: 0.85987\n",
      "Epoch: 38/100 Iteration: 760 Validation Acc: 0.8511\n",
      "Epoch: 39/100 Iteration: 760 Training loss: 0.45329 Train Acc: 0.85350\n",
      "Epoch: 39/100 Iteration: 761 Training loss: 0.44119 Train Acc: 0.86146\n",
      "Epoch: 39/100 Iteration: 762 Training loss: 0.43324 Train Acc: 0.85271\n",
      "Epoch: 39/100 Iteration: 763 Training loss: 0.45307 Train Acc: 0.85032\n",
      "Epoch: 39/100 Iteration: 764 Training loss: 0.39051 Train Acc: 0.84793\n",
      "Epoch: 39/100 Iteration: 765 Validation Acc: 0.8535\n",
      "Epoch: 39/100 Iteration: 765 Training loss: 0.44166 Train Acc: 0.85032\n",
      "Epoch: 39/100 Iteration: 766 Training loss: 0.45444 Train Acc: 0.85032\n",
      "Epoch: 39/100 Iteration: 767 Training loss: 0.43217 Train Acc: 0.85350\n",
      "Epoch: 39/100 Iteration: 768 Training loss: 0.41861 Train Acc: 0.85510\n",
      "Epoch: 39/100 Iteration: 769 Training loss: 0.46813 Train Acc: 0.85908\n",
      "Epoch: 39/100 Iteration: 770 Validation Acc: 0.8535\n",
      "Epoch: 39/100 Iteration: 770 Training loss: 0.40399 Train Acc: 0.85748\n",
      "Epoch: 39/100 Iteration: 771 Training loss: 0.42129 Train Acc: 0.84793\n",
      "Epoch: 39/100 Iteration: 772 Training loss: 0.42358 Train Acc: 0.86545\n",
      "Epoch: 39/100 Iteration: 773 Training loss: 0.43512 Train Acc: 0.85111\n",
      "Epoch: 39/100 Iteration: 774 Training loss: 0.43909 Train Acc: 0.85669\n",
      "Epoch: 39/100 Iteration: 775 Validation Acc: 0.8479\n",
      "Epoch: 39/100 Iteration: 775 Training loss: 0.44443 Train Acc: 0.84873\n",
      "Epoch: 39/100 Iteration: 776 Training loss: 0.45601 Train Acc: 0.85589\n",
      "Epoch: 39/100 Iteration: 777 Training loss: 0.39349 Train Acc: 0.84952\n",
      "Epoch: 39/100 Iteration: 778 Training loss: 0.45414 Train Acc: 0.84475\n",
      "Epoch: 39/100 Iteration: 779 Training loss: 0.41550 Train Acc: 0.85908\n",
      "Epoch: 39/100 Iteration: 780 Validation Acc: 0.8511\n",
      "Epoch: 40/100 Iteration: 780 Training loss: 0.41771 Train Acc: 0.85111\n",
      "Epoch: 40/100 Iteration: 781 Training loss: 0.45256 Train Acc: 0.85589\n",
      "Epoch: 40/100 Iteration: 782 Training loss: 0.39761 Train Acc: 0.85748\n",
      "Epoch: 40/100 Iteration: 783 Training loss: 0.40326 Train Acc: 0.85589\n",
      "Epoch: 40/100 Iteration: 784 Training loss: 0.39114 Train Acc: 0.85589\n",
      "Epoch: 40/100 Iteration: 785 Validation Acc: 0.8599\n",
      "Epoch: 40/100 Iteration: 785 Training loss: 0.43746 Train Acc: 0.86306\n",
      "Epoch: 40/100 Iteration: 786 Training loss: 0.43537 Train Acc: 0.85908\n",
      "Epoch: 40/100 Iteration: 787 Training loss: 0.41568 Train Acc: 0.86306\n",
      "Epoch: 40/100 Iteration: 788 Training loss: 0.42830 Train Acc: 0.86783\n",
      "Epoch: 40/100 Iteration: 789 Training loss: 0.46338 Train Acc: 0.85111\n",
      "Epoch: 40/100 Iteration: 790 Validation Acc: 0.8503\n",
      "Epoch: 40/100 Iteration: 790 Training loss: 0.41759 Train Acc: 0.85350\n",
      "Epoch: 40/100 Iteration: 791 Training loss: 0.42130 Train Acc: 0.85032\n",
      "Epoch: 40/100 Iteration: 792 Training loss: 0.43387 Train Acc: 0.85589\n",
      "Epoch: 40/100 Iteration: 793 Training loss: 0.43936 Train Acc: 0.85350\n",
      "Epoch: 40/100 Iteration: 794 Training loss: 0.43595 Train Acc: 0.85430\n",
      "Epoch: 40/100 Iteration: 795 Validation Acc: 0.8455\n",
      "Epoch: 40/100 Iteration: 795 Training loss: 0.43401 Train Acc: 0.85271\n",
      "Epoch: 40/100 Iteration: 796 Training loss: 0.45435 Train Acc: 0.85589\n",
      "Epoch: 40/100 Iteration: 797 Training loss: 0.41853 Train Acc: 0.85510\n",
      "Epoch: 40/100 Iteration: 798 Training loss: 0.42677 Train Acc: 0.86226\n",
      "Epoch: 40/100 Iteration: 799 Training loss: 0.41483 Train Acc: 0.86385\n",
      "Epoch: 40/100 Iteration: 800 Validation Acc: 0.8511\n",
      "Epoch: 41/100 Iteration: 800 Training loss: 0.43425 Train Acc: 0.86306\n",
      "Epoch: 41/100 Iteration: 801 Training loss: 0.45497 Train Acc: 0.84634\n",
      "Epoch: 41/100 Iteration: 802 Training loss: 0.43390 Train Acc: 0.86226\n",
      "Epoch: 41/100 Iteration: 803 Training loss: 0.42793 Train Acc: 0.85111\n",
      "Epoch: 41/100 Iteration: 804 Training loss: 0.40746 Train Acc: 0.85908\n",
      "Epoch: 41/100 Iteration: 805 Validation Acc: 0.8662\n",
      "Epoch: 41/100 Iteration: 805 Training loss: 0.40970 Train Acc: 0.86067\n",
      "Epoch: 41/100 Iteration: 806 Training loss: 0.42291 Train Acc: 0.85510\n",
      "Epoch: 41/100 Iteration: 807 Training loss: 0.41269 Train Acc: 0.85430\n",
      "Epoch: 41/100 Iteration: 808 Training loss: 0.40788 Train Acc: 0.86465\n",
      "Epoch: 41/100 Iteration: 809 Training loss: 0.45521 Train Acc: 0.85748\n",
      "Epoch: 41/100 Iteration: 810 Validation Acc: 0.8670\n",
      "Epoch: 41/100 Iteration: 810 Training loss: 0.43433 Train Acc: 0.86226\n",
      "Epoch: 41/100 Iteration: 811 Training loss: 0.41582 Train Acc: 0.85430\n",
      "Epoch: 41/100 Iteration: 812 Training loss: 0.41546 Train Acc: 0.84076\n",
      "Epoch: 41/100 Iteration: 813 Training loss: 0.43514 Train Acc: 0.84156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41/100 Iteration: 814 Training loss: 0.42852 Train Acc: 0.85271\n",
      "Epoch: 41/100 Iteration: 815 Validation Acc: 0.8495\n",
      "Epoch: 41/100 Iteration: 815 Training loss: 0.43960 Train Acc: 0.85191\n",
      "Epoch: 41/100 Iteration: 816 Training loss: 0.45028 Train Acc: 0.83280\n",
      "Epoch: 41/100 Iteration: 817 Training loss: 0.43062 Train Acc: 0.85111\n",
      "Epoch: 41/100 Iteration: 818 Training loss: 0.44009 Train Acc: 0.85191\n",
      "Epoch: 41/100 Iteration: 819 Training loss: 0.41721 Train Acc: 0.85987\n",
      "Epoch: 41/100 Iteration: 820 Validation Acc: 0.8575\n",
      "Epoch: 42/100 Iteration: 820 Training loss: 0.41794 Train Acc: 0.85987\n",
      "Epoch: 42/100 Iteration: 821 Training loss: 0.44403 Train Acc: 0.85589\n",
      "Epoch: 42/100 Iteration: 822 Training loss: 0.41535 Train Acc: 0.86226\n",
      "Epoch: 42/100 Iteration: 823 Training loss: 0.41556 Train Acc: 0.85350\n",
      "Epoch: 42/100 Iteration: 824 Training loss: 0.40995 Train Acc: 0.85430\n",
      "Epoch: 42/100 Iteration: 825 Validation Acc: 0.8583\n",
      "Epoch: 42/100 Iteration: 825 Training loss: 0.44272 Train Acc: 0.86226\n",
      "Epoch: 42/100 Iteration: 826 Training loss: 0.41969 Train Acc: 0.84873\n",
      "Epoch: 42/100 Iteration: 827 Training loss: 0.41149 Train Acc: 0.86067\n",
      "Epoch: 42/100 Iteration: 828 Training loss: 0.40330 Train Acc: 0.85032\n",
      "Epoch: 42/100 Iteration: 829 Training loss: 0.45500 Train Acc: 0.86465\n",
      "Epoch: 42/100 Iteration: 830 Validation Acc: 0.8535\n",
      "Epoch: 42/100 Iteration: 830 Training loss: 0.43020 Train Acc: 0.85191\n",
      "Epoch: 42/100 Iteration: 831 Training loss: 0.41751 Train Acc: 0.85430\n",
      "Epoch: 42/100 Iteration: 832 Training loss: 0.42054 Train Acc: 0.84554\n",
      "Epoch: 42/100 Iteration: 833 Training loss: 0.41846 Train Acc: 0.85111\n",
      "Epoch: 42/100 Iteration: 834 Training loss: 0.44043 Train Acc: 0.85191\n",
      "Epoch: 42/100 Iteration: 835 Validation Acc: 0.8487\n",
      "Epoch: 42/100 Iteration: 835 Training loss: 0.45217 Train Acc: 0.85669\n",
      "Epoch: 42/100 Iteration: 836 Training loss: 0.45401 Train Acc: 0.86067\n",
      "Epoch: 42/100 Iteration: 837 Training loss: 0.41638 Train Acc: 0.85987\n",
      "Epoch: 42/100 Iteration: 838 Training loss: 0.42690 Train Acc: 0.84952\n",
      "Epoch: 42/100 Iteration: 839 Training loss: 0.41388 Train Acc: 0.84713\n",
      "Epoch: 42/100 Iteration: 840 Validation Acc: 0.8424\n",
      "Epoch: 43/100 Iteration: 840 Training loss: 0.43856 Train Acc: 0.85271\n",
      "Epoch: 43/100 Iteration: 841 Training loss: 0.44748 Train Acc: 0.85271\n",
      "Epoch: 43/100 Iteration: 842 Training loss: 0.41687 Train Acc: 0.86226\n",
      "Epoch: 43/100 Iteration: 843 Training loss: 0.42781 Train Acc: 0.86465\n",
      "Epoch: 43/100 Iteration: 844 Training loss: 0.40854 Train Acc: 0.85111\n",
      "Epoch: 43/100 Iteration: 845 Validation Acc: 0.8543\n",
      "Epoch: 43/100 Iteration: 845 Training loss: 0.41764 Train Acc: 0.86226\n",
      "Epoch: 43/100 Iteration: 846 Training loss: 0.44663 Train Acc: 0.86146\n",
      "Epoch: 43/100 Iteration: 847 Training loss: 0.41821 Train Acc: 0.85987\n",
      "Epoch: 43/100 Iteration: 848 Training loss: 0.39384 Train Acc: 0.86226\n",
      "Epoch: 43/100 Iteration: 849 Training loss: 0.45425 Train Acc: 0.85669\n",
      "Epoch: 43/100 Iteration: 850 Validation Acc: 0.8400\n",
      "Epoch: 43/100 Iteration: 850 Training loss: 0.44357 Train Acc: 0.85589\n",
      "Epoch: 43/100 Iteration: 851 Training loss: 0.40391 Train Acc: 0.84236\n",
      "Epoch: 43/100 Iteration: 852 Training loss: 0.43874 Train Acc: 0.84952\n",
      "Epoch: 43/100 Iteration: 853 Training loss: 0.39985 Train Acc: 0.85510\n",
      "Epoch: 43/100 Iteration: 854 Training loss: 0.44878 Train Acc: 0.84873\n",
      "Epoch: 43/100 Iteration: 855 Validation Acc: 0.8575\n",
      "Epoch: 43/100 Iteration: 855 Training loss: 0.45061 Train Acc: 0.84952\n",
      "Epoch: 43/100 Iteration: 856 Training loss: 0.45960 Train Acc: 0.84634\n",
      "Epoch: 43/100 Iteration: 857 Training loss: 0.42348 Train Acc: 0.84873\n",
      "Epoch: 43/100 Iteration: 858 Training loss: 0.43373 Train Acc: 0.83917\n",
      "Epoch: 43/100 Iteration: 859 Training loss: 0.42103 Train Acc: 0.84236\n",
      "Epoch: 43/100 Iteration: 860 Validation Acc: 0.8471\n",
      "Epoch: 44/100 Iteration: 860 Training loss: 0.43347 Train Acc: 0.85271\n",
      "Epoch: 44/100 Iteration: 861 Training loss: 0.43818 Train Acc: 0.85669\n",
      "Epoch: 44/100 Iteration: 862 Training loss: 0.41553 Train Acc: 0.85271\n",
      "Epoch: 44/100 Iteration: 863 Training loss: 0.43447 Train Acc: 0.84554\n",
      "Epoch: 44/100 Iteration: 864 Training loss: 0.40832 Train Acc: 0.84634\n",
      "Epoch: 44/100 Iteration: 865 Validation Acc: 0.8439\n",
      "Epoch: 44/100 Iteration: 865 Training loss: 0.43596 Train Acc: 0.84395\n",
      "Epoch: 44/100 Iteration: 866 Training loss: 0.44792 Train Acc: 0.85271\n",
      "Epoch: 44/100 Iteration: 867 Training loss: 0.44530 Train Acc: 0.83917\n",
      "Epoch: 44/100 Iteration: 868 Training loss: 0.42057 Train Acc: 0.83917\n",
      "Epoch: 44/100 Iteration: 869 Training loss: 0.47156 Train Acc: 0.84315\n",
      "Epoch: 44/100 Iteration: 870 Validation Acc: 0.8439\n",
      "Epoch: 44/100 Iteration: 870 Training loss: 0.43429 Train Acc: 0.83439\n",
      "Epoch: 44/100 Iteration: 871 Training loss: 0.43428 Train Acc: 0.85669\n",
      "Epoch: 44/100 Iteration: 872 Training loss: 0.43472 Train Acc: 0.84315\n",
      "Epoch: 44/100 Iteration: 873 Training loss: 0.40316 Train Acc: 0.84634\n",
      "Epoch: 44/100 Iteration: 874 Training loss: 0.44000 Train Acc: 0.85748\n",
      "Epoch: 44/100 Iteration: 875 Validation Acc: 0.8527\n",
      "Epoch: 44/100 Iteration: 875 Training loss: 0.43717 Train Acc: 0.85032\n",
      "Epoch: 44/100 Iteration: 876 Training loss: 0.44941 Train Acc: 0.85191\n",
      "Epoch: 44/100 Iteration: 877 Training loss: 0.42801 Train Acc: 0.86146\n",
      "Epoch: 44/100 Iteration: 878 Training loss: 0.42555 Train Acc: 0.85987\n",
      "Epoch: 44/100 Iteration: 879 Training loss: 0.42694 Train Acc: 0.84315\n",
      "Epoch: 44/100 Iteration: 880 Validation Acc: 0.8559\n",
      "Epoch: 45/100 Iteration: 880 Training loss: 0.44261 Train Acc: 0.86067\n",
      "Epoch: 45/100 Iteration: 881 Training loss: 0.44334 Train Acc: 0.85510\n",
      "Epoch: 45/100 Iteration: 882 Training loss: 0.41315 Train Acc: 0.85589\n",
      "Epoch: 45/100 Iteration: 883 Training loss: 0.43138 Train Acc: 0.84873\n",
      "Epoch: 45/100 Iteration: 884 Training loss: 0.41720 Train Acc: 0.86465\n",
      "Epoch: 45/100 Iteration: 885 Validation Acc: 0.8535\n",
      "Epoch: 45/100 Iteration: 885 Training loss: 0.43207 Train Acc: 0.86863\n",
      "Epoch: 45/100 Iteration: 886 Training loss: 0.43431 Train Acc: 0.85828\n",
      "Epoch: 45/100 Iteration: 887 Training loss: 0.42605 Train Acc: 0.86465\n",
      "Epoch: 45/100 Iteration: 888 Training loss: 0.39752 Train Acc: 0.85908\n",
      "Epoch: 45/100 Iteration: 889 Training loss: 0.46660 Train Acc: 0.85828\n",
      "Epoch: 45/100 Iteration: 890 Validation Acc: 0.8615\n",
      "Epoch: 45/100 Iteration: 890 Training loss: 0.42518 Train Acc: 0.85589\n",
      "Epoch: 45/100 Iteration: 891 Training loss: 0.41997 Train Acc: 0.85271\n",
      "Epoch: 45/100 Iteration: 892 Training loss: 0.43957 Train Acc: 0.85828\n",
      "Epoch: 45/100 Iteration: 893 Training loss: 0.42135 Train Acc: 0.85828\n",
      "Epoch: 45/100 Iteration: 894 Training loss: 0.44407 Train Acc: 0.85032\n",
      "Epoch: 45/100 Iteration: 895 Validation Acc: 0.8447\n",
      "Epoch: 45/100 Iteration: 895 Training loss: 0.42989 Train Acc: 0.86226\n",
      "Epoch: 45/100 Iteration: 896 Training loss: 0.44480 Train Acc: 0.85430\n",
      "Epoch: 45/100 Iteration: 897 Training loss: 0.41046 Train Acc: 0.85589\n",
      "Epoch: 45/100 Iteration: 898 Training loss: 0.41597 Train Acc: 0.87341\n",
      "Epoch: 45/100 Iteration: 899 Training loss: 0.39083 Train Acc: 0.86624\n",
      "Epoch: 45/100 Iteration: 900 Validation Acc: 0.8583\n",
      "Epoch: 46/100 Iteration: 900 Training loss: 0.42360 Train Acc: 0.86306\n",
      "Epoch: 46/100 Iteration: 901 Training loss: 0.43156 Train Acc: 0.85271\n",
      "Epoch: 46/100 Iteration: 902 Training loss: 0.39426 Train Acc: 0.84793\n",
      "Epoch: 46/100 Iteration: 903 Training loss: 0.40723 Train Acc: 0.85191\n",
      "Epoch: 46/100 Iteration: 904 Training loss: 0.40269 Train Acc: 0.84873\n",
      "Epoch: 46/100 Iteration: 905 Validation Acc: 0.8646\n",
      "Epoch: 46/100 Iteration: 905 Training loss: 0.45925 Train Acc: 0.84793\n",
      "Epoch: 46/100 Iteration: 906 Training loss: 0.44949 Train Acc: 0.85271\n",
      "Epoch: 46/100 Iteration: 907 Training loss: 0.43142 Train Acc: 0.86863\n",
      "Epoch: 46/100 Iteration: 908 Training loss: 0.41475 Train Acc: 0.86465\n",
      "Epoch: 46/100 Iteration: 909 Training loss: 0.45849 Train Acc: 0.86385\n",
      "Epoch: 46/100 Iteration: 910 Validation Acc: 0.8543\n",
      "Epoch: 46/100 Iteration: 910 Training loss: 0.42525 Train Acc: 0.85350\n",
      "Epoch: 46/100 Iteration: 911 Training loss: 0.40130 Train Acc: 0.84634\n",
      "Epoch: 46/100 Iteration: 912 Training loss: 0.41437 Train Acc: 0.85510\n",
      "Epoch: 46/100 Iteration: 913 Training loss: 0.39890 Train Acc: 0.85191\n",
      "Epoch: 46/100 Iteration: 914 Training loss: 0.42309 Train Acc: 0.84952\n",
      "Epoch: 46/100 Iteration: 915 Validation Acc: 0.8416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46/100 Iteration: 915 Training loss: 0.42639 Train Acc: 0.84076\n",
      "Epoch: 46/100 Iteration: 916 Training loss: 0.43213 Train Acc: 0.83997\n",
      "Epoch: 46/100 Iteration: 917 Training loss: 0.42529 Train Acc: 0.84236\n",
      "Epoch: 46/100 Iteration: 918 Training loss: 0.43643 Train Acc: 0.85111\n",
      "Epoch: 46/100 Iteration: 919 Training loss: 0.41525 Train Acc: 0.84793\n",
      "Epoch: 46/100 Iteration: 920 Validation Acc: 0.8471\n",
      "Epoch: 47/100 Iteration: 920 Training loss: 0.44602 Train Acc: 0.85510\n",
      "Epoch: 47/100 Iteration: 921 Training loss: 0.44777 Train Acc: 0.85191\n",
      "Epoch: 47/100 Iteration: 922 Training loss: 0.42833 Train Acc: 0.84793\n",
      "Epoch: 47/100 Iteration: 923 Training loss: 0.43615 Train Acc: 0.85111\n",
      "Epoch: 47/100 Iteration: 924 Training loss: 0.40388 Train Acc: 0.85350\n",
      "Epoch: 47/100 Iteration: 925 Validation Acc: 0.8535\n",
      "Epoch: 47/100 Iteration: 925 Training loss: 0.41000 Train Acc: 0.85669\n",
      "Epoch: 47/100 Iteration: 926 Training loss: 0.45737 Train Acc: 0.86385\n",
      "Epoch: 47/100 Iteration: 927 Training loss: 0.41058 Train Acc: 0.85589\n",
      "Epoch: 47/100 Iteration: 928 Training loss: 0.40626 Train Acc: 0.84952\n",
      "Epoch: 47/100 Iteration: 929 Training loss: 0.46832 Train Acc: 0.84634\n",
      "Epoch: 47/100 Iteration: 930 Validation Acc: 0.8639\n",
      "Epoch: 47/100 Iteration: 930 Training loss: 0.44368 Train Acc: 0.85111\n",
      "Epoch: 47/100 Iteration: 931 Training loss: 0.43279 Train Acc: 0.86226\n",
      "Epoch: 47/100 Iteration: 932 Training loss: 0.42200 Train Acc: 0.85271\n",
      "Epoch: 47/100 Iteration: 933 Training loss: 0.41799 Train Acc: 0.86306\n",
      "Epoch: 47/100 Iteration: 934 Training loss: 0.42142 Train Acc: 0.85271\n",
      "Epoch: 47/100 Iteration: 935 Validation Acc: 0.8432\n",
      "Epoch: 47/100 Iteration: 935 Training loss: 0.42672 Train Acc: 0.85032\n",
      "Epoch: 47/100 Iteration: 936 Training loss: 0.44373 Train Acc: 0.85191\n",
      "Epoch: 47/100 Iteration: 937 Training loss: 0.42060 Train Acc: 0.85430\n",
      "Epoch: 47/100 Iteration: 938 Training loss: 0.41444 Train Acc: 0.86067\n",
      "Epoch: 47/100 Iteration: 939 Training loss: 0.43592 Train Acc: 0.84873\n",
      "Epoch: 47/100 Iteration: 940 Validation Acc: 0.8543\n",
      "Epoch: 48/100 Iteration: 940 Training loss: 0.41939 Train Acc: 0.84873\n",
      "Epoch: 48/100 Iteration: 941 Training loss: 0.43277 Train Acc: 0.85510\n",
      "Epoch: 48/100 Iteration: 942 Training loss: 0.41444 Train Acc: 0.85748\n",
      "Epoch: 48/100 Iteration: 943 Training loss: 0.39809 Train Acc: 0.86067\n",
      "Epoch: 48/100 Iteration: 944 Training loss: 0.40651 Train Acc: 0.86624\n",
      "Epoch: 48/100 Iteration: 945 Validation Acc: 0.8654\n",
      "Epoch: 48/100 Iteration: 945 Training loss: 0.44962 Train Acc: 0.85191\n",
      "Epoch: 48/100 Iteration: 946 Training loss: 0.44350 Train Acc: 0.85271\n",
      "Epoch: 48/100 Iteration: 947 Training loss: 0.44343 Train Acc: 0.86146\n",
      "Epoch: 48/100 Iteration: 948 Training loss: 0.42047 Train Acc: 0.86306\n",
      "Epoch: 48/100 Iteration: 949 Training loss: 0.46542 Train Acc: 0.85589\n",
      "Epoch: 48/100 Iteration: 950 Validation Acc: 0.8543\n",
      "Epoch: 48/100 Iteration: 950 Training loss: 0.43143 Train Acc: 0.86067\n",
      "Epoch: 48/100 Iteration: 951 Training loss: 0.42423 Train Acc: 0.86545\n",
      "Epoch: 48/100 Iteration: 952 Training loss: 0.41191 Train Acc: 0.86943\n",
      "Epoch: 48/100 Iteration: 953 Training loss: 0.42234 Train Acc: 0.87102\n",
      "Epoch: 48/100 Iteration: 954 Training loss: 0.40322 Train Acc: 0.86067\n",
      "Epoch: 48/100 Iteration: 955 Validation Acc: 0.8678\n",
      "Epoch: 48/100 Iteration: 955 Training loss: 0.41578 Train Acc: 0.85191\n",
      "Epoch: 48/100 Iteration: 956 Training loss: 0.45883 Train Acc: 0.85748\n",
      "Epoch: 48/100 Iteration: 957 Training loss: 0.44501 Train Acc: 0.85669\n",
      "Epoch: 48/100 Iteration: 958 Training loss: 0.40101 Train Acc: 0.85032\n",
      "Epoch: 48/100 Iteration: 959 Training loss: 0.40287 Train Acc: 0.85510\n",
      "Epoch: 48/100 Iteration: 960 Validation Acc: 0.8567\n",
      "Epoch: 49/100 Iteration: 960 Training loss: 0.42377 Train Acc: 0.85350\n",
      "Epoch: 49/100 Iteration: 961 Training loss: 0.44591 Train Acc: 0.85589\n",
      "Epoch: 49/100 Iteration: 962 Training loss: 0.39974 Train Acc: 0.86783\n",
      "Epoch: 49/100 Iteration: 963 Training loss: 0.42261 Train Acc: 0.86545\n",
      "Epoch: 49/100 Iteration: 964 Training loss: 0.39951 Train Acc: 0.85350\n",
      "Epoch: 49/100 Iteration: 965 Validation Acc: 0.8535\n",
      "Epoch: 49/100 Iteration: 965 Training loss: 0.42900 Train Acc: 0.85191\n",
      "Epoch: 49/100 Iteration: 966 Training loss: 0.44875 Train Acc: 0.86465\n",
      "Epoch: 49/100 Iteration: 967 Training loss: 0.39955 Train Acc: 0.85111\n",
      "Epoch: 49/100 Iteration: 968 Training loss: 0.41896 Train Acc: 0.86146\n",
      "Epoch: 49/100 Iteration: 969 Training loss: 0.47001 Train Acc: 0.85748\n",
      "Epoch: 49/100 Iteration: 970 Validation Acc: 0.8623\n",
      "Epoch: 49/100 Iteration: 970 Training loss: 0.43139 Train Acc: 0.86704\n",
      "Epoch: 49/100 Iteration: 971 Training loss: 0.40577 Train Acc: 0.85828\n",
      "Epoch: 49/100 Iteration: 972 Training loss: 0.42274 Train Acc: 0.85908\n",
      "Epoch: 49/100 Iteration: 973 Training loss: 0.39872 Train Acc: 0.86385\n",
      "Epoch: 49/100 Iteration: 974 Training loss: 0.40891 Train Acc: 0.86863\n",
      "Epoch: 49/100 Iteration: 975 Validation Acc: 0.8575\n",
      "Epoch: 49/100 Iteration: 975 Training loss: 0.41990 Train Acc: 0.85430\n",
      "Epoch: 49/100 Iteration: 976 Training loss: 0.44137 Train Acc: 0.85510\n",
      "Epoch: 49/100 Iteration: 977 Training loss: 0.40481 Train Acc: 0.85589\n",
      "Epoch: 49/100 Iteration: 978 Training loss: 0.40549 Train Acc: 0.86146\n",
      "Epoch: 49/100 Iteration: 979 Training loss: 0.41203 Train Acc: 0.85908\n",
      "Epoch: 49/100 Iteration: 980 Validation Acc: 0.8670\n",
      "Epoch: 50/100 Iteration: 980 Training loss: 0.43100 Train Acc: 0.85589\n",
      "Epoch: 50/100 Iteration: 981 Training loss: 0.44808 Train Acc: 0.85430\n",
      "Epoch: 50/100 Iteration: 982 Training loss: 0.42685 Train Acc: 0.85987\n",
      "Epoch: 50/100 Iteration: 983 Training loss: 0.42005 Train Acc: 0.86783\n",
      "Epoch: 50/100 Iteration: 984 Training loss: 0.41013 Train Acc: 0.85271\n",
      "Epoch: 50/100 Iteration: 985 Validation Acc: 0.8495\n",
      "Epoch: 50/100 Iteration: 985 Training loss: 0.43669 Train Acc: 0.85271\n",
      "Epoch: 50/100 Iteration: 986 Training loss: 0.46003 Train Acc: 0.83997\n",
      "Epoch: 50/100 Iteration: 987 Training loss: 0.41342 Train Acc: 0.83917\n",
      "Epoch: 50/100 Iteration: 988 Training loss: 0.40642 Train Acc: 0.84475\n",
      "Epoch: 50/100 Iteration: 989 Training loss: 0.44358 Train Acc: 0.83917\n",
      "Epoch: 50/100 Iteration: 990 Validation Acc: 0.8447\n",
      "Epoch: 50/100 Iteration: 990 Training loss: 0.43950 Train Acc: 0.84076\n",
      "Epoch: 50/100 Iteration: 991 Training loss: 0.43229 Train Acc: 0.85350\n",
      "Epoch: 50/100 Iteration: 992 Training loss: 0.42191 Train Acc: 0.84475\n",
      "Epoch: 50/100 Iteration: 993 Training loss: 0.42532 Train Acc: 0.85191\n",
      "Epoch: 50/100 Iteration: 994 Training loss: 0.41307 Train Acc: 0.85589\n",
      "Epoch: 50/100 Iteration: 995 Validation Acc: 0.8463\n",
      "Epoch: 50/100 Iteration: 995 Training loss: 0.44159 Train Acc: 0.84793\n",
      "Epoch: 50/100 Iteration: 996 Training loss: 0.45211 Train Acc: 0.84952\n",
      "Epoch: 50/100 Iteration: 997 Training loss: 0.41225 Train Acc: 0.85430\n",
      "Epoch: 50/100 Iteration: 998 Training loss: 0.41843 Train Acc: 0.85510\n",
      "Epoch: 50/100 Iteration: 999 Training loss: 0.41522 Train Acc: 0.85828\n",
      "Epoch: 50/100 Iteration: 1000 Validation Acc: 0.8575\n",
      "Epoch: 51/100 Iteration: 1000 Training loss: 0.43375 Train Acc: 0.84793\n",
      "Epoch: 51/100 Iteration: 1001 Training loss: 0.44372 Train Acc: 0.85510\n",
      "Epoch: 51/100 Iteration: 1002 Training loss: 0.41322 Train Acc: 0.85271\n",
      "Epoch: 51/100 Iteration: 1003 Training loss: 0.42395 Train Acc: 0.84952\n",
      "Epoch: 51/100 Iteration: 1004 Training loss: 0.40364 Train Acc: 0.86306\n",
      "Epoch: 51/100 Iteration: 1005 Validation Acc: 0.8615\n",
      "Epoch: 51/100 Iteration: 1005 Training loss: 0.43662 Train Acc: 0.85669\n",
      "Epoch: 51/100 Iteration: 1006 Training loss: 0.43610 Train Acc: 0.86306\n",
      "Epoch: 51/100 Iteration: 1007 Training loss: 0.41771 Train Acc: 0.85430\n",
      "Epoch: 51/100 Iteration: 1008 Training loss: 0.40766 Train Acc: 0.86146\n",
      "Epoch: 51/100 Iteration: 1009 Training loss: 0.45143 Train Acc: 0.86067\n",
      "Epoch: 51/100 Iteration: 1010 Validation Acc: 0.8519\n",
      "Epoch: 51/100 Iteration: 1010 Training loss: 0.43069 Train Acc: 0.84873\n",
      "Epoch: 51/100 Iteration: 1011 Training loss: 0.44265 Train Acc: 0.87500\n",
      "Epoch: 51/100 Iteration: 1012 Training loss: 0.43099 Train Acc: 0.86306\n",
      "Epoch: 51/100 Iteration: 1013 Training loss: 0.40256 Train Acc: 0.86146\n",
      "Epoch: 51/100 Iteration: 1014 Training loss: 0.41359 Train Acc: 0.86704\n",
      "Epoch: 51/100 Iteration: 1015 Validation Acc: 0.8615\n",
      "Epoch: 51/100 Iteration: 1015 Training loss: 0.39678 Train Acc: 0.86226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 51/100 Iteration: 1016 Training loss: 0.44900 Train Acc: 0.86465\n",
      "Epoch: 51/100 Iteration: 1017 Training loss: 0.41228 Train Acc: 0.86465\n",
      "Epoch: 51/100 Iteration: 1018 Training loss: 0.38955 Train Acc: 0.85350\n",
      "Epoch: 51/100 Iteration: 1019 Training loss: 0.42439 Train Acc: 0.86146\n",
      "Epoch: 51/100 Iteration: 1020 Validation Acc: 0.8559\n",
      "Epoch: 52/100 Iteration: 1020 Training loss: 0.42114 Train Acc: 0.86624\n",
      "Epoch: 52/100 Iteration: 1021 Training loss: 0.43343 Train Acc: 0.87022\n",
      "Epoch: 52/100 Iteration: 1022 Training loss: 0.40691 Train Acc: 0.86863\n",
      "Epoch: 52/100 Iteration: 1023 Training loss: 0.42176 Train Acc: 0.86146\n",
      "Epoch: 52/100 Iteration: 1024 Training loss: 0.39730 Train Acc: 0.87580\n",
      "Epoch: 52/100 Iteration: 1025 Validation Acc: 0.8527\n",
      "Epoch: 52/100 Iteration: 1025 Training loss: 0.44291 Train Acc: 0.86067\n",
      "Epoch: 52/100 Iteration: 1026 Training loss: 0.42725 Train Acc: 0.86385\n",
      "Epoch: 52/100 Iteration: 1027 Training loss: 0.42983 Train Acc: 0.87022\n",
      "Epoch: 52/100 Iteration: 1028 Training loss: 0.38674 Train Acc: 0.86146\n",
      "Epoch: 52/100 Iteration: 1029 Training loss: 0.45920 Train Acc: 0.86704\n",
      "Epoch: 52/100 Iteration: 1030 Validation Acc: 0.8654\n",
      "Epoch: 52/100 Iteration: 1030 Training loss: 0.41002 Train Acc: 0.86624\n",
      "Epoch: 52/100 Iteration: 1031 Training loss: 0.40645 Train Acc: 0.86226\n",
      "Epoch: 52/100 Iteration: 1032 Training loss: 0.41490 Train Acc: 0.86067\n",
      "Epoch: 52/100 Iteration: 1033 Training loss: 0.41034 Train Acc: 0.85748\n",
      "Epoch: 52/100 Iteration: 1034 Training loss: 0.43006 Train Acc: 0.85032\n",
      "Epoch: 52/100 Iteration: 1035 Validation Acc: 0.8535\n",
      "Epoch: 52/100 Iteration: 1035 Training loss: 0.39881 Train Acc: 0.85111\n",
      "Epoch: 52/100 Iteration: 1036 Training loss: 0.44061 Train Acc: 0.84873\n",
      "Epoch: 52/100 Iteration: 1037 Training loss: 0.40968 Train Acc: 0.85191\n",
      "Epoch: 52/100 Iteration: 1038 Training loss: 0.41406 Train Acc: 0.85430\n",
      "Epoch: 52/100 Iteration: 1039 Training loss: 0.40535 Train Acc: 0.85828\n",
      "Epoch: 52/100 Iteration: 1040 Validation Acc: 0.8639\n",
      "Epoch: 53/100 Iteration: 1040 Training loss: 0.41390 Train Acc: 0.86704\n",
      "Epoch: 53/100 Iteration: 1041 Training loss: 0.43450 Train Acc: 0.86385\n",
      "Epoch: 53/100 Iteration: 1042 Training loss: 0.40336 Train Acc: 0.86863\n",
      "Epoch: 53/100 Iteration: 1043 Training loss: 0.40325 Train Acc: 0.87898\n",
      "Epoch: 53/100 Iteration: 1044 Training loss: 0.39788 Train Acc: 0.84793\n",
      "Epoch: 53/100 Iteration: 1045 Validation Acc: 0.8615\n",
      "Epoch: 53/100 Iteration: 1045 Training loss: 0.41639 Train Acc: 0.85111\n",
      "Epoch: 53/100 Iteration: 1046 Training loss: 0.45453 Train Acc: 0.85828\n",
      "Epoch: 53/100 Iteration: 1047 Training loss: 0.40792 Train Acc: 0.85987\n",
      "Epoch: 53/100 Iteration: 1048 Training loss: 0.40368 Train Acc: 0.86067\n",
      "Epoch: 53/100 Iteration: 1049 Training loss: 0.44567 Train Acc: 0.86545\n",
      "Epoch: 53/100 Iteration: 1050 Validation Acc: 0.8543\n",
      "Epoch: 53/100 Iteration: 1050 Training loss: 0.43307 Train Acc: 0.84634\n",
      "Epoch: 53/100 Iteration: 1051 Training loss: 0.40115 Train Acc: 0.86146\n",
      "Epoch: 53/100 Iteration: 1052 Training loss: 0.40315 Train Acc: 0.86146\n",
      "Epoch: 53/100 Iteration: 1053 Training loss: 0.40376 Train Acc: 0.86067\n",
      "Epoch: 53/100 Iteration: 1054 Training loss: 0.42505 Train Acc: 0.86146\n",
      "Epoch: 53/100 Iteration: 1055 Validation Acc: 0.8487\n",
      "Epoch: 53/100 Iteration: 1055 Training loss: 0.43918 Train Acc: 0.85828\n",
      "Epoch: 53/100 Iteration: 1056 Training loss: 0.43354 Train Acc: 0.84952\n",
      "Epoch: 53/100 Iteration: 1057 Training loss: 0.41619 Train Acc: 0.85828\n",
      "Epoch: 53/100 Iteration: 1058 Training loss: 0.40770 Train Acc: 0.85350\n",
      "Epoch: 53/100 Iteration: 1059 Training loss: 0.40374 Train Acc: 0.86783\n",
      "Epoch: 53/100 Iteration: 1060 Validation Acc: 0.8551\n",
      "Epoch: 54/100 Iteration: 1060 Training loss: 0.41415 Train Acc: 0.86226\n",
      "Epoch: 54/100 Iteration: 1061 Training loss: 0.43336 Train Acc: 0.86624\n",
      "Epoch: 54/100 Iteration: 1062 Training loss: 0.38825 Train Acc: 0.84793\n",
      "Epoch: 54/100 Iteration: 1063 Training loss: 0.39859 Train Acc: 0.86226\n",
      "Epoch: 54/100 Iteration: 1064 Training loss: 0.38915 Train Acc: 0.85589\n",
      "Epoch: 54/100 Iteration: 1065 Validation Acc: 0.8678\n",
      "Epoch: 54/100 Iteration: 1065 Training loss: 0.42759 Train Acc: 0.86226\n",
      "Epoch: 54/100 Iteration: 1066 Training loss: 0.42940 Train Acc: 0.86863\n",
      "Epoch: 54/100 Iteration: 1067 Training loss: 0.41949 Train Acc: 0.85669\n",
      "Epoch: 54/100 Iteration: 1068 Training loss: 0.39931 Train Acc: 0.87022\n",
      "Epoch: 54/100 Iteration: 1069 Training loss: 0.45768 Train Acc: 0.87898\n",
      "Epoch: 54/100 Iteration: 1070 Validation Acc: 0.8766\n",
      "Epoch: 54/100 Iteration: 1070 Training loss: 0.41419 Train Acc: 0.87182\n",
      "Epoch: 54/100 Iteration: 1071 Training loss: 0.41761 Train Acc: 0.86943\n",
      "Epoch: 54/100 Iteration: 1072 Training loss: 0.41090 Train Acc: 0.86624\n",
      "Epoch: 54/100 Iteration: 1073 Training loss: 0.39267 Train Acc: 0.87818\n",
      "Epoch: 54/100 Iteration: 1074 Training loss: 0.43796 Train Acc: 0.86624\n",
      "Epoch: 54/100 Iteration: 1075 Validation Acc: 0.8623\n",
      "Epoch: 54/100 Iteration: 1075 Training loss: 0.42682 Train Acc: 0.86863\n",
      "Epoch: 54/100 Iteration: 1076 Training loss: 0.44083 Train Acc: 0.86783\n",
      "Epoch: 54/100 Iteration: 1077 Training loss: 0.39881 Train Acc: 0.87022\n",
      "Epoch: 54/100 Iteration: 1078 Training loss: 0.40307 Train Acc: 0.86067\n",
      "Epoch: 54/100 Iteration: 1079 Training loss: 0.39083 Train Acc: 0.86863\n",
      "Epoch: 54/100 Iteration: 1080 Validation Acc: 0.8639\n",
      "Epoch: 55/100 Iteration: 1080 Training loss: 0.40507 Train Acc: 0.86226\n",
      "Epoch: 55/100 Iteration: 1081 Training loss: 0.42079 Train Acc: 0.86943\n",
      "Epoch: 55/100 Iteration: 1082 Training loss: 0.39704 Train Acc: 0.86624\n",
      "Epoch: 55/100 Iteration: 1083 Training loss: 0.40394 Train Acc: 0.87261\n",
      "Epoch: 55/100 Iteration: 1084 Training loss: 0.39672 Train Acc: 0.87580\n",
      "Epoch: 55/100 Iteration: 1085 Validation Acc: 0.8631\n",
      "Epoch: 55/100 Iteration: 1085 Training loss: 0.42653 Train Acc: 0.88057\n",
      "Epoch: 55/100 Iteration: 1086 Training loss: 0.44522 Train Acc: 0.86624\n",
      "Epoch: 55/100 Iteration: 1087 Training loss: 0.39817 Train Acc: 0.87102\n",
      "Epoch: 55/100 Iteration: 1088 Training loss: 0.39383 Train Acc: 0.87500\n",
      "Epoch: 55/100 Iteration: 1089 Training loss: 0.46217 Train Acc: 0.87500\n",
      "Epoch: 55/100 Iteration: 1090 Validation Acc: 0.8694\n",
      "Epoch: 55/100 Iteration: 1090 Training loss: 0.40048 Train Acc: 0.87341\n",
      "Epoch: 55/100 Iteration: 1091 Training loss: 0.40914 Train Acc: 0.86943\n",
      "Epoch: 55/100 Iteration: 1092 Training loss: 0.41300 Train Acc: 0.86385\n",
      "Epoch: 55/100 Iteration: 1093 Training loss: 0.39528 Train Acc: 0.85987\n",
      "Epoch: 55/100 Iteration: 1094 Training loss: 0.43766 Train Acc: 0.85748\n",
      "Epoch: 55/100 Iteration: 1095 Validation Acc: 0.8551\n",
      "Epoch: 55/100 Iteration: 1095 Training loss: 0.43219 Train Acc: 0.85350\n",
      "Epoch: 55/100 Iteration: 1096 Training loss: 0.43920 Train Acc: 0.84634\n",
      "Epoch: 55/100 Iteration: 1097 Training loss: 0.41719 Train Acc: 0.84793\n",
      "Epoch: 55/100 Iteration: 1098 Training loss: 0.42011 Train Acc: 0.86624\n",
      "Epoch: 55/100 Iteration: 1099 Training loss: 0.41595 Train Acc: 0.87500\n",
      "Epoch: 55/100 Iteration: 1100 Validation Acc: 0.8654\n",
      "Epoch: 56/100 Iteration: 1100 Training loss: 0.42520 Train Acc: 0.87022\n",
      "Epoch: 56/100 Iteration: 1101 Training loss: 0.43222 Train Acc: 0.87022\n",
      "Epoch: 56/100 Iteration: 1102 Training loss: 0.40184 Train Acc: 0.86306\n",
      "Epoch: 56/100 Iteration: 1103 Training loss: 0.39311 Train Acc: 0.87420\n",
      "Epoch: 56/100 Iteration: 1104 Training loss: 0.39364 Train Acc: 0.86385\n",
      "Epoch: 56/100 Iteration: 1105 Validation Acc: 0.8750\n",
      "Epoch: 56/100 Iteration: 1105 Training loss: 0.42799 Train Acc: 0.85748\n",
      "Epoch: 56/100 Iteration: 1106 Training loss: 0.43527 Train Acc: 0.85510\n",
      "Epoch: 56/100 Iteration: 1107 Training loss: 0.40898 Train Acc: 0.85589\n",
      "Epoch: 56/100 Iteration: 1108 Training loss: 0.39414 Train Acc: 0.86863\n",
      "Epoch: 56/100 Iteration: 1109 Training loss: 0.45410 Train Acc: 0.87580\n",
      "Epoch: 56/100 Iteration: 1110 Validation Acc: 0.8646\n",
      "Epoch: 56/100 Iteration: 1110 Training loss: 0.41954 Train Acc: 0.84873\n",
      "Epoch: 56/100 Iteration: 1111 Training loss: 0.41591 Train Acc: 0.85828\n",
      "Epoch: 56/100 Iteration: 1112 Training loss: 0.39971 Train Acc: 0.85828\n",
      "Epoch: 56/100 Iteration: 1113 Training loss: 0.41577 Train Acc: 0.85589\n",
      "Epoch: 56/100 Iteration: 1114 Training loss: 0.41162 Train Acc: 0.86863\n",
      "Epoch: 56/100 Iteration: 1115 Validation Acc: 0.8694\n",
      "Epoch: 56/100 Iteration: 1115 Training loss: 0.41333 Train Acc: 0.86067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 56/100 Iteration: 1116 Training loss: 0.41338 Train Acc: 0.86545\n",
      "Epoch: 56/100 Iteration: 1117 Training loss: 0.42333 Train Acc: 0.86067\n",
      "Epoch: 56/100 Iteration: 1118 Training loss: 0.39308 Train Acc: 0.86545\n",
      "Epoch: 56/100 Iteration: 1119 Training loss: 0.40124 Train Acc: 0.86465\n",
      "Epoch: 56/100 Iteration: 1120 Validation Acc: 0.8662\n",
      "Epoch: 57/100 Iteration: 1120 Training loss: 0.40689 Train Acc: 0.86783\n",
      "Epoch: 57/100 Iteration: 1121 Training loss: 0.42173 Train Acc: 0.86704\n",
      "Epoch: 57/100 Iteration: 1122 Training loss: 0.40631 Train Acc: 0.87500\n",
      "Epoch: 57/100 Iteration: 1123 Training loss: 0.40915 Train Acc: 0.87102\n",
      "Epoch: 57/100 Iteration: 1124 Training loss: 0.38743 Train Acc: 0.87182\n",
      "Epoch: 57/100 Iteration: 1125 Validation Acc: 0.8694\n",
      "Epoch: 57/100 Iteration: 1125 Training loss: 0.42895 Train Acc: 0.86704\n",
      "Epoch: 57/100 Iteration: 1126 Training loss: 0.41858 Train Acc: 0.86783\n",
      "Epoch: 57/100 Iteration: 1127 Training loss: 0.39853 Train Acc: 0.86704\n",
      "Epoch: 57/100 Iteration: 1128 Training loss: 0.39995 Train Acc: 0.86863\n",
      "Epoch: 57/100 Iteration: 1129 Training loss: 0.43380 Train Acc: 0.86783\n",
      "Epoch: 57/100 Iteration: 1130 Validation Acc: 0.8718\n",
      "Epoch: 57/100 Iteration: 1130 Training loss: 0.40256 Train Acc: 0.86624\n",
      "Epoch: 57/100 Iteration: 1131 Training loss: 0.43519 Train Acc: 0.85828\n",
      "Epoch: 57/100 Iteration: 1132 Training loss: 0.40772 Train Acc: 0.86067\n",
      "Epoch: 57/100 Iteration: 1133 Training loss: 0.39912 Train Acc: 0.85828\n",
      "Epoch: 57/100 Iteration: 1134 Training loss: 0.41447 Train Acc: 0.86385\n",
      "Epoch: 57/100 Iteration: 1135 Validation Acc: 0.8543\n",
      "Epoch: 57/100 Iteration: 1135 Training loss: 0.41555 Train Acc: 0.85908\n",
      "Epoch: 57/100 Iteration: 1136 Training loss: 0.43028 Train Acc: 0.86545\n",
      "Epoch: 57/100 Iteration: 1137 Training loss: 0.41807 Train Acc: 0.86067\n",
      "Epoch: 57/100 Iteration: 1138 Training loss: 0.40434 Train Acc: 0.86545\n",
      "Epoch: 57/100 Iteration: 1139 Training loss: 0.39934 Train Acc: 0.85271\n",
      "Epoch: 57/100 Iteration: 1140 Validation Acc: 0.8631\n",
      "Epoch: 58/100 Iteration: 1140 Training loss: 0.41166 Train Acc: 0.86385\n",
      "Epoch: 58/100 Iteration: 1141 Training loss: 0.43035 Train Acc: 0.87500\n",
      "Epoch: 58/100 Iteration: 1142 Training loss: 0.39355 Train Acc: 0.86226\n",
      "Epoch: 58/100 Iteration: 1143 Training loss: 0.37807 Train Acc: 0.87102\n",
      "Epoch: 58/100 Iteration: 1144 Training loss: 0.39180 Train Acc: 0.87182\n",
      "Epoch: 58/100 Iteration: 1145 Validation Acc: 0.8639\n",
      "Epoch: 58/100 Iteration: 1145 Training loss: 0.42160 Train Acc: 0.86545\n",
      "Epoch: 58/100 Iteration: 1146 Training loss: 0.42173 Train Acc: 0.87261\n",
      "Epoch: 58/100 Iteration: 1147 Training loss: 0.39876 Train Acc: 0.87580\n",
      "Epoch: 58/100 Iteration: 1148 Training loss: 0.39345 Train Acc: 0.87261\n",
      "Epoch: 58/100 Iteration: 1149 Training loss: 0.43985 Train Acc: 0.86624\n",
      "Epoch: 58/100 Iteration: 1150 Validation Acc: 0.8639\n",
      "Epoch: 58/100 Iteration: 1150 Training loss: 0.40466 Train Acc: 0.86783\n",
      "Epoch: 58/100 Iteration: 1151 Training loss: 0.41681 Train Acc: 0.87818\n",
      "Epoch: 58/100 Iteration: 1152 Training loss: 0.40502 Train Acc: 0.87261\n",
      "Epoch: 58/100 Iteration: 1153 Training loss: 0.39068 Train Acc: 0.86943\n",
      "Epoch: 58/100 Iteration: 1154 Training loss: 0.41265 Train Acc: 0.86624\n",
      "Epoch: 58/100 Iteration: 1155 Validation Acc: 0.8750\n",
      "Epoch: 58/100 Iteration: 1155 Training loss: 0.39338 Train Acc: 0.87580\n",
      "Epoch: 58/100 Iteration: 1156 Training loss: 0.43544 Train Acc: 0.86943\n",
      "Epoch: 58/100 Iteration: 1157 Training loss: 0.42181 Train Acc: 0.86943\n",
      "Epoch: 58/100 Iteration: 1158 Training loss: 0.41691 Train Acc: 0.85828\n",
      "Epoch: 58/100 Iteration: 1159 Training loss: 0.39175 Train Acc: 0.86704\n",
      "Epoch: 58/100 Iteration: 1160 Validation Acc: 0.8662\n",
      "Epoch: 59/100 Iteration: 1160 Training loss: 0.39652 Train Acc: 0.87022\n",
      "Epoch: 59/100 Iteration: 1161 Training loss: 0.43185 Train Acc: 0.86067\n",
      "Epoch: 59/100 Iteration: 1162 Training loss: 0.39297 Train Acc: 0.86863\n",
      "Epoch: 59/100 Iteration: 1163 Training loss: 0.40754 Train Acc: 0.86624\n",
      "Epoch: 59/100 Iteration: 1164 Training loss: 0.39512 Train Acc: 0.86465\n",
      "Epoch: 59/100 Iteration: 1165 Validation Acc: 0.8631\n",
      "Epoch: 59/100 Iteration: 1165 Training loss: 0.42501 Train Acc: 0.87182\n",
      "Epoch: 59/100 Iteration: 1166 Training loss: 0.42301 Train Acc: 0.85828\n",
      "Epoch: 59/100 Iteration: 1167 Training loss: 0.39671 Train Acc: 0.87022\n",
      "Epoch: 59/100 Iteration: 1168 Training loss: 0.43281 Train Acc: 0.86385\n",
      "Epoch: 59/100 Iteration: 1169 Training loss: 0.45681 Train Acc: 0.85908\n",
      "Epoch: 59/100 Iteration: 1170 Validation Acc: 0.8631\n",
      "Epoch: 59/100 Iteration: 1170 Training loss: 0.43349 Train Acc: 0.85987\n",
      "Epoch: 59/100 Iteration: 1171 Training loss: 0.40118 Train Acc: 0.85828\n",
      "Epoch: 59/100 Iteration: 1172 Training loss: 0.41767 Train Acc: 0.85669\n",
      "Epoch: 59/100 Iteration: 1173 Training loss: 0.41657 Train Acc: 0.85510\n",
      "Epoch: 59/100 Iteration: 1174 Training loss: 0.42331 Train Acc: 0.85987\n",
      "Epoch: 59/100 Iteration: 1175 Validation Acc: 0.8615\n",
      "Epoch: 59/100 Iteration: 1175 Training loss: 0.39574 Train Acc: 0.85748\n",
      "Epoch: 59/100 Iteration: 1176 Training loss: 0.43564 Train Acc: 0.85589\n",
      "Epoch: 59/100 Iteration: 1177 Training loss: 0.40883 Train Acc: 0.85271\n",
      "Epoch: 59/100 Iteration: 1178 Training loss: 0.40765 Train Acc: 0.86146\n",
      "Epoch: 59/100 Iteration: 1179 Training loss: 0.41030 Train Acc: 0.86226\n",
      "Epoch: 59/100 Iteration: 1180 Validation Acc: 0.8694\n",
      "Epoch: 60/100 Iteration: 1180 Training loss: 0.41257 Train Acc: 0.87898\n",
      "Epoch: 60/100 Iteration: 1181 Training loss: 0.42194 Train Acc: 0.86863\n",
      "Epoch: 60/100 Iteration: 1182 Training loss: 0.39054 Train Acc: 0.86624\n",
      "Epoch: 60/100 Iteration: 1183 Training loss: 0.40611 Train Acc: 0.85430\n",
      "Epoch: 60/100 Iteration: 1184 Training loss: 0.37490 Train Acc: 0.86385\n",
      "Epoch: 60/100 Iteration: 1185 Validation Acc: 0.8615\n",
      "Epoch: 60/100 Iteration: 1185 Training loss: 0.41845 Train Acc: 0.86067\n",
      "Epoch: 60/100 Iteration: 1186 Training loss: 0.43828 Train Acc: 0.86624\n",
      "Epoch: 60/100 Iteration: 1187 Training loss: 0.42970 Train Acc: 0.86624\n",
      "Epoch: 60/100 Iteration: 1188 Training loss: 0.39248 Train Acc: 0.86704\n",
      "Epoch: 60/100 Iteration: 1189 Training loss: 0.46503 Train Acc: 0.85589\n",
      "Epoch: 60/100 Iteration: 1190 Validation Acc: 0.8551\n",
      "Epoch: 60/100 Iteration: 1190 Training loss: 0.41000 Train Acc: 0.86863\n",
      "Epoch: 60/100 Iteration: 1191 Training loss: 0.41358 Train Acc: 0.85987\n",
      "Epoch: 60/100 Iteration: 1192 Training loss: 0.42954 Train Acc: 0.85191\n",
      "Epoch: 60/100 Iteration: 1193 Training loss: 0.40168 Train Acc: 0.86067\n",
      "Epoch: 60/100 Iteration: 1194 Training loss: 0.43432 Train Acc: 0.85908\n",
      "Epoch: 60/100 Iteration: 1195 Validation Acc: 0.8702\n",
      "Epoch: 60/100 Iteration: 1195 Training loss: 0.42311 Train Acc: 0.86704\n",
      "Epoch: 60/100 Iteration: 1196 Training loss: 0.43402 Train Acc: 0.86863\n",
      "Epoch: 60/100 Iteration: 1197 Training loss: 0.40027 Train Acc: 0.86545\n",
      "Epoch: 60/100 Iteration: 1198 Training loss: 0.40858 Train Acc: 0.86146\n",
      "Epoch: 60/100 Iteration: 1199 Training loss: 0.38910 Train Acc: 0.86545\n",
      "Epoch: 60/100 Iteration: 1200 Validation Acc: 0.8559\n",
      "Epoch: 61/100 Iteration: 1200 Training loss: 0.41511 Train Acc: 0.84873\n",
      "Epoch: 61/100 Iteration: 1201 Training loss: 0.43755 Train Acc: 0.84873\n",
      "Epoch: 61/100 Iteration: 1202 Training loss: 0.40480 Train Acc: 0.85748\n",
      "Epoch: 61/100 Iteration: 1203 Training loss: 0.39290 Train Acc: 0.85748\n",
      "Epoch: 61/100 Iteration: 1204 Training loss: 0.40113 Train Acc: 0.86226\n",
      "Epoch: 61/100 Iteration: 1205 Validation Acc: 0.8599\n",
      "Epoch: 61/100 Iteration: 1205 Training loss: 0.41849 Train Acc: 0.86624\n",
      "Epoch: 61/100 Iteration: 1206 Training loss: 0.43998 Train Acc: 0.86146\n",
      "Epoch: 61/100 Iteration: 1207 Training loss: 0.41051 Train Acc: 0.86465\n",
      "Epoch: 61/100 Iteration: 1208 Training loss: 0.41048 Train Acc: 0.86624\n",
      "Epoch: 61/100 Iteration: 1209 Training loss: 0.46542 Train Acc: 0.86385\n",
      "Epoch: 61/100 Iteration: 1210 Validation Acc: 0.8567\n",
      "Epoch: 61/100 Iteration: 1210 Training loss: 0.41735 Train Acc: 0.86385\n",
      "Epoch: 61/100 Iteration: 1211 Training loss: 0.38920 Train Acc: 0.87420\n",
      "Epoch: 61/100 Iteration: 1212 Training loss: 0.41263 Train Acc: 0.87261\n",
      "Epoch: 61/100 Iteration: 1213 Training loss: 0.41278 Train Acc: 0.86704\n",
      "Epoch: 61/100 Iteration: 1214 Training loss: 0.41371 Train Acc: 0.87102\n",
      "Epoch: 61/100 Iteration: 1215 Validation Acc: 0.8686\n",
      "Epoch: 61/100 Iteration: 1215 Training loss: 0.42099 Train Acc: 0.87420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 61/100 Iteration: 1216 Training loss: 0.43881 Train Acc: 0.86545\n",
      "Epoch: 61/100 Iteration: 1217 Training loss: 0.39943 Train Acc: 0.88217\n",
      "Epoch: 61/100 Iteration: 1218 Training loss: 0.40718 Train Acc: 0.87341\n",
      "Epoch: 61/100 Iteration: 1219 Training loss: 0.38010 Train Acc: 0.88057\n",
      "Epoch: 61/100 Iteration: 1220 Validation Acc: 0.8702\n",
      "Epoch: 62/100 Iteration: 1220 Training loss: 0.41957 Train Acc: 0.86624\n",
      "Epoch: 62/100 Iteration: 1221 Training loss: 0.41601 Train Acc: 0.88296\n",
      "Epoch: 62/100 Iteration: 1222 Training loss: 0.38592 Train Acc: 0.88137\n",
      "Epoch: 62/100 Iteration: 1223 Training loss: 0.40868 Train Acc: 0.87580\n",
      "Epoch: 62/100 Iteration: 1224 Training loss: 0.38925 Train Acc: 0.87102\n",
      "Epoch: 62/100 Iteration: 1225 Validation Acc: 0.8774\n",
      "Epoch: 62/100 Iteration: 1225 Training loss: 0.41261 Train Acc: 0.87978\n",
      "Epoch: 62/100 Iteration: 1226 Training loss: 0.41276 Train Acc: 0.87182\n",
      "Epoch: 62/100 Iteration: 1227 Training loss: 0.40464 Train Acc: 0.87182\n",
      "Epoch: 62/100 Iteration: 1228 Training loss: 0.41584 Train Acc: 0.87739\n",
      "Epoch: 62/100 Iteration: 1229 Training loss: 0.44447 Train Acc: 0.88296\n",
      "Epoch: 62/100 Iteration: 1230 Validation Acc: 0.8742\n",
      "Epoch: 62/100 Iteration: 1230 Training loss: 0.41730 Train Acc: 0.87102\n",
      "Epoch: 62/100 Iteration: 1231 Training loss: 0.41081 Train Acc: 0.87420\n",
      "Epoch: 62/100 Iteration: 1232 Training loss: 0.40608 Train Acc: 0.87898\n",
      "Epoch: 62/100 Iteration: 1233 Training loss: 0.41111 Train Acc: 0.87261\n",
      "Epoch: 62/100 Iteration: 1234 Training loss: 0.40655 Train Acc: 0.86146\n",
      "Epoch: 62/100 Iteration: 1235 Validation Acc: 0.8790\n",
      "Epoch: 62/100 Iteration: 1235 Training loss: 0.39053 Train Acc: 0.87182\n",
      "Epoch: 62/100 Iteration: 1236 Training loss: 0.42762 Train Acc: 0.87182\n",
      "Epoch: 62/100 Iteration: 1237 Training loss: 0.39720 Train Acc: 0.86146\n",
      "Epoch: 62/100 Iteration: 1238 Training loss: 0.40900 Train Acc: 0.87500\n",
      "Epoch: 62/100 Iteration: 1239 Training loss: 0.38187 Train Acc: 0.85987\n",
      "Epoch: 62/100 Iteration: 1240 Validation Acc: 0.8583\n",
      "Epoch: 63/100 Iteration: 1240 Training loss: 0.40472 Train Acc: 0.86545\n",
      "Epoch: 63/100 Iteration: 1241 Training loss: 0.44097 Train Acc: 0.86545\n",
      "Epoch: 63/100 Iteration: 1242 Training loss: 0.39557 Train Acc: 0.85510\n",
      "Epoch: 63/100 Iteration: 1243 Training loss: 0.38870 Train Acc: 0.85111\n",
      "Epoch: 63/100 Iteration: 1244 Training loss: 0.38650 Train Acc: 0.86704\n",
      "Epoch: 63/100 Iteration: 1245 Validation Acc: 0.8702\n",
      "Epoch: 63/100 Iteration: 1245 Training loss: 0.43105 Train Acc: 0.85987\n",
      "Epoch: 63/100 Iteration: 1246 Training loss: 0.42766 Train Acc: 0.85908\n",
      "Epoch: 63/100 Iteration: 1247 Training loss: 0.41896 Train Acc: 0.87022\n",
      "Epoch: 63/100 Iteration: 1248 Training loss: 0.39486 Train Acc: 0.86226\n",
      "Epoch: 63/100 Iteration: 1249 Training loss: 0.44416 Train Acc: 0.87500\n",
      "Epoch: 63/100 Iteration: 1250 Validation Acc: 0.8591\n",
      "Epoch: 63/100 Iteration: 1250 Training loss: 0.42096 Train Acc: 0.86704\n",
      "Epoch: 63/100 Iteration: 1251 Training loss: 0.42901 Train Acc: 0.88057\n",
      "Epoch: 63/100 Iteration: 1252 Training loss: 0.41197 Train Acc: 0.86385\n",
      "Epoch: 63/100 Iteration: 1253 Training loss: 0.43999 Train Acc: 0.86067\n",
      "Epoch: 63/100 Iteration: 1254 Training loss: 0.41028 Train Acc: 0.84952\n",
      "Epoch: 63/100 Iteration: 1255 Validation Acc: 0.8678\n",
      "Epoch: 63/100 Iteration: 1255 Training loss: 0.39464 Train Acc: 0.85669\n",
      "Epoch: 63/100 Iteration: 1256 Training loss: 0.43750 Train Acc: 0.85828\n",
      "Epoch: 63/100 Iteration: 1257 Training loss: 0.39695 Train Acc: 0.85828\n",
      "Epoch: 63/100 Iteration: 1258 Training loss: 0.40607 Train Acc: 0.86624\n",
      "Epoch: 63/100 Iteration: 1259 Training loss: 0.39207 Train Acc: 0.86545\n",
      "Epoch: 63/100 Iteration: 1260 Validation Acc: 0.8694\n",
      "Epoch: 64/100 Iteration: 1260 Training loss: 0.42365 Train Acc: 0.86146\n",
      "Epoch: 64/100 Iteration: 1261 Training loss: 0.43728 Train Acc: 0.86067\n",
      "Epoch: 64/100 Iteration: 1262 Training loss: 0.40454 Train Acc: 0.86306\n",
      "Epoch: 64/100 Iteration: 1263 Training loss: 0.41683 Train Acc: 0.85748\n",
      "Epoch: 64/100 Iteration: 1264 Training loss: 0.40307 Train Acc: 0.87341\n",
      "Epoch: 64/100 Iteration: 1265 Validation Acc: 0.8702\n",
      "Epoch: 64/100 Iteration: 1265 Training loss: 0.41460 Train Acc: 0.85908\n",
      "Epoch: 64/100 Iteration: 1266 Training loss: 0.44287 Train Acc: 0.86863\n",
      "Epoch: 64/100 Iteration: 1267 Training loss: 0.39638 Train Acc: 0.86306\n",
      "Epoch: 64/100 Iteration: 1268 Training loss: 0.42539 Train Acc: 0.86385\n",
      "Epoch: 64/100 Iteration: 1269 Training loss: 0.44044 Train Acc: 0.87102\n",
      "Epoch: 64/100 Iteration: 1270 Validation Acc: 0.8686\n",
      "Epoch: 64/100 Iteration: 1270 Training loss: 0.42229 Train Acc: 0.86624\n",
      "Epoch: 64/100 Iteration: 1271 Training loss: 0.39595 Train Acc: 0.87022\n",
      "Epoch: 64/100 Iteration: 1272 Training loss: 0.42580 Train Acc: 0.87182\n",
      "Epoch: 64/100 Iteration: 1273 Training loss: 0.43308 Train Acc: 0.87022\n",
      "Epoch: 64/100 Iteration: 1274 Training loss: 0.41119 Train Acc: 0.87022\n",
      "Epoch: 64/100 Iteration: 1275 Validation Acc: 0.8830\n",
      "Epoch: 64/100 Iteration: 1275 Training loss: 0.40925 Train Acc: 0.88137\n",
      "Epoch: 64/100 Iteration: 1276 Training loss: 0.42081 Train Acc: 0.87818\n",
      "Epoch: 64/100 Iteration: 1277 Training loss: 0.42053 Train Acc: 0.88057\n",
      "Epoch: 64/100 Iteration: 1278 Training loss: 0.38560 Train Acc: 0.88057\n",
      "Epoch: 64/100 Iteration: 1279 Training loss: 0.39528 Train Acc: 0.86465\n",
      "Epoch: 64/100 Iteration: 1280 Validation Acc: 0.8798\n",
      "Epoch: 65/100 Iteration: 1280 Training loss: 0.40429 Train Acc: 0.87500\n",
      "Epoch: 65/100 Iteration: 1281 Training loss: 0.42962 Train Acc: 0.86465\n",
      "Epoch: 65/100 Iteration: 1282 Training loss: 0.38524 Train Acc: 0.86624\n",
      "Epoch: 65/100 Iteration: 1283 Training loss: 0.41081 Train Acc: 0.87341\n",
      "Epoch: 65/100 Iteration: 1284 Training loss: 0.39340 Train Acc: 0.87580\n",
      "Epoch: 65/100 Iteration: 1285 Validation Acc: 0.8702\n",
      "Epoch: 65/100 Iteration: 1285 Training loss: 0.41721 Train Acc: 0.86943\n",
      "Epoch: 65/100 Iteration: 1286 Training loss: 0.42763 Train Acc: 0.87898\n",
      "Epoch: 65/100 Iteration: 1287 Training loss: 0.41127 Train Acc: 0.87102\n",
      "Epoch: 65/100 Iteration: 1288 Training loss: 0.40151 Train Acc: 0.87261\n",
      "Epoch: 65/100 Iteration: 1289 Training loss: 0.43750 Train Acc: 0.86385\n",
      "Epoch: 65/100 Iteration: 1290 Validation Acc: 0.8726\n",
      "Epoch: 65/100 Iteration: 1290 Training loss: 0.42604 Train Acc: 0.86146\n",
      "Epoch: 65/100 Iteration: 1291 Training loss: 0.40045 Train Acc: 0.87659\n",
      "Epoch: 65/100 Iteration: 1292 Training loss: 0.41206 Train Acc: 0.86385\n",
      "Epoch: 65/100 Iteration: 1293 Training loss: 0.40136 Train Acc: 0.86704\n",
      "Epoch: 65/100 Iteration: 1294 Training loss: 0.40956 Train Acc: 0.85987\n",
      "Epoch: 65/100 Iteration: 1295 Validation Acc: 0.8694\n",
      "Epoch: 65/100 Iteration: 1295 Training loss: 0.40591 Train Acc: 0.88057\n",
      "Epoch: 65/100 Iteration: 1296 Training loss: 0.43577 Train Acc: 0.86943\n",
      "Epoch: 65/100 Iteration: 1297 Training loss: 0.42515 Train Acc: 0.87898\n",
      "Epoch: 65/100 Iteration: 1298 Training loss: 0.39830 Train Acc: 0.87898\n",
      "Epoch: 65/100 Iteration: 1299 Training loss: 0.39402 Train Acc: 0.88217\n",
      "Epoch: 65/100 Iteration: 1300 Validation Acc: 0.8774\n",
      "Epoch: 66/100 Iteration: 1300 Training loss: 0.41495 Train Acc: 0.88615\n",
      "Epoch: 66/100 Iteration: 1301 Training loss: 0.42415 Train Acc: 0.87341\n",
      "Epoch: 66/100 Iteration: 1302 Training loss: 0.38505 Train Acc: 0.87580\n",
      "Epoch: 66/100 Iteration: 1303 Training loss: 0.40571 Train Acc: 0.87978\n",
      "Epoch: 66/100 Iteration: 1304 Training loss: 0.38190 Train Acc: 0.86306\n",
      "Epoch: 66/100 Iteration: 1305 Validation Acc: 0.8631\n",
      "Epoch: 66/100 Iteration: 1305 Training loss: 0.41804 Train Acc: 0.87022\n",
      "Epoch: 66/100 Iteration: 1306 Training loss: 0.41403 Train Acc: 0.87898\n",
      "Epoch: 66/100 Iteration: 1307 Training loss: 0.40557 Train Acc: 0.88057\n",
      "Epoch: 66/100 Iteration: 1308 Training loss: 0.39602 Train Acc: 0.86704\n",
      "Epoch: 66/100 Iteration: 1309 Training loss: 0.43515 Train Acc: 0.86385\n",
      "Epoch: 66/100 Iteration: 1310 Validation Acc: 0.8599\n",
      "Epoch: 66/100 Iteration: 1310 Training loss: 0.40706 Train Acc: 0.87500\n",
      "Epoch: 66/100 Iteration: 1311 Training loss: 0.38392 Train Acc: 0.85589\n",
      "Epoch: 66/100 Iteration: 1312 Training loss: 0.42893 Train Acc: 0.85908\n",
      "Epoch: 66/100 Iteration: 1313 Training loss: 0.40795 Train Acc: 0.85032\n",
      "Epoch: 66/100 Iteration: 1314 Training loss: 0.43651 Train Acc: 0.84713\n",
      "Epoch: 66/100 Iteration: 1315 Validation Acc: 0.8607\n",
      "Epoch: 66/100 Iteration: 1315 Training loss: 0.39787 Train Acc: 0.85430\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 66/100 Iteration: 1316 Training loss: 0.42213 Train Acc: 0.85748\n",
      "Epoch: 66/100 Iteration: 1317 Training loss: 0.43071 Train Acc: 0.86146\n",
      "Epoch: 66/100 Iteration: 1318 Training loss: 0.40196 Train Acc: 0.86704\n",
      "Epoch: 66/100 Iteration: 1319 Training loss: 0.39699 Train Acc: 0.86385\n",
      "Epoch: 66/100 Iteration: 1320 Validation Acc: 0.8686\n",
      "Epoch: 67/100 Iteration: 1320 Training loss: 0.41029 Train Acc: 0.86943\n",
      "Epoch: 67/100 Iteration: 1321 Training loss: 0.41728 Train Acc: 0.87261\n",
      "Epoch: 67/100 Iteration: 1322 Training loss: 0.38930 Train Acc: 0.87022\n",
      "Epoch: 67/100 Iteration: 1323 Training loss: 0.39951 Train Acc: 0.87022\n",
      "Epoch: 67/100 Iteration: 1324 Training loss: 0.38419 Train Acc: 0.87022\n",
      "Epoch: 67/100 Iteration: 1325 Validation Acc: 0.8790\n",
      "Epoch: 67/100 Iteration: 1325 Training loss: 0.40592 Train Acc: 0.87500\n",
      "Epoch: 67/100 Iteration: 1326 Training loss: 0.42988 Train Acc: 0.86465\n",
      "Epoch: 67/100 Iteration: 1327 Training loss: 0.39031 Train Acc: 0.87261\n",
      "Epoch: 67/100 Iteration: 1328 Training loss: 0.40219 Train Acc: 0.86306\n",
      "Epoch: 67/100 Iteration: 1329 Training loss: 0.44156 Train Acc: 0.86783\n",
      "Epoch: 67/100 Iteration: 1330 Validation Acc: 0.8782\n",
      "Epoch: 67/100 Iteration: 1330 Training loss: 0.41813 Train Acc: 0.87978\n",
      "Epoch: 67/100 Iteration: 1331 Training loss: 0.39858 Train Acc: 0.87022\n",
      "Epoch: 67/100 Iteration: 1332 Training loss: 0.40821 Train Acc: 0.88694\n",
      "Epoch: 67/100 Iteration: 1333 Training loss: 0.40479 Train Acc: 0.87420\n",
      "Epoch: 67/100 Iteration: 1334 Training loss: 0.41110 Train Acc: 0.86943\n",
      "Epoch: 67/100 Iteration: 1335 Validation Acc: 0.8702\n",
      "Epoch: 67/100 Iteration: 1335 Training loss: 0.39384 Train Acc: 0.86943\n",
      "Epoch: 67/100 Iteration: 1336 Training loss: 0.43430 Train Acc: 0.86704\n",
      "Epoch: 67/100 Iteration: 1337 Training loss: 0.40098 Train Acc: 0.87182\n",
      "Epoch: 67/100 Iteration: 1338 Training loss: 0.38001 Train Acc: 0.87420\n",
      "Epoch: 67/100 Iteration: 1339 Training loss: 0.38850 Train Acc: 0.86067\n",
      "Epoch: 67/100 Iteration: 1340 Validation Acc: 0.8718\n",
      "Epoch: 68/100 Iteration: 1340 Training loss: 0.39152 Train Acc: 0.86465\n",
      "Epoch: 68/100 Iteration: 1341 Training loss: 0.41875 Train Acc: 0.86146\n",
      "Epoch: 68/100 Iteration: 1342 Training loss: 0.39203 Train Acc: 0.86943\n",
      "Epoch: 68/100 Iteration: 1343 Training loss: 0.39940 Train Acc: 0.86226\n",
      "Epoch: 68/100 Iteration: 1344 Training loss: 0.37839 Train Acc: 0.86067\n",
      "Epoch: 68/100 Iteration: 1345 Validation Acc: 0.8694\n",
      "Epoch: 68/100 Iteration: 1345 Training loss: 0.40199 Train Acc: 0.85987\n",
      "Epoch: 68/100 Iteration: 1346 Training loss: 0.42472 Train Acc: 0.85828\n",
      "Epoch: 68/100 Iteration: 1347 Training loss: 0.40066 Train Acc: 0.86624\n",
      "Epoch: 68/100 Iteration: 1348 Training loss: 0.40483 Train Acc: 0.86624\n",
      "Epoch: 68/100 Iteration: 1349 Training loss: 0.45848 Train Acc: 0.86465\n",
      "Epoch: 68/100 Iteration: 1350 Validation Acc: 0.8678\n",
      "Epoch: 68/100 Iteration: 1350 Training loss: 0.43491 Train Acc: 0.86226\n",
      "Epoch: 68/100 Iteration: 1351 Training loss: 0.42091 Train Acc: 0.86385\n",
      "Epoch: 68/100 Iteration: 1352 Training loss: 0.41353 Train Acc: 0.85748\n",
      "Epoch: 68/100 Iteration: 1353 Training loss: 0.43992 Train Acc: 0.86465\n",
      "Epoch: 68/100 Iteration: 1354 Training loss: 0.40992 Train Acc: 0.87420\n",
      "Epoch: 68/100 Iteration: 1355 Validation Acc: 0.8631\n",
      "Epoch: 68/100 Iteration: 1355 Training loss: 0.39542 Train Acc: 0.85510\n",
      "Epoch: 68/100 Iteration: 1356 Training loss: 0.41124 Train Acc: 0.86863\n",
      "Epoch: 68/100 Iteration: 1357 Training loss: 0.41731 Train Acc: 0.87022\n",
      "Epoch: 68/100 Iteration: 1358 Training loss: 0.39093 Train Acc: 0.87341\n",
      "Epoch: 68/100 Iteration: 1359 Training loss: 0.38885 Train Acc: 0.87102\n",
      "Epoch: 68/100 Iteration: 1360 Validation Acc: 0.8670\n",
      "Epoch: 69/100 Iteration: 1360 Training loss: 0.40846 Train Acc: 0.87261\n",
      "Epoch: 69/100 Iteration: 1361 Training loss: 0.42575 Train Acc: 0.86545\n",
      "Epoch: 69/100 Iteration: 1362 Training loss: 0.39391 Train Acc: 0.86863\n",
      "Epoch: 69/100 Iteration: 1363 Training loss: 0.39607 Train Acc: 0.87261\n",
      "Epoch: 69/100 Iteration: 1364 Training loss: 0.38070 Train Acc: 0.87659\n",
      "Epoch: 69/100 Iteration: 1365 Validation Acc: 0.8782\n",
      "Epoch: 69/100 Iteration: 1365 Training loss: 0.42118 Train Acc: 0.87420\n",
      "Epoch: 69/100 Iteration: 1366 Training loss: 0.41656 Train Acc: 0.87978\n",
      "Epoch: 69/100 Iteration: 1367 Training loss: 0.40892 Train Acc: 0.87420\n",
      "Epoch: 69/100 Iteration: 1368 Training loss: 0.38122 Train Acc: 0.87102\n",
      "Epoch: 69/100 Iteration: 1369 Training loss: 0.44457 Train Acc: 0.86306\n",
      "Epoch: 69/100 Iteration: 1370 Validation Acc: 0.8758\n",
      "Epoch: 69/100 Iteration: 1370 Training loss: 0.40391 Train Acc: 0.86783\n",
      "Epoch: 69/100 Iteration: 1371 Training loss: 0.41573 Train Acc: 0.87341\n",
      "Epoch: 69/100 Iteration: 1372 Training loss: 0.40301 Train Acc: 0.87500\n",
      "Epoch: 69/100 Iteration: 1373 Training loss: 0.40487 Train Acc: 0.87341\n",
      "Epoch: 69/100 Iteration: 1374 Training loss: 0.41031 Train Acc: 0.86783\n",
      "Epoch: 69/100 Iteration: 1375 Validation Acc: 0.8631\n",
      "Epoch: 69/100 Iteration: 1375 Training loss: 0.40100 Train Acc: 0.86704\n",
      "Epoch: 69/100 Iteration: 1376 Training loss: 0.42305 Train Acc: 0.86943\n",
      "Epoch: 69/100 Iteration: 1377 Training loss: 0.40846 Train Acc: 0.87739\n",
      "Epoch: 69/100 Iteration: 1378 Training loss: 0.38249 Train Acc: 0.87818\n",
      "Epoch: 69/100 Iteration: 1379 Training loss: 0.39341 Train Acc: 0.87978\n",
      "Epoch: 69/100 Iteration: 1380 Validation Acc: 0.8782\n",
      "Epoch: 70/100 Iteration: 1380 Training loss: 0.38398 Train Acc: 0.87341\n",
      "Epoch: 70/100 Iteration: 1381 Training loss: 0.42859 Train Acc: 0.86863\n",
      "Epoch: 70/100 Iteration: 1382 Training loss: 0.38929 Train Acc: 0.87580\n",
      "Epoch: 70/100 Iteration: 1383 Training loss: 0.38930 Train Acc: 0.88137\n",
      "Epoch: 70/100 Iteration: 1384 Training loss: 0.39550 Train Acc: 0.88296\n",
      "Epoch: 70/100 Iteration: 1385 Validation Acc: 0.8806\n",
      "Epoch: 70/100 Iteration: 1385 Training loss: 0.40378 Train Acc: 0.87420\n",
      "Epoch: 70/100 Iteration: 1386 Training loss: 0.43893 Train Acc: 0.86863\n",
      "Epoch: 70/100 Iteration: 1387 Training loss: 0.40388 Train Acc: 0.87420\n",
      "Epoch: 70/100 Iteration: 1388 Training loss: 0.37977 Train Acc: 0.87420\n",
      "Epoch: 70/100 Iteration: 1389 Training loss: 0.44511 Train Acc: 0.88057\n",
      "Epoch: 70/100 Iteration: 1390 Validation Acc: 0.8726\n",
      "Epoch: 70/100 Iteration: 1390 Training loss: 0.39615 Train Acc: 0.87580\n",
      "Epoch: 70/100 Iteration: 1391 Training loss: 0.41672 Train Acc: 0.86146\n",
      "Epoch: 70/100 Iteration: 1392 Training loss: 0.41618 Train Acc: 0.87102\n",
      "Epoch: 70/100 Iteration: 1393 Training loss: 0.40578 Train Acc: 0.86545\n",
      "Epoch: 70/100 Iteration: 1394 Training loss: 0.40593 Train Acc: 0.86943\n",
      "Epoch: 70/100 Iteration: 1395 Validation Acc: 0.8575\n",
      "Epoch: 70/100 Iteration: 1395 Training loss: 0.42535 Train Acc: 0.85987\n",
      "Epoch: 70/100 Iteration: 1396 Training loss: 0.44282 Train Acc: 0.86306\n",
      "Epoch: 70/100 Iteration: 1397 Training loss: 0.40029 Train Acc: 0.86943\n",
      "Epoch: 70/100 Iteration: 1398 Training loss: 0.40942 Train Acc: 0.86465\n",
      "Epoch: 70/100 Iteration: 1399 Training loss: 0.39489 Train Acc: 0.85510\n",
      "Epoch: 70/100 Iteration: 1400 Validation Acc: 0.8639\n",
      "Epoch: 71/100 Iteration: 1400 Training loss: 0.38524 Train Acc: 0.86704\n",
      "Epoch: 71/100 Iteration: 1401 Training loss: 0.41552 Train Acc: 0.85510\n",
      "Epoch: 71/100 Iteration: 1402 Training loss: 0.38818 Train Acc: 0.85987\n",
      "Epoch: 71/100 Iteration: 1403 Training loss: 0.39182 Train Acc: 0.87022\n",
      "Epoch: 71/100 Iteration: 1404 Training loss: 0.36815 Train Acc: 0.87580\n",
      "Epoch: 71/100 Iteration: 1405 Validation Acc: 0.8662\n",
      "Epoch: 71/100 Iteration: 1405 Training loss: 0.41751 Train Acc: 0.87659\n",
      "Epoch: 71/100 Iteration: 1406 Training loss: 0.41920 Train Acc: 0.86465\n",
      "Epoch: 71/100 Iteration: 1407 Training loss: 0.38760 Train Acc: 0.87978\n",
      "Epoch: 71/100 Iteration: 1408 Training loss: 0.37805 Train Acc: 0.87818\n",
      "Epoch: 71/100 Iteration: 1409 Training loss: 0.44433 Train Acc: 0.87739\n",
      "Epoch: 71/100 Iteration: 1410 Validation Acc: 0.8877\n",
      "Epoch: 71/100 Iteration: 1410 Training loss: 0.39322 Train Acc: 0.86863\n",
      "Epoch: 71/100 Iteration: 1411 Training loss: 0.41704 Train Acc: 0.86545\n",
      "Epoch: 71/100 Iteration: 1412 Training loss: 0.40953 Train Acc: 0.87898\n",
      "Epoch: 71/100 Iteration: 1413 Training loss: 0.39511 Train Acc: 0.87102\n",
      "Epoch: 71/100 Iteration: 1414 Training loss: 0.39934 Train Acc: 0.87500\n",
      "Epoch: 71/100 Iteration: 1415 Validation Acc: 0.8702\n",
      "Epoch: 71/100 Iteration: 1415 Training loss: 0.40126 Train Acc: 0.87182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 71/100 Iteration: 1416 Training loss: 0.42205 Train Acc: 0.86306\n",
      "Epoch: 71/100 Iteration: 1417 Training loss: 0.39937 Train Acc: 0.88057\n",
      "Epoch: 71/100 Iteration: 1418 Training loss: 0.39227 Train Acc: 0.87261\n",
      "Epoch: 71/100 Iteration: 1419 Training loss: 0.38882 Train Acc: 0.87420\n",
      "Epoch: 71/100 Iteration: 1420 Validation Acc: 0.8615\n",
      "Epoch: 72/100 Iteration: 1420 Training loss: 0.39054 Train Acc: 0.85748\n",
      "Epoch: 72/100 Iteration: 1421 Training loss: 0.41799 Train Acc: 0.86067\n",
      "Epoch: 72/100 Iteration: 1422 Training loss: 0.38935 Train Acc: 0.88137\n",
      "Epoch: 72/100 Iteration: 1423 Training loss: 0.42807 Train Acc: 0.86943\n",
      "Epoch: 72/100 Iteration: 1424 Training loss: 0.38092 Train Acc: 0.87500\n",
      "Epoch: 72/100 Iteration: 1425 Validation Acc: 0.8686\n",
      "Epoch: 72/100 Iteration: 1425 Training loss: 0.42483 Train Acc: 0.87420\n",
      "Epoch: 72/100 Iteration: 1426 Training loss: 0.42438 Train Acc: 0.87659\n",
      "Epoch: 72/100 Iteration: 1427 Training loss: 0.38833 Train Acc: 0.88137\n",
      "Epoch: 72/100 Iteration: 1428 Training loss: 0.37389 Train Acc: 0.88137\n",
      "Epoch: 72/100 Iteration: 1429 Training loss: 0.41659 Train Acc: 0.88057\n",
      "Epoch: 72/100 Iteration: 1430 Validation Acc: 0.8750\n",
      "Epoch: 72/100 Iteration: 1430 Training loss: 0.40499 Train Acc: 0.88137\n",
      "Epoch: 72/100 Iteration: 1431 Training loss: 0.39669 Train Acc: 0.87818\n",
      "Epoch: 72/100 Iteration: 1432 Training loss: 0.39919 Train Acc: 0.87420\n",
      "Epoch: 72/100 Iteration: 1433 Training loss: 0.39470 Train Acc: 0.88296\n",
      "Epoch: 72/100 Iteration: 1434 Training loss: 0.40230 Train Acc: 0.86943\n",
      "Epoch: 72/100 Iteration: 1435 Validation Acc: 0.8830\n",
      "Epoch: 72/100 Iteration: 1435 Training loss: 0.43461 Train Acc: 0.87659\n",
      "Epoch: 72/100 Iteration: 1436 Training loss: 0.43048 Train Acc: 0.87739\n",
      "Epoch: 72/100 Iteration: 1437 Training loss: 0.40384 Train Acc: 0.87022\n",
      "Epoch: 72/100 Iteration: 1438 Training loss: 0.37900 Train Acc: 0.87659\n",
      "Epoch: 72/100 Iteration: 1439 Training loss: 0.38854 Train Acc: 0.88296\n",
      "Epoch: 72/100 Iteration: 1440 Validation Acc: 0.8734\n",
      "Epoch: 73/100 Iteration: 1440 Training loss: 0.38421 Train Acc: 0.87261\n",
      "Epoch: 73/100 Iteration: 1441 Training loss: 0.40523 Train Acc: 0.86306\n",
      "Epoch: 73/100 Iteration: 1442 Training loss: 0.38396 Train Acc: 0.87420\n",
      "Epoch: 73/100 Iteration: 1443 Training loss: 0.40432 Train Acc: 0.86943\n",
      "Epoch: 73/100 Iteration: 1444 Training loss: 0.37356 Train Acc: 0.86943\n",
      "Epoch: 73/100 Iteration: 1445 Validation Acc: 0.8734\n",
      "Epoch: 73/100 Iteration: 1445 Training loss: 0.41099 Train Acc: 0.86624\n",
      "Epoch: 73/100 Iteration: 1446 Training loss: 0.42671 Train Acc: 0.86783\n",
      "Epoch: 73/100 Iteration: 1447 Training loss: 0.39730 Train Acc: 0.87261\n",
      "Epoch: 73/100 Iteration: 1448 Training loss: 0.38525 Train Acc: 0.87182\n",
      "Epoch: 73/100 Iteration: 1449 Training loss: 0.41297 Train Acc: 0.87261\n",
      "Epoch: 73/100 Iteration: 1450 Validation Acc: 0.8798\n",
      "Epoch: 73/100 Iteration: 1450 Training loss: 0.39287 Train Acc: 0.87978\n",
      "Epoch: 73/100 Iteration: 1451 Training loss: 0.41713 Train Acc: 0.87739\n",
      "Epoch: 73/100 Iteration: 1452 Training loss: 0.39661 Train Acc: 0.87500\n",
      "Epoch: 73/100 Iteration: 1453 Training loss: 0.39054 Train Acc: 0.87898\n",
      "Epoch: 73/100 Iteration: 1454 Training loss: 0.38773 Train Acc: 0.87739\n",
      "Epoch: 73/100 Iteration: 1455 Validation Acc: 0.8734\n",
      "Epoch: 73/100 Iteration: 1455 Training loss: 0.41233 Train Acc: 0.86863\n",
      "Epoch: 73/100 Iteration: 1456 Training loss: 0.41616 Train Acc: 0.88057\n",
      "Epoch: 73/100 Iteration: 1457 Training loss: 0.38783 Train Acc: 0.88057\n",
      "Epoch: 73/100 Iteration: 1458 Training loss: 0.38721 Train Acc: 0.87898\n",
      "Epoch: 73/100 Iteration: 1459 Training loss: 0.37875 Train Acc: 0.87420\n",
      "Epoch: 73/100 Iteration: 1460 Validation Acc: 0.8806\n",
      "Epoch: 74/100 Iteration: 1460 Training loss: 0.40232 Train Acc: 0.87898\n",
      "Epoch: 74/100 Iteration: 1461 Training loss: 0.41695 Train Acc: 0.88296\n",
      "Epoch: 74/100 Iteration: 1462 Training loss: 0.39377 Train Acc: 0.87341\n",
      "Epoch: 74/100 Iteration: 1463 Training loss: 0.41206 Train Acc: 0.88137\n",
      "Epoch: 74/100 Iteration: 1464 Training loss: 0.37201 Train Acc: 0.87500\n",
      "Epoch: 74/100 Iteration: 1465 Validation Acc: 0.8814\n",
      "Epoch: 74/100 Iteration: 1465 Training loss: 0.40221 Train Acc: 0.87818\n",
      "Epoch: 74/100 Iteration: 1466 Training loss: 0.42988 Train Acc: 0.88057\n",
      "Epoch: 74/100 Iteration: 1467 Training loss: 0.37927 Train Acc: 0.88296\n",
      "Epoch: 74/100 Iteration: 1468 Training loss: 0.40526 Train Acc: 0.88455\n",
      "Epoch: 74/100 Iteration: 1469 Training loss: 0.41664 Train Acc: 0.87898\n",
      "Epoch: 74/100 Iteration: 1470 Validation Acc: 0.8806\n",
      "Epoch: 74/100 Iteration: 1470 Training loss: 0.40889 Train Acc: 0.89411\n",
      "Epoch: 74/100 Iteration: 1471 Training loss: 0.40568 Train Acc: 0.88455\n",
      "Epoch: 74/100 Iteration: 1472 Training loss: 0.40519 Train Acc: 0.88296\n",
      "Epoch: 74/100 Iteration: 1473 Training loss: 0.38293 Train Acc: 0.88854\n",
      "Epoch: 74/100 Iteration: 1474 Training loss: 0.39586 Train Acc: 0.87818\n",
      "Epoch: 74/100 Iteration: 1475 Validation Acc: 0.8869\n",
      "Epoch: 74/100 Iteration: 1475 Training loss: 0.39242 Train Acc: 0.87898\n",
      "Epoch: 74/100 Iteration: 1476 Training loss: 0.40336 Train Acc: 0.87659\n",
      "Epoch: 74/100 Iteration: 1477 Training loss: 0.39896 Train Acc: 0.88057\n",
      "Epoch: 74/100 Iteration: 1478 Training loss: 0.38775 Train Acc: 0.87341\n",
      "Epoch: 74/100 Iteration: 1479 Training loss: 0.38458 Train Acc: 0.88137\n",
      "Epoch: 74/100 Iteration: 1480 Validation Acc: 0.8965\n",
      "Epoch: 75/100 Iteration: 1480 Training loss: 0.38016 Train Acc: 0.87739\n",
      "Epoch: 75/100 Iteration: 1481 Training loss: 0.40329 Train Acc: 0.87022\n",
      "Epoch: 75/100 Iteration: 1482 Training loss: 0.37711 Train Acc: 0.87420\n",
      "Epoch: 75/100 Iteration: 1483 Training loss: 0.39140 Train Acc: 0.87420\n",
      "Epoch: 75/100 Iteration: 1484 Training loss: 0.36881 Train Acc: 0.88217\n",
      "Epoch: 75/100 Iteration: 1485 Validation Acc: 0.8758\n",
      "Epoch: 75/100 Iteration: 1485 Training loss: 0.39882 Train Acc: 0.86704\n",
      "Epoch: 75/100 Iteration: 1486 Training loss: 0.41906 Train Acc: 0.87898\n",
      "Epoch: 75/100 Iteration: 1487 Training loss: 0.37237 Train Acc: 0.87420\n",
      "Epoch: 75/100 Iteration: 1488 Training loss: 0.37896 Train Acc: 0.88376\n",
      "Epoch: 75/100 Iteration: 1489 Training loss: 0.41463 Train Acc: 0.87739\n",
      "Epoch: 75/100 Iteration: 1490 Validation Acc: 0.8678\n",
      "Epoch: 75/100 Iteration: 1490 Training loss: 0.41087 Train Acc: 0.87898\n",
      "Epoch: 75/100 Iteration: 1491 Training loss: 0.39867 Train Acc: 0.88057\n",
      "Epoch: 75/100 Iteration: 1492 Training loss: 0.39594 Train Acc: 0.88217\n",
      "Epoch: 75/100 Iteration: 1493 Training loss: 0.39110 Train Acc: 0.87182\n",
      "Epoch: 75/100 Iteration: 1494 Training loss: 0.40318 Train Acc: 0.89172\n",
      "Epoch: 75/100 Iteration: 1495 Validation Acc: 0.8790\n",
      "Epoch: 75/100 Iteration: 1495 Training loss: 0.40371 Train Acc: 0.87341\n",
      "Epoch: 75/100 Iteration: 1496 Training loss: 0.42693 Train Acc: 0.88057\n",
      "Epoch: 75/100 Iteration: 1497 Training loss: 0.39191 Train Acc: 0.88376\n",
      "Epoch: 75/100 Iteration: 1498 Training loss: 0.39750 Train Acc: 0.88217\n",
      "Epoch: 75/100 Iteration: 1499 Training loss: 0.39195 Train Acc: 0.87898\n",
      "Epoch: 75/100 Iteration: 1500 Validation Acc: 0.8846\n",
      "Epoch: 76/100 Iteration: 1500 Training loss: 0.39942 Train Acc: 0.88694\n",
      "Epoch: 76/100 Iteration: 1501 Training loss: 0.41707 Train Acc: 0.88854\n",
      "Epoch: 76/100 Iteration: 1502 Training loss: 0.40648 Train Acc: 0.87420\n",
      "Epoch: 76/100 Iteration: 1503 Training loss: 0.40113 Train Acc: 0.87978\n",
      "Epoch: 76/100 Iteration: 1504 Training loss: 0.38187 Train Acc: 0.87818\n",
      "Epoch: 76/100 Iteration: 1505 Validation Acc: 0.8702\n",
      "Epoch: 76/100 Iteration: 1505 Training loss: 0.41318 Train Acc: 0.87898\n",
      "Epoch: 76/100 Iteration: 1506 Training loss: 0.41693 Train Acc: 0.88137\n",
      "Epoch: 76/100 Iteration: 1507 Training loss: 0.38631 Train Acc: 0.86385\n",
      "Epoch: 76/100 Iteration: 1508 Training loss: 0.39164 Train Acc: 0.87500\n",
      "Epoch: 76/100 Iteration: 1509 Training loss: 0.42335 Train Acc: 0.88137\n",
      "Epoch: 76/100 Iteration: 1510 Validation Acc: 0.8694\n",
      "Epoch: 76/100 Iteration: 1510 Training loss: 0.38900 Train Acc: 0.87818\n",
      "Epoch: 76/100 Iteration: 1511 Training loss: 0.39320 Train Acc: 0.88455\n",
      "Epoch: 76/100 Iteration: 1512 Training loss: 0.40001 Train Acc: 0.87739\n",
      "Epoch: 76/100 Iteration: 1513 Training loss: 0.38087 Train Acc: 0.87739\n",
      "Epoch: 76/100 Iteration: 1514 Training loss: 0.39883 Train Acc: 0.88376\n",
      "Epoch: 76/100 Iteration: 1515 Validation Acc: 0.8854\n",
      "Epoch: 76/100 Iteration: 1515 Training loss: 0.40900 Train Acc: 0.88535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 76/100 Iteration: 1516 Training loss: 0.42677 Train Acc: 0.88376\n",
      "Epoch: 76/100 Iteration: 1517 Training loss: 0.39475 Train Acc: 0.88217\n",
      "Epoch: 76/100 Iteration: 1518 Training loss: 0.39635 Train Acc: 0.88535\n",
      "Epoch: 76/100 Iteration: 1519 Training loss: 0.38078 Train Acc: 0.87818\n",
      "Epoch: 76/100 Iteration: 1520 Validation Acc: 0.8750\n",
      "Epoch: 77/100 Iteration: 1520 Training loss: 0.38106 Train Acc: 0.87898\n",
      "Epoch: 77/100 Iteration: 1521 Training loss: 0.43093 Train Acc: 0.88296\n",
      "Epoch: 77/100 Iteration: 1522 Training loss: 0.39094 Train Acc: 0.87978\n",
      "Epoch: 77/100 Iteration: 1523 Training loss: 0.39652 Train Acc: 0.88615\n",
      "Epoch: 77/100 Iteration: 1524 Training loss: 0.37779 Train Acc: 0.88057\n",
      "Epoch: 77/100 Iteration: 1525 Validation Acc: 0.8734\n",
      "Epoch: 77/100 Iteration: 1525 Training loss: 0.41331 Train Acc: 0.88535\n",
      "Epoch: 77/100 Iteration: 1526 Training loss: 0.42665 Train Acc: 0.87739\n",
      "Epoch: 77/100 Iteration: 1527 Training loss: 0.40791 Train Acc: 0.87341\n",
      "Epoch: 77/100 Iteration: 1528 Training loss: 0.38718 Train Acc: 0.87739\n",
      "Epoch: 77/100 Iteration: 1529 Training loss: 0.42164 Train Acc: 0.86704\n",
      "Epoch: 77/100 Iteration: 1530 Validation Acc: 0.8718\n",
      "Epoch: 77/100 Iteration: 1530 Training loss: 0.41111 Train Acc: 0.86385\n",
      "Epoch: 77/100 Iteration: 1531 Training loss: 0.39327 Train Acc: 0.87022\n",
      "Epoch: 77/100 Iteration: 1532 Training loss: 0.40905 Train Acc: 0.87898\n",
      "Epoch: 77/100 Iteration: 1533 Training loss: 0.39402 Train Acc: 0.86146\n",
      "Epoch: 77/100 Iteration: 1534 Training loss: 0.41238 Train Acc: 0.86943\n",
      "Epoch: 77/100 Iteration: 1535 Validation Acc: 0.8710\n",
      "Epoch: 77/100 Iteration: 1535 Training loss: 0.39436 Train Acc: 0.87182\n",
      "Epoch: 77/100 Iteration: 1536 Training loss: 0.41552 Train Acc: 0.87818\n",
      "Epoch: 77/100 Iteration: 1537 Training loss: 0.38070 Train Acc: 0.87580\n",
      "Epoch: 77/100 Iteration: 1538 Training loss: 0.38917 Train Acc: 0.87739\n",
      "Epoch: 77/100 Iteration: 1539 Training loss: 0.39264 Train Acc: 0.87978\n",
      "Epoch: 77/100 Iteration: 1540 Validation Acc: 0.8822\n",
      "Epoch: 78/100 Iteration: 1540 Training loss: 0.37751 Train Acc: 0.87580\n",
      "Epoch: 78/100 Iteration: 1541 Training loss: 0.40873 Train Acc: 0.87182\n",
      "Epoch: 78/100 Iteration: 1542 Training loss: 0.37989 Train Acc: 0.88854\n",
      "Epoch: 78/100 Iteration: 1543 Training loss: 0.40109 Train Acc: 0.87898\n",
      "Epoch: 78/100 Iteration: 1544 Training loss: 0.35147 Train Acc: 0.87978\n",
      "Epoch: 78/100 Iteration: 1545 Validation Acc: 0.8790\n",
      "Epoch: 78/100 Iteration: 1545 Training loss: 0.40092 Train Acc: 0.88137\n",
      "Epoch: 78/100 Iteration: 1546 Training loss: 0.40916 Train Acc: 0.87818\n",
      "Epoch: 78/100 Iteration: 1547 Training loss: 0.39811 Train Acc: 0.87739\n",
      "Epoch: 78/100 Iteration: 1548 Training loss: 0.39313 Train Acc: 0.88217\n",
      "Epoch: 78/100 Iteration: 1549 Training loss: 0.43897 Train Acc: 0.87978\n",
      "Epoch: 78/100 Iteration: 1550 Validation Acc: 0.8766\n",
      "Epoch: 78/100 Iteration: 1550 Training loss: 0.40600 Train Acc: 0.87978\n",
      "Epoch: 78/100 Iteration: 1551 Training loss: 0.40395 Train Acc: 0.87341\n",
      "Epoch: 78/100 Iteration: 1552 Training loss: 0.41817 Train Acc: 0.87341\n",
      "Epoch: 78/100 Iteration: 1553 Training loss: 0.38199 Train Acc: 0.87898\n",
      "Epoch: 78/100 Iteration: 1554 Training loss: 0.38771 Train Acc: 0.88057\n",
      "Epoch: 78/100 Iteration: 1555 Validation Acc: 0.8798\n",
      "Epoch: 78/100 Iteration: 1555 Training loss: 0.38278 Train Acc: 0.87580\n",
      "Epoch: 78/100 Iteration: 1556 Training loss: 0.42832 Train Acc: 0.87659\n",
      "Epoch: 78/100 Iteration: 1557 Training loss: 0.40104 Train Acc: 0.88694\n",
      "Epoch: 78/100 Iteration: 1558 Training loss: 0.37427 Train Acc: 0.88057\n",
      "Epoch: 78/100 Iteration: 1559 Training loss: 0.40001 Train Acc: 0.87978\n",
      "Epoch: 78/100 Iteration: 1560 Validation Acc: 0.8830\n",
      "Epoch: 79/100 Iteration: 1560 Training loss: 0.40552 Train Acc: 0.88854\n",
      "Epoch: 79/100 Iteration: 1561 Training loss: 0.40375 Train Acc: 0.87659\n",
      "Epoch: 79/100 Iteration: 1562 Training loss: 0.39980 Train Acc: 0.88217\n",
      "Epoch: 79/100 Iteration: 1563 Training loss: 0.39953 Train Acc: 0.88296\n",
      "Epoch: 79/100 Iteration: 1564 Training loss: 0.36962 Train Acc: 0.87420\n",
      "Epoch: 79/100 Iteration: 1565 Validation Acc: 0.8774\n",
      "Epoch: 79/100 Iteration: 1565 Training loss: 0.41107 Train Acc: 0.87022\n",
      "Epoch: 79/100 Iteration: 1566 Training loss: 0.42376 Train Acc: 0.87420\n",
      "Epoch: 79/100 Iteration: 1567 Training loss: 0.38893 Train Acc: 0.87580\n",
      "Epoch: 79/100 Iteration: 1568 Training loss: 0.39397 Train Acc: 0.86704\n",
      "Epoch: 79/100 Iteration: 1569 Training loss: 0.42020 Train Acc: 0.85908\n",
      "Epoch: 79/100 Iteration: 1570 Validation Acc: 0.8678\n",
      "Epoch: 79/100 Iteration: 1570 Training loss: 0.39312 Train Acc: 0.86385\n",
      "Epoch: 79/100 Iteration: 1571 Training loss: 0.39927 Train Acc: 0.87102\n",
      "Epoch: 79/100 Iteration: 1572 Training loss: 0.40796 Train Acc: 0.85828\n",
      "Epoch: 79/100 Iteration: 1573 Training loss: 0.40883 Train Acc: 0.87102\n",
      "Epoch: 79/100 Iteration: 1574 Training loss: 0.39715 Train Acc: 0.87341\n",
      "Epoch: 79/100 Iteration: 1575 Validation Acc: 0.8639\n",
      "Epoch: 79/100 Iteration: 1575 Training loss: 0.41000 Train Acc: 0.87341\n",
      "Epoch: 79/100 Iteration: 1576 Training loss: 0.41599 Train Acc: 0.86704\n",
      "Epoch: 79/100 Iteration: 1577 Training loss: 0.39869 Train Acc: 0.86545\n",
      "Epoch: 79/100 Iteration: 1578 Training loss: 0.38081 Train Acc: 0.86783\n",
      "Epoch: 79/100 Iteration: 1579 Training loss: 0.39259 Train Acc: 0.87978\n",
      "Epoch: 79/100 Iteration: 1580 Validation Acc: 0.8790\n",
      "Epoch: 80/100 Iteration: 1580 Training loss: 0.38537 Train Acc: 0.87580\n",
      "Epoch: 80/100 Iteration: 1581 Training loss: 0.40779 Train Acc: 0.88057\n",
      "Epoch: 80/100 Iteration: 1582 Training loss: 0.37963 Train Acc: 0.87420\n",
      "Epoch: 80/100 Iteration: 1583 Training loss: 0.40008 Train Acc: 0.87739\n",
      "Epoch: 80/100 Iteration: 1584 Training loss: 0.36795 Train Acc: 0.88217\n",
      "Epoch: 80/100 Iteration: 1585 Validation Acc: 0.8774\n",
      "Epoch: 80/100 Iteration: 1585 Training loss: 0.38903 Train Acc: 0.87739\n",
      "Epoch: 80/100 Iteration: 1586 Training loss: 0.42560 Train Acc: 0.87420\n",
      "Epoch: 80/100 Iteration: 1587 Training loss: 0.38133 Train Acc: 0.87500\n",
      "Epoch: 80/100 Iteration: 1588 Training loss: 0.38928 Train Acc: 0.87659\n",
      "Epoch: 80/100 Iteration: 1589 Training loss: 0.41172 Train Acc: 0.88535\n",
      "Epoch: 80/100 Iteration: 1590 Validation Acc: 0.8814\n",
      "Epoch: 80/100 Iteration: 1590 Training loss: 0.39545 Train Acc: 0.88854\n",
      "Epoch: 80/100 Iteration: 1591 Training loss: 0.40882 Train Acc: 0.88057\n",
      "Epoch: 80/100 Iteration: 1592 Training loss: 0.39431 Train Acc: 0.88296\n",
      "Epoch: 80/100 Iteration: 1593 Training loss: 0.39039 Train Acc: 0.88376\n",
      "Epoch: 80/100 Iteration: 1594 Training loss: 0.38977 Train Acc: 0.87580\n",
      "Epoch: 80/100 Iteration: 1595 Validation Acc: 0.8782\n",
      "Epoch: 80/100 Iteration: 1595 Training loss: 0.40565 Train Acc: 0.88217\n",
      "Epoch: 80/100 Iteration: 1596 Training loss: 0.41208 Train Acc: 0.87978\n",
      "Epoch: 80/100 Iteration: 1597 Training loss: 0.40576 Train Acc: 0.88217\n",
      "Epoch: 80/100 Iteration: 1598 Training loss: 0.38690 Train Acc: 0.88535\n",
      "Epoch: 80/100 Iteration: 1599 Training loss: 0.38519 Train Acc: 0.88694\n",
      "Epoch: 80/100 Iteration: 1600 Validation Acc: 0.8830\n",
      "Epoch: 81/100 Iteration: 1600 Training loss: 0.39501 Train Acc: 0.89570\n",
      "Epoch: 81/100 Iteration: 1601 Training loss: 0.40237 Train Acc: 0.89092\n",
      "Epoch: 81/100 Iteration: 1602 Training loss: 0.36841 Train Acc: 0.87261\n",
      "Epoch: 81/100 Iteration: 1603 Training loss: 0.38665 Train Acc: 0.89570\n",
      "Epoch: 81/100 Iteration: 1604 Training loss: 0.36833 Train Acc: 0.88455\n",
      "Epoch: 81/100 Iteration: 1605 Validation Acc: 0.8869\n",
      "Epoch: 81/100 Iteration: 1605 Training loss: 0.42022 Train Acc: 0.88535\n",
      "Epoch: 81/100 Iteration: 1606 Training loss: 0.43353 Train Acc: 0.89172\n",
      "Epoch: 81/100 Iteration: 1607 Training loss: 0.38376 Train Acc: 0.89013\n",
      "Epoch: 81/100 Iteration: 1608 Training loss: 0.37714 Train Acc: 0.88376\n",
      "Epoch: 81/100 Iteration: 1609 Training loss: 0.41737 Train Acc: 0.88615\n",
      "Epoch: 81/100 Iteration: 1610 Validation Acc: 0.8758\n",
      "Epoch: 81/100 Iteration: 1610 Training loss: 0.39382 Train Acc: 0.88535\n",
      "Epoch: 81/100 Iteration: 1611 Training loss: 0.40320 Train Acc: 0.88217\n",
      "Epoch: 81/100 Iteration: 1612 Training loss: 0.41570 Train Acc: 0.89013\n",
      "Epoch: 81/100 Iteration: 1613 Training loss: 0.39308 Train Acc: 0.88535\n",
      "Epoch: 81/100 Iteration: 1614 Training loss: 0.40182 Train Acc: 0.88057\n",
      "Epoch: 81/100 Iteration: 1615 Validation Acc: 0.8838\n",
      "Epoch: 81/100 Iteration: 1615 Training loss: 0.40719 Train Acc: 0.88137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 81/100 Iteration: 1616 Training loss: 0.40144 Train Acc: 0.88455\n",
      "Epoch: 81/100 Iteration: 1617 Training loss: 0.40723 Train Acc: 0.89013\n",
      "Epoch: 81/100 Iteration: 1618 Training loss: 0.38071 Train Acc: 0.88694\n",
      "Epoch: 81/100 Iteration: 1619 Training loss: 0.37184 Train Acc: 0.88296\n",
      "Epoch: 81/100 Iteration: 1620 Validation Acc: 0.8869\n",
      "Epoch: 82/100 Iteration: 1620 Training loss: 0.39079 Train Acc: 0.87898\n",
      "Epoch: 82/100 Iteration: 1621 Training loss: 0.41739 Train Acc: 0.87739\n",
      "Epoch: 82/100 Iteration: 1622 Training loss: 0.39538 Train Acc: 0.89013\n",
      "Epoch: 82/100 Iteration: 1623 Training loss: 0.39189 Train Acc: 0.88057\n",
      "Epoch: 82/100 Iteration: 1624 Training loss: 0.38022 Train Acc: 0.88217\n",
      "Epoch: 82/100 Iteration: 1625 Validation Acc: 0.8838\n",
      "Epoch: 82/100 Iteration: 1625 Training loss: 0.40159 Train Acc: 0.87659\n",
      "Epoch: 82/100 Iteration: 1626 Training loss: 0.43283 Train Acc: 0.87341\n",
      "Epoch: 82/100 Iteration: 1627 Training loss: 0.38178 Train Acc: 0.87818\n",
      "Epoch: 82/100 Iteration: 1628 Training loss: 0.37726 Train Acc: 0.86943\n",
      "Epoch: 82/100 Iteration: 1629 Training loss: 0.41611 Train Acc: 0.88137\n",
      "Epoch: 82/100 Iteration: 1630 Validation Acc: 0.8774\n",
      "Epoch: 82/100 Iteration: 1630 Training loss: 0.40493 Train Acc: 0.87978\n",
      "Epoch: 82/100 Iteration: 1631 Training loss: 0.39030 Train Acc: 0.86943\n",
      "Epoch: 82/100 Iteration: 1632 Training loss: 0.40776 Train Acc: 0.87420\n",
      "Epoch: 82/100 Iteration: 1633 Training loss: 0.38524 Train Acc: 0.87739\n",
      "Epoch: 82/100 Iteration: 1634 Training loss: 0.40297 Train Acc: 0.87261\n",
      "Epoch: 82/100 Iteration: 1635 Validation Acc: 0.8814\n",
      "Epoch: 82/100 Iteration: 1635 Training loss: 0.38988 Train Acc: 0.87580\n",
      "Epoch: 82/100 Iteration: 1636 Training loss: 0.40620 Train Acc: 0.88376\n",
      "Epoch: 82/100 Iteration: 1637 Training loss: 0.38211 Train Acc: 0.87261\n",
      "Epoch: 82/100 Iteration: 1638 Training loss: 0.36719 Train Acc: 0.87898\n",
      "Epoch: 82/100 Iteration: 1639 Training loss: 0.38755 Train Acc: 0.87898\n",
      "Epoch: 82/100 Iteration: 1640 Validation Acc: 0.8798\n",
      "Epoch: 83/100 Iteration: 1640 Training loss: 0.39622 Train Acc: 0.88137\n",
      "Epoch: 83/100 Iteration: 1641 Training loss: 0.41353 Train Acc: 0.88296\n",
      "Epoch: 83/100 Iteration: 1642 Training loss: 0.38290 Train Acc: 0.88057\n",
      "Epoch: 83/100 Iteration: 1643 Training loss: 0.41012 Train Acc: 0.88217\n",
      "Epoch: 83/100 Iteration: 1644 Training loss: 0.36979 Train Acc: 0.88137\n",
      "Epoch: 83/100 Iteration: 1645 Validation Acc: 0.8822\n",
      "Epoch: 83/100 Iteration: 1645 Training loss: 0.42265 Train Acc: 0.87580\n",
      "Epoch: 83/100 Iteration: 1646 Training loss: 0.42579 Train Acc: 0.88296\n",
      "Epoch: 83/100 Iteration: 1647 Training loss: 0.39651 Train Acc: 0.87341\n",
      "Epoch: 83/100 Iteration: 1648 Training loss: 0.38610 Train Acc: 0.87580\n",
      "Epoch: 83/100 Iteration: 1649 Training loss: 0.42911 Train Acc: 0.88296\n",
      "Epoch: 83/100 Iteration: 1650 Validation Acc: 0.8822\n",
      "Epoch: 83/100 Iteration: 1650 Training loss: 0.41418 Train Acc: 0.87500\n",
      "Epoch: 83/100 Iteration: 1651 Training loss: 0.41082 Train Acc: 0.87978\n",
      "Epoch: 83/100 Iteration: 1652 Training loss: 0.40390 Train Acc: 0.87978\n",
      "Epoch: 83/100 Iteration: 1653 Training loss: 0.38442 Train Acc: 0.88217\n",
      "Epoch: 83/100 Iteration: 1654 Training loss: 0.42009 Train Acc: 0.87898\n",
      "Epoch: 83/100 Iteration: 1655 Validation Acc: 0.8631\n",
      "Epoch: 83/100 Iteration: 1655 Training loss: 0.40363 Train Acc: 0.87659\n",
      "Epoch: 83/100 Iteration: 1656 Training loss: 0.41198 Train Acc: 0.87978\n",
      "Epoch: 83/100 Iteration: 1657 Training loss: 0.38811 Train Acc: 0.87182\n",
      "Epoch: 83/100 Iteration: 1658 Training loss: 0.38062 Train Acc: 0.87739\n",
      "Epoch: 83/100 Iteration: 1659 Training loss: 0.39265 Train Acc: 0.88694\n",
      "Epoch: 83/100 Iteration: 1660 Validation Acc: 0.8814\n",
      "Epoch: 84/100 Iteration: 1660 Training loss: 0.38035 Train Acc: 0.87818\n",
      "Epoch: 84/100 Iteration: 1661 Training loss: 0.39794 Train Acc: 0.87739\n",
      "Epoch: 84/100 Iteration: 1662 Training loss: 0.37387 Train Acc: 0.88376\n",
      "Epoch: 84/100 Iteration: 1663 Training loss: 0.38197 Train Acc: 0.87898\n",
      "Epoch: 84/100 Iteration: 1664 Training loss: 0.36242 Train Acc: 0.88535\n",
      "Epoch: 84/100 Iteration: 1665 Validation Acc: 0.8885\n",
      "Epoch: 84/100 Iteration: 1665 Training loss: 0.38983 Train Acc: 0.88376\n",
      "Epoch: 84/100 Iteration: 1666 Training loss: 0.41082 Train Acc: 0.87500\n",
      "Epoch: 84/100 Iteration: 1667 Training loss: 0.39300 Train Acc: 0.87659\n",
      "Epoch: 84/100 Iteration: 1668 Training loss: 0.38491 Train Acc: 0.88376\n",
      "Epoch: 84/100 Iteration: 1669 Training loss: 0.43633 Train Acc: 0.88694\n",
      "Epoch: 84/100 Iteration: 1670 Validation Acc: 0.8838\n",
      "Epoch: 84/100 Iteration: 1670 Training loss: 0.41112 Train Acc: 0.86863\n",
      "Epoch: 84/100 Iteration: 1671 Training loss: 0.38148 Train Acc: 0.88455\n",
      "Epoch: 84/100 Iteration: 1672 Training loss: 0.40705 Train Acc: 0.87420\n",
      "Epoch: 84/100 Iteration: 1673 Training loss: 0.39331 Train Acc: 0.88137\n",
      "Epoch: 84/100 Iteration: 1674 Training loss: 0.40581 Train Acc: 0.88057\n",
      "Epoch: 84/100 Iteration: 1675 Validation Acc: 0.8742\n",
      "Epoch: 84/100 Iteration: 1675 Training loss: 0.41157 Train Acc: 0.87261\n",
      "Epoch: 84/100 Iteration: 1676 Training loss: 0.41325 Train Acc: 0.88057\n",
      "Epoch: 84/100 Iteration: 1677 Training loss: 0.39842 Train Acc: 0.87898\n",
      "Epoch: 84/100 Iteration: 1678 Training loss: 0.39703 Train Acc: 0.87580\n",
      "Epoch: 84/100 Iteration: 1679 Training loss: 0.40435 Train Acc: 0.88057\n",
      "Epoch: 84/100 Iteration: 1680 Validation Acc: 0.8726\n",
      "Epoch: 85/100 Iteration: 1680 Training loss: 0.39267 Train Acc: 0.86704\n",
      "Epoch: 85/100 Iteration: 1681 Training loss: 0.42198 Train Acc: 0.86863\n",
      "Epoch: 85/100 Iteration: 1682 Training loss: 0.38170 Train Acc: 0.86146\n",
      "Epoch: 85/100 Iteration: 1683 Training loss: 0.38788 Train Acc: 0.87341\n",
      "Epoch: 85/100 Iteration: 1684 Training loss: 0.38524 Train Acc: 0.87022\n",
      "Epoch: 85/100 Iteration: 1685 Validation Acc: 0.8646\n",
      "Epoch: 85/100 Iteration: 1685 Training loss: 0.40891 Train Acc: 0.86545\n",
      "Epoch: 85/100 Iteration: 1686 Training loss: 0.42124 Train Acc: 0.86385\n",
      "Epoch: 85/100 Iteration: 1687 Training loss: 0.39196 Train Acc: 0.86545\n",
      "Epoch: 85/100 Iteration: 1688 Training loss: 0.39095 Train Acc: 0.87580\n",
      "Epoch: 85/100 Iteration: 1689 Training loss: 0.42118 Train Acc: 0.86863\n",
      "Epoch: 85/100 Iteration: 1690 Validation Acc: 0.8678\n",
      "Epoch: 85/100 Iteration: 1690 Training loss: 0.41052 Train Acc: 0.86783\n",
      "Epoch: 85/100 Iteration: 1691 Training loss: 0.42057 Train Acc: 0.87818\n",
      "Epoch: 85/100 Iteration: 1692 Training loss: 0.41353 Train Acc: 0.86545\n",
      "Epoch: 85/100 Iteration: 1693 Training loss: 0.40341 Train Acc: 0.86863\n",
      "Epoch: 85/100 Iteration: 1694 Training loss: 0.43717 Train Acc: 0.85828\n",
      "Epoch: 85/100 Iteration: 1695 Validation Acc: 0.8654\n",
      "Epoch: 85/100 Iteration: 1695 Training loss: 0.39546 Train Acc: 0.86783\n",
      "Epoch: 85/100 Iteration: 1696 Training loss: 0.42231 Train Acc: 0.87022\n",
      "Epoch: 85/100 Iteration: 1697 Training loss: 0.40562 Train Acc: 0.87102\n",
      "Epoch: 85/100 Iteration: 1698 Training loss: 0.41266 Train Acc: 0.87420\n",
      "Epoch: 85/100 Iteration: 1699 Training loss: 0.39291 Train Acc: 0.87739\n",
      "Epoch: 85/100 Iteration: 1700 Validation Acc: 0.8726\n",
      "Epoch: 86/100 Iteration: 1700 Training loss: 0.38441 Train Acc: 0.87341\n",
      "Epoch: 86/100 Iteration: 1701 Training loss: 0.40606 Train Acc: 0.87580\n",
      "Epoch: 86/100 Iteration: 1702 Training loss: 0.38295 Train Acc: 0.87500\n",
      "Epoch: 86/100 Iteration: 1703 Training loss: 0.39820 Train Acc: 0.87420\n",
      "Epoch: 86/100 Iteration: 1704 Training loss: 0.37344 Train Acc: 0.87978\n",
      "Epoch: 86/100 Iteration: 1705 Validation Acc: 0.8854\n",
      "Epoch: 86/100 Iteration: 1705 Training loss: 0.40048 Train Acc: 0.87500\n",
      "Epoch: 86/100 Iteration: 1706 Training loss: 0.42646 Train Acc: 0.87022\n",
      "Epoch: 86/100 Iteration: 1707 Training loss: 0.38407 Train Acc: 0.88376\n",
      "Epoch: 86/100 Iteration: 1708 Training loss: 0.38386 Train Acc: 0.87898\n",
      "Epoch: 86/100 Iteration: 1709 Training loss: 0.39791 Train Acc: 0.87818\n",
      "Epoch: 86/100 Iteration: 1710 Validation Acc: 0.8838\n",
      "Epoch: 86/100 Iteration: 1710 Training loss: 0.39910 Train Acc: 0.88057\n",
      "Epoch: 86/100 Iteration: 1711 Training loss: 0.42362 Train Acc: 0.87739\n",
      "Epoch: 86/100 Iteration: 1712 Training loss: 0.39473 Train Acc: 0.88296\n",
      "Epoch: 86/100 Iteration: 1713 Training loss: 0.39890 Train Acc: 0.88376\n",
      "Epoch: 86/100 Iteration: 1714 Training loss: 0.41728 Train Acc: 0.88933\n",
      "Epoch: 86/100 Iteration: 1715 Validation Acc: 0.8877\n",
      "Epoch: 86/100 Iteration: 1715 Training loss: 0.39653 Train Acc: 0.89013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 86/100 Iteration: 1716 Training loss: 0.41576 Train Acc: 0.88774\n",
      "Epoch: 86/100 Iteration: 1717 Training loss: 0.39691 Train Acc: 0.88535\n",
      "Epoch: 86/100 Iteration: 1718 Training loss: 0.38811 Train Acc: 0.87818\n",
      "Epoch: 86/100 Iteration: 1719 Training loss: 0.39664 Train Acc: 0.87659\n",
      "Epoch: 86/100 Iteration: 1720 Validation Acc: 0.8830\n",
      "Epoch: 87/100 Iteration: 1720 Training loss: 0.39260 Train Acc: 0.87978\n",
      "Epoch: 87/100 Iteration: 1721 Training loss: 0.42786 Train Acc: 0.88535\n",
      "Epoch: 87/100 Iteration: 1722 Training loss: 0.38832 Train Acc: 0.87818\n",
      "Epoch: 87/100 Iteration: 1723 Training loss: 0.40199 Train Acc: 0.87500\n",
      "Epoch: 87/100 Iteration: 1724 Training loss: 0.38518 Train Acc: 0.88057\n",
      "Epoch: 87/100 Iteration: 1725 Validation Acc: 0.8766\n",
      "Epoch: 87/100 Iteration: 1725 Training loss: 0.42131 Train Acc: 0.89172\n",
      "Epoch: 87/100 Iteration: 1726 Training loss: 0.42912 Train Acc: 0.88217\n",
      "Epoch: 87/100 Iteration: 1727 Training loss: 0.39478 Train Acc: 0.88615\n",
      "Epoch: 87/100 Iteration: 1728 Training loss: 0.38605 Train Acc: 0.87898\n",
      "Epoch: 87/100 Iteration: 1729 Training loss: 0.42693 Train Acc: 0.87898\n",
      "Epoch: 87/100 Iteration: 1730 Validation Acc: 0.8814\n",
      "Epoch: 87/100 Iteration: 1730 Training loss: 0.39643 Train Acc: 0.88455\n",
      "Epoch: 87/100 Iteration: 1731 Training loss: 0.40126 Train Acc: 0.88057\n",
      "Epoch: 87/100 Iteration: 1732 Training loss: 0.41237 Train Acc: 0.89172\n",
      "Epoch: 87/100 Iteration: 1733 Training loss: 0.39896 Train Acc: 0.89013\n",
      "Epoch: 87/100 Iteration: 1734 Training loss: 0.42071 Train Acc: 0.88376\n",
      "Epoch: 87/100 Iteration: 1735 Validation Acc: 0.8782\n",
      "Epoch: 87/100 Iteration: 1735 Training loss: 0.40220 Train Acc: 0.88217\n",
      "Epoch: 87/100 Iteration: 1736 Training loss: 0.41685 Train Acc: 0.87341\n",
      "Epoch: 87/100 Iteration: 1737 Training loss: 0.41229 Train Acc: 0.87102\n",
      "Epoch: 87/100 Iteration: 1738 Training loss: 0.37063 Train Acc: 0.88296\n",
      "Epoch: 87/100 Iteration: 1739 Training loss: 0.40354 Train Acc: 0.88057\n",
      "Epoch: 87/100 Iteration: 1740 Validation Acc: 0.8806\n",
      "Epoch: 88/100 Iteration: 1740 Training loss: 0.38561 Train Acc: 0.87739\n",
      "Epoch: 88/100 Iteration: 1741 Training loss: 0.39443 Train Acc: 0.88854\n",
      "Epoch: 88/100 Iteration: 1742 Training loss: 0.39625 Train Acc: 0.88376\n",
      "Epoch: 88/100 Iteration: 1743 Training loss: 0.40198 Train Acc: 0.88376\n",
      "Epoch: 88/100 Iteration: 1744 Training loss: 0.39188 Train Acc: 0.89252\n",
      "Epoch: 88/100 Iteration: 1745 Validation Acc: 0.8869\n",
      "Epoch: 88/100 Iteration: 1745 Training loss: 0.40493 Train Acc: 0.88376\n",
      "Epoch: 88/100 Iteration: 1746 Training loss: 0.42532 Train Acc: 0.87022\n",
      "Epoch: 88/100 Iteration: 1747 Training loss: 0.38683 Train Acc: 0.88615\n",
      "Epoch: 88/100 Iteration: 1748 Training loss: 0.40325 Train Acc: 0.87978\n",
      "Epoch: 88/100 Iteration: 1749 Training loss: 0.41676 Train Acc: 0.88217\n",
      "Epoch: 88/100 Iteration: 1750 Validation Acc: 0.8806\n",
      "Epoch: 88/100 Iteration: 1750 Training loss: 0.40252 Train Acc: 0.87102\n",
      "Epoch: 88/100 Iteration: 1751 Training loss: 0.39073 Train Acc: 0.87182\n",
      "Epoch: 88/100 Iteration: 1752 Training loss: 0.40320 Train Acc: 0.87659\n",
      "Epoch: 88/100 Iteration: 1753 Training loss: 0.38683 Train Acc: 0.86943\n",
      "Epoch: 88/100 Iteration: 1754 Training loss: 0.40932 Train Acc: 0.88296\n",
      "Epoch: 88/100 Iteration: 1755 Validation Acc: 0.8822\n",
      "Epoch: 88/100 Iteration: 1755 Training loss: 0.39859 Train Acc: 0.87978\n",
      "Epoch: 88/100 Iteration: 1756 Training loss: 0.40642 Train Acc: 0.87182\n",
      "Epoch: 88/100 Iteration: 1757 Training loss: 0.41140 Train Acc: 0.87102\n",
      "Epoch: 88/100 Iteration: 1758 Training loss: 0.40636 Train Acc: 0.87182\n",
      "Epoch: 88/100 Iteration: 1759 Training loss: 0.40414 Train Acc: 0.86067\n",
      "Epoch: 88/100 Iteration: 1760 Validation Acc: 0.8710\n",
      "Epoch: 89/100 Iteration: 1760 Training loss: 0.38600 Train Acc: 0.87022\n",
      "Epoch: 89/100 Iteration: 1761 Training loss: 0.42922 Train Acc: 0.87261\n",
      "Epoch: 89/100 Iteration: 1762 Training loss: 0.38339 Train Acc: 0.86545\n",
      "Epoch: 89/100 Iteration: 1763 Training loss: 0.40045 Train Acc: 0.87978\n",
      "Epoch: 89/100 Iteration: 1764 Training loss: 0.36846 Train Acc: 0.87659\n",
      "Epoch: 89/100 Iteration: 1765 Validation Acc: 0.8822\n",
      "Epoch: 89/100 Iteration: 1765 Training loss: 0.42687 Train Acc: 0.88296\n",
      "Epoch: 89/100 Iteration: 1766 Training loss: 0.41254 Train Acc: 0.89013\n",
      "Epoch: 89/100 Iteration: 1767 Training loss: 0.39859 Train Acc: 0.87818\n",
      "Epoch: 89/100 Iteration: 1768 Training loss: 0.40632 Train Acc: 0.87420\n",
      "Epoch: 89/100 Iteration: 1769 Training loss: 0.43302 Train Acc: 0.88217\n",
      "Epoch: 89/100 Iteration: 1770 Validation Acc: 0.8814\n",
      "Epoch: 89/100 Iteration: 1770 Training loss: 0.40929 Train Acc: 0.87739\n",
      "Epoch: 89/100 Iteration: 1771 Training loss: 0.39533 Train Acc: 0.86146\n",
      "Epoch: 89/100 Iteration: 1772 Training loss: 0.38513 Train Acc: 0.88137\n",
      "Epoch: 89/100 Iteration: 1773 Training loss: 0.40909 Train Acc: 0.87659\n",
      "Epoch: 89/100 Iteration: 1774 Training loss: 0.40378 Train Acc: 0.87341\n",
      "Epoch: 89/100 Iteration: 1775 Validation Acc: 0.8726\n",
      "Epoch: 89/100 Iteration: 1775 Training loss: 0.39488 Train Acc: 0.87818\n",
      "Epoch: 89/100 Iteration: 1776 Training loss: 0.43029 Train Acc: 0.87182\n",
      "Epoch: 89/100 Iteration: 1777 Training loss: 0.41578 Train Acc: 0.88137\n",
      "Epoch: 89/100 Iteration: 1778 Training loss: 0.39315 Train Acc: 0.89092\n",
      "Epoch: 89/100 Iteration: 1779 Training loss: 0.38181 Train Acc: 0.88615\n",
      "Epoch: 89/100 Iteration: 1780 Validation Acc: 0.8702\n",
      "Epoch: 90/100 Iteration: 1780 Training loss: 0.39841 Train Acc: 0.87420\n",
      "Epoch: 90/100 Iteration: 1781 Training loss: 0.41353 Train Acc: 0.87978\n",
      "Epoch: 90/100 Iteration: 1782 Training loss: 0.39378 Train Acc: 0.86943\n",
      "Epoch: 90/100 Iteration: 1783 Training loss: 0.39160 Train Acc: 0.87739\n",
      "Epoch: 90/100 Iteration: 1784 Training loss: 0.37791 Train Acc: 0.87341\n",
      "Epoch: 90/100 Iteration: 1785 Validation Acc: 0.8766\n",
      "Epoch: 90/100 Iteration: 1785 Training loss: 0.41290 Train Acc: 0.87978\n",
      "Epoch: 90/100 Iteration: 1786 Training loss: 0.41363 Train Acc: 0.87978\n",
      "Epoch: 90/100 Iteration: 1787 Training loss: 0.39732 Train Acc: 0.89172\n",
      "Epoch: 90/100 Iteration: 1788 Training loss: 0.38967 Train Acc: 0.89172\n",
      "Epoch: 90/100 Iteration: 1789 Training loss: 0.40994 Train Acc: 0.88376\n",
      "Epoch: 90/100 Iteration: 1790 Validation Acc: 0.8854\n",
      "Epoch: 90/100 Iteration: 1790 Training loss: 0.41193 Train Acc: 0.88455\n",
      "Epoch: 90/100 Iteration: 1791 Training loss: 0.40595 Train Acc: 0.87818\n",
      "Epoch: 90/100 Iteration: 1792 Training loss: 0.39771 Train Acc: 0.88137\n",
      "Epoch: 90/100 Iteration: 1793 Training loss: 0.38720 Train Acc: 0.89411\n",
      "Epoch: 90/100 Iteration: 1794 Training loss: 0.40812 Train Acc: 0.88137\n",
      "Epoch: 90/100 Iteration: 1795 Validation Acc: 0.8830\n",
      "Epoch: 90/100 Iteration: 1795 Training loss: 0.39286 Train Acc: 0.88296\n",
      "Epoch: 90/100 Iteration: 1796 Training loss: 0.42626 Train Acc: 0.88854\n",
      "Epoch: 90/100 Iteration: 1797 Training loss: 0.40864 Train Acc: 0.88774\n",
      "Epoch: 90/100 Iteration: 1798 Training loss: 0.39342 Train Acc: 0.89013\n",
      "Epoch: 90/100 Iteration: 1799 Training loss: 0.39638 Train Acc: 0.88774\n",
      "Epoch: 90/100 Iteration: 1800 Validation Acc: 0.8861\n",
      "Epoch: 91/100 Iteration: 1800 Training loss: 0.40215 Train Acc: 0.88455\n",
      "Epoch: 91/100 Iteration: 1801 Training loss: 0.39270 Train Acc: 0.89490\n",
      "Epoch: 91/100 Iteration: 1802 Training loss: 0.38213 Train Acc: 0.89252\n",
      "Epoch: 91/100 Iteration: 1803 Training loss: 0.38725 Train Acc: 0.89092\n",
      "Epoch: 91/100 Iteration: 1804 Training loss: 0.37046 Train Acc: 0.89013\n",
      "Epoch: 91/100 Iteration: 1805 Validation Acc: 0.8782\n",
      "Epoch: 91/100 Iteration: 1805 Training loss: 0.39576 Train Acc: 0.87898\n",
      "Epoch: 91/100 Iteration: 1806 Training loss: 0.40515 Train Acc: 0.88933\n",
      "Epoch: 91/100 Iteration: 1807 Training loss: 0.38580 Train Acc: 0.87659\n",
      "Epoch: 91/100 Iteration: 1808 Training loss: 0.38018 Train Acc: 0.87341\n",
      "Epoch: 91/100 Iteration: 1809 Training loss: 0.39317 Train Acc: 0.88455\n",
      "Epoch: 91/100 Iteration: 1810 Validation Acc: 0.8806\n",
      "Epoch: 91/100 Iteration: 1810 Training loss: 0.40114 Train Acc: 0.88455\n",
      "Epoch: 91/100 Iteration: 1811 Training loss: 0.40748 Train Acc: 0.87341\n",
      "Epoch: 91/100 Iteration: 1812 Training loss: 0.37799 Train Acc: 0.88057\n",
      "Epoch: 91/100 Iteration: 1813 Training loss: 0.39543 Train Acc: 0.88137\n",
      "Epoch: 91/100 Iteration: 1814 Training loss: 0.40121 Train Acc: 0.88615\n",
      "Epoch: 91/100 Iteration: 1815 Validation Acc: 0.8854\n",
      "Epoch: 91/100 Iteration: 1815 Training loss: 0.38864 Train Acc: 0.88535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 91/100 Iteration: 1816 Training loss: 0.41484 Train Acc: 0.89172\n",
      "Epoch: 91/100 Iteration: 1817 Training loss: 0.39511 Train Acc: 0.89252\n",
      "Epoch: 91/100 Iteration: 1818 Training loss: 0.38835 Train Acc: 0.88615\n",
      "Epoch: 91/100 Iteration: 1819 Training loss: 0.37757 Train Acc: 0.89331\n",
      "Epoch: 91/100 Iteration: 1820 Validation Acc: 0.8877\n",
      "Epoch: 92/100 Iteration: 1820 Training loss: 0.39734 Train Acc: 0.88694\n",
      "Epoch: 92/100 Iteration: 1821 Training loss: 0.37438 Train Acc: 0.88535\n",
      "Epoch: 92/100 Iteration: 1822 Training loss: 0.37220 Train Acc: 0.88774\n",
      "Epoch: 92/100 Iteration: 1823 Training loss: 0.38288 Train Acc: 0.89331\n",
      "Epoch: 92/100 Iteration: 1824 Training loss: 0.37738 Train Acc: 0.89490\n",
      "Epoch: 92/100 Iteration: 1825 Validation Acc: 0.8941\n",
      "Epoch: 92/100 Iteration: 1825 Training loss: 0.42463 Train Acc: 0.89172\n",
      "Epoch: 92/100 Iteration: 1826 Training loss: 0.40694 Train Acc: 0.89650\n",
      "Epoch: 92/100 Iteration: 1827 Training loss: 0.37559 Train Acc: 0.89172\n",
      "Epoch: 92/100 Iteration: 1828 Training loss: 0.39084 Train Acc: 0.88933\n",
      "Epoch: 92/100 Iteration: 1829 Training loss: 0.39931 Train Acc: 0.88854\n",
      "Epoch: 92/100 Iteration: 1830 Validation Acc: 0.8782\n",
      "Epoch: 92/100 Iteration: 1830 Training loss: 0.40061 Train Acc: 0.88615\n",
      "Epoch: 92/100 Iteration: 1831 Training loss: 0.37651 Train Acc: 0.88933\n",
      "Epoch: 92/100 Iteration: 1832 Training loss: 0.40245 Train Acc: 0.88854\n",
      "Epoch: 92/100 Iteration: 1833 Training loss: 0.40200 Train Acc: 0.87659\n",
      "Epoch: 92/100 Iteration: 1834 Training loss: 0.41108 Train Acc: 0.88057\n",
      "Epoch: 92/100 Iteration: 1835 Validation Acc: 0.8750\n",
      "Epoch: 92/100 Iteration: 1835 Training loss: 0.41072 Train Acc: 0.87261\n",
      "Epoch: 92/100 Iteration: 1836 Training loss: 0.42332 Train Acc: 0.86704\n",
      "Epoch: 92/100 Iteration: 1837 Training loss: 0.41067 Train Acc: 0.87739\n",
      "Epoch: 92/100 Iteration: 1838 Training loss: 0.38339 Train Acc: 0.88376\n",
      "Epoch: 92/100 Iteration: 1839 Training loss: 0.40202 Train Acc: 0.87580\n",
      "Epoch: 92/100 Iteration: 1840 Validation Acc: 0.8822\n",
      "Epoch: 93/100 Iteration: 1840 Training loss: 0.39499 Train Acc: 0.88137\n",
      "Epoch: 93/100 Iteration: 1841 Training loss: 0.40431 Train Acc: 0.88137\n",
      "Epoch: 93/100 Iteration: 1842 Training loss: 0.38042 Train Acc: 0.88615\n",
      "Epoch: 93/100 Iteration: 1843 Training loss: 0.38794 Train Acc: 0.88535\n",
      "Epoch: 93/100 Iteration: 1844 Training loss: 0.36769 Train Acc: 0.89411\n",
      "Epoch: 93/100 Iteration: 1845 Validation Acc: 0.8957\n",
      "Epoch: 93/100 Iteration: 1845 Training loss: 0.40583 Train Acc: 0.89331\n",
      "Epoch: 93/100 Iteration: 1846 Training loss: 0.41421 Train Acc: 0.89490\n",
      "Epoch: 93/100 Iteration: 1847 Training loss: 0.38795 Train Acc: 0.89570\n",
      "Epoch: 93/100 Iteration: 1848 Training loss: 0.39148 Train Acc: 0.89729\n",
      "Epoch: 93/100 Iteration: 1849 Training loss: 0.41241 Train Acc: 0.88694\n",
      "Epoch: 93/100 Iteration: 1850 Validation Acc: 0.8941\n",
      "Epoch: 93/100 Iteration: 1850 Training loss: 0.39431 Train Acc: 0.90366\n",
      "Epoch: 93/100 Iteration: 1851 Training loss: 0.41013 Train Acc: 0.89252\n",
      "Epoch: 93/100 Iteration: 1852 Training loss: 0.40445 Train Acc: 0.90446\n",
      "Epoch: 93/100 Iteration: 1853 Training loss: 0.38080 Train Acc: 0.89331\n",
      "Epoch: 93/100 Iteration: 1854 Training loss: 0.40893 Train Acc: 0.89889\n",
      "Epoch: 93/100 Iteration: 1855 Validation Acc: 0.8854\n",
      "Epoch: 93/100 Iteration: 1855 Training loss: 0.39818 Train Acc: 0.88376\n",
      "Epoch: 93/100 Iteration: 1856 Training loss: 0.40941 Train Acc: 0.88615\n",
      "Epoch: 93/100 Iteration: 1857 Training loss: 0.38540 Train Acc: 0.89490\n",
      "Epoch: 93/100 Iteration: 1858 Training loss: 0.36811 Train Acc: 0.89013\n",
      "Epoch: 93/100 Iteration: 1859 Training loss: 0.37198 Train Acc: 0.89092\n",
      "Epoch: 93/100 Iteration: 1860 Validation Acc: 0.8774\n",
      "Epoch: 94/100 Iteration: 1860 Training loss: 0.37440 Train Acc: 0.87898\n",
      "Epoch: 94/100 Iteration: 1861 Training loss: 0.41103 Train Acc: 0.89013\n",
      "Epoch: 94/100 Iteration: 1862 Training loss: 0.36925 Train Acc: 0.88137\n",
      "Epoch: 94/100 Iteration: 1863 Training loss: 0.40009 Train Acc: 0.88455\n",
      "Epoch: 94/100 Iteration: 1864 Training loss: 0.38859 Train Acc: 0.88137\n",
      "Epoch: 94/100 Iteration: 1865 Validation Acc: 0.8854\n",
      "Epoch: 94/100 Iteration: 1865 Training loss: 0.39362 Train Acc: 0.87818\n",
      "Epoch: 94/100 Iteration: 1866 Training loss: 0.40385 Train Acc: 0.87420\n",
      "Epoch: 94/100 Iteration: 1867 Training loss: 0.38995 Train Acc: 0.89013\n",
      "Epoch: 94/100 Iteration: 1868 Training loss: 0.38898 Train Acc: 0.87978\n",
      "Epoch: 94/100 Iteration: 1869 Training loss: 0.40513 Train Acc: 0.88137\n",
      "Epoch: 94/100 Iteration: 1870 Validation Acc: 0.8774\n",
      "Epoch: 94/100 Iteration: 1870 Training loss: 0.37804 Train Acc: 0.87978\n",
      "Epoch: 94/100 Iteration: 1871 Training loss: 0.37976 Train Acc: 0.88057\n",
      "Epoch: 94/100 Iteration: 1872 Training loss: 0.39945 Train Acc: 0.89252\n",
      "Epoch: 94/100 Iteration: 1873 Training loss: 0.40180 Train Acc: 0.88217\n",
      "Epoch: 94/100 Iteration: 1874 Training loss: 0.39133 Train Acc: 0.88057\n",
      "Epoch: 94/100 Iteration: 1875 Validation Acc: 0.8822\n",
      "Epoch: 94/100 Iteration: 1875 Training loss: 0.39653 Train Acc: 0.88854\n",
      "Epoch: 94/100 Iteration: 1876 Training loss: 0.41461 Train Acc: 0.88854\n",
      "Epoch: 94/100 Iteration: 1877 Training loss: 0.39198 Train Acc: 0.88455\n",
      "Epoch: 94/100 Iteration: 1878 Training loss: 0.37996 Train Acc: 0.89013\n",
      "Epoch: 94/100 Iteration: 1879 Training loss: 0.38090 Train Acc: 0.88057\n",
      "Epoch: 94/100 Iteration: 1880 Validation Acc: 0.8957\n",
      "Epoch: 95/100 Iteration: 1880 Training loss: 0.38473 Train Acc: 0.88774\n",
      "Epoch: 95/100 Iteration: 1881 Training loss: 0.40876 Train Acc: 0.89411\n",
      "Epoch: 95/100 Iteration: 1882 Training loss: 0.37052 Train Acc: 0.89013\n",
      "Epoch: 95/100 Iteration: 1883 Training loss: 0.38065 Train Acc: 0.89172\n",
      "Epoch: 95/100 Iteration: 1884 Training loss: 0.35190 Train Acc: 0.89013\n",
      "Epoch: 95/100 Iteration: 1885 Validation Acc: 0.8766\n",
      "Epoch: 95/100 Iteration: 1885 Training loss: 0.41436 Train Acc: 0.88854\n",
      "Epoch: 95/100 Iteration: 1886 Training loss: 0.40457 Train Acc: 0.89252\n",
      "Epoch: 95/100 Iteration: 1887 Training loss: 0.38902 Train Acc: 0.88217\n",
      "Epoch: 95/100 Iteration: 1888 Training loss: 0.38749 Train Acc: 0.88694\n",
      "Epoch: 95/100 Iteration: 1889 Training loss: 0.40232 Train Acc: 0.87261\n",
      "Epoch: 95/100 Iteration: 1890 Validation Acc: 0.8830\n",
      "Epoch: 95/100 Iteration: 1890 Training loss: 0.39268 Train Acc: 0.89092\n",
      "Epoch: 95/100 Iteration: 1891 Training loss: 0.41381 Train Acc: 0.87659\n",
      "Epoch: 95/100 Iteration: 1892 Training loss: 0.40063 Train Acc: 0.87818\n",
      "Epoch: 95/100 Iteration: 1893 Training loss: 0.38239 Train Acc: 0.87739\n",
      "Epoch: 95/100 Iteration: 1894 Training loss: 0.42538 Train Acc: 0.87659\n",
      "Epoch: 95/100 Iteration: 1895 Validation Acc: 0.8758\n",
      "Epoch: 95/100 Iteration: 1895 Training loss: 0.40737 Train Acc: 0.87659\n",
      "Epoch: 95/100 Iteration: 1896 Training loss: 0.43880 Train Acc: 0.89013\n",
      "Epoch: 95/100 Iteration: 1897 Training loss: 0.36647 Train Acc: 0.89729\n",
      "Epoch: 95/100 Iteration: 1898 Training loss: 0.38080 Train Acc: 0.87341\n",
      "Epoch: 95/100 Iteration: 1899 Training loss: 0.40063 Train Acc: 0.89172\n",
      "Epoch: 95/100 Iteration: 1900 Validation Acc: 0.8798\n",
      "Epoch: 96/100 Iteration: 1900 Training loss: 0.38058 Train Acc: 0.88296\n",
      "Epoch: 96/100 Iteration: 1901 Training loss: 0.40914 Train Acc: 0.88057\n",
      "Epoch: 96/100 Iteration: 1902 Training loss: 0.37737 Train Acc: 0.88933\n",
      "Epoch: 96/100 Iteration: 1903 Training loss: 0.38974 Train Acc: 0.88535\n",
      "Epoch: 96/100 Iteration: 1904 Training loss: 0.38002 Train Acc: 0.88376\n",
      "Epoch: 96/100 Iteration: 1905 Validation Acc: 0.8854\n",
      "Epoch: 96/100 Iteration: 1905 Training loss: 0.42861 Train Acc: 0.88535\n",
      "Epoch: 96/100 Iteration: 1906 Training loss: 0.41477 Train Acc: 0.89252\n",
      "Epoch: 96/100 Iteration: 1907 Training loss: 0.39254 Train Acc: 0.87341\n",
      "Epoch: 96/100 Iteration: 1908 Training loss: 0.38702 Train Acc: 0.88376\n",
      "Epoch: 96/100 Iteration: 1909 Training loss: 0.40697 Train Acc: 0.87898\n",
      "Epoch: 96/100 Iteration: 1910 Validation Acc: 0.8933\n",
      "Epoch: 96/100 Iteration: 1910 Training loss: 0.39573 Train Acc: 0.88376\n",
      "Epoch: 96/100 Iteration: 1911 Training loss: 0.39237 Train Acc: 0.88615\n",
      "Epoch: 96/100 Iteration: 1912 Training loss: 0.39291 Train Acc: 0.88455\n",
      "Epoch: 96/100 Iteration: 1913 Training loss: 0.39103 Train Acc: 0.87500\n",
      "Epoch: 96/100 Iteration: 1914 Training loss: 0.40109 Train Acc: 0.87818\n",
      "Epoch: 96/100 Iteration: 1915 Validation Acc: 0.8925\n",
      "Epoch: 96/100 Iteration: 1915 Training loss: 0.38490 Train Acc: 0.87898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 96/100 Iteration: 1916 Training loss: 0.42961 Train Acc: 0.87898\n",
      "Epoch: 96/100 Iteration: 1917 Training loss: 0.37862 Train Acc: 0.87978\n",
      "Epoch: 96/100 Iteration: 1918 Training loss: 0.38322 Train Acc: 0.87261\n",
      "Epoch: 96/100 Iteration: 1919 Training loss: 0.40429 Train Acc: 0.87898\n",
      "Epoch: 96/100 Iteration: 1920 Validation Acc: 0.8790\n",
      "Epoch: 97/100 Iteration: 1920 Training loss: 0.38434 Train Acc: 0.89331\n",
      "Epoch: 97/100 Iteration: 1921 Training loss: 0.41140 Train Acc: 0.87420\n",
      "Epoch: 97/100 Iteration: 1922 Training loss: 0.38577 Train Acc: 0.87978\n",
      "Epoch: 97/100 Iteration: 1923 Training loss: 0.39096 Train Acc: 0.87261\n",
      "Epoch: 97/100 Iteration: 1924 Training loss: 0.36945 Train Acc: 0.87818\n",
      "Epoch: 97/100 Iteration: 1925 Validation Acc: 0.8790\n",
      "Epoch: 97/100 Iteration: 1925 Training loss: 0.39992 Train Acc: 0.88137\n",
      "Epoch: 97/100 Iteration: 1926 Training loss: 0.40662 Train Acc: 0.87182\n",
      "Epoch: 97/100 Iteration: 1927 Training loss: 0.37273 Train Acc: 0.88376\n",
      "Epoch: 97/100 Iteration: 1928 Training loss: 0.37826 Train Acc: 0.87898\n",
      "Epoch: 97/100 Iteration: 1929 Training loss: 0.40346 Train Acc: 0.87978\n",
      "Epoch: 97/100 Iteration: 1930 Validation Acc: 0.8798\n",
      "Epoch: 97/100 Iteration: 1930 Training loss: 0.38073 Train Acc: 0.87659\n",
      "Epoch: 97/100 Iteration: 1931 Training loss: 0.39169 Train Acc: 0.87818\n",
      "Epoch: 97/100 Iteration: 1932 Training loss: 0.38629 Train Acc: 0.87580\n",
      "Epoch: 97/100 Iteration: 1933 Training loss: 0.40794 Train Acc: 0.87898\n",
      "Epoch: 97/100 Iteration: 1934 Training loss: 0.41217 Train Acc: 0.88217\n",
      "Epoch: 97/100 Iteration: 1935 Validation Acc: 0.8854\n",
      "Epoch: 97/100 Iteration: 1935 Training loss: 0.41286 Train Acc: 0.87659\n",
      "Epoch: 97/100 Iteration: 1936 Training loss: 0.42376 Train Acc: 0.88057\n",
      "Epoch: 97/100 Iteration: 1937 Training loss: 0.38175 Train Acc: 0.88854\n",
      "Epoch: 97/100 Iteration: 1938 Training loss: 0.38118 Train Acc: 0.88774\n",
      "Epoch: 97/100 Iteration: 1939 Training loss: 0.38653 Train Acc: 0.88694\n",
      "Epoch: 97/100 Iteration: 1940 Validation Acc: 0.8822\n",
      "Epoch: 98/100 Iteration: 1940 Training loss: 0.38893 Train Acc: 0.89013\n",
      "Epoch: 98/100 Iteration: 1941 Training loss: 0.41646 Train Acc: 0.88376\n",
      "Epoch: 98/100 Iteration: 1942 Training loss: 0.37493 Train Acc: 0.88535\n",
      "Epoch: 98/100 Iteration: 1943 Training loss: 0.40774 Train Acc: 0.89570\n",
      "Epoch: 98/100 Iteration: 1944 Training loss: 0.37467 Train Acc: 0.89331\n",
      "Epoch: 98/100 Iteration: 1945 Validation Acc: 0.8893\n",
      "Epoch: 98/100 Iteration: 1945 Training loss: 0.40227 Train Acc: 0.88455\n",
      "Epoch: 98/100 Iteration: 1946 Training loss: 0.40685 Train Acc: 0.89570\n",
      "Epoch: 98/100 Iteration: 1947 Training loss: 0.37037 Train Acc: 0.89092\n",
      "Epoch: 98/100 Iteration: 1948 Training loss: 0.38203 Train Acc: 0.88615\n",
      "Epoch: 98/100 Iteration: 1949 Training loss: 0.39323 Train Acc: 0.88376\n",
      "Epoch: 98/100 Iteration: 1950 Validation Acc: 0.8917\n",
      "Epoch: 98/100 Iteration: 1950 Training loss: 0.37917 Train Acc: 0.89490\n",
      "Epoch: 98/100 Iteration: 1951 Training loss: 0.38678 Train Acc: 0.89172\n",
      "Epoch: 98/100 Iteration: 1952 Training loss: 0.39907 Train Acc: 0.88854\n",
      "Epoch: 98/100 Iteration: 1953 Training loss: 0.37932 Train Acc: 0.88376\n",
      "Epoch: 98/100 Iteration: 1954 Training loss: 0.40321 Train Acc: 0.88694\n",
      "Epoch: 98/100 Iteration: 1955 Validation Acc: 0.8933\n",
      "Epoch: 98/100 Iteration: 1955 Training loss: 0.39385 Train Acc: 0.89570\n",
      "Epoch: 98/100 Iteration: 1956 Training loss: 0.41162 Train Acc: 0.89411\n",
      "Epoch: 98/100 Iteration: 1957 Training loss: 0.38296 Train Acc: 0.89729\n",
      "Epoch: 98/100 Iteration: 1958 Training loss: 0.38936 Train Acc: 0.89252\n",
      "Epoch: 98/100 Iteration: 1959 Training loss: 0.38007 Train Acc: 0.88854\n",
      "Epoch: 98/100 Iteration: 1960 Validation Acc: 0.8885\n",
      "Epoch: 99/100 Iteration: 1960 Training loss: 0.38373 Train Acc: 0.88854\n",
      "Epoch: 99/100 Iteration: 1961 Training loss: 0.40859 Train Acc: 0.89889\n",
      "Epoch: 99/100 Iteration: 1962 Training loss: 0.37093 Train Acc: 0.89650\n",
      "Epoch: 99/100 Iteration: 1963 Training loss: 0.37699 Train Acc: 0.88854\n",
      "Epoch: 99/100 Iteration: 1964 Training loss: 0.36891 Train Acc: 0.89650\n",
      "Epoch: 99/100 Iteration: 1965 Validation Acc: 0.8917\n",
      "Epoch: 99/100 Iteration: 1965 Training loss: 0.39772 Train Acc: 0.89490\n",
      "Epoch: 99/100 Iteration: 1966 Training loss: 0.40611 Train Acc: 0.89411\n",
      "Epoch: 99/100 Iteration: 1967 Training loss: 0.37840 Train Acc: 0.90366\n",
      "Epoch: 99/100 Iteration: 1968 Training loss: 0.39075 Train Acc: 0.89889\n",
      "Epoch: 99/100 Iteration: 1969 Training loss: 0.38897 Train Acc: 0.89570\n",
      "Epoch: 99/100 Iteration: 1970 Validation Acc: 0.8885\n",
      "Epoch: 99/100 Iteration: 1970 Training loss: 0.38651 Train Acc: 0.89889\n",
      "Epoch: 99/100 Iteration: 1971 Training loss: 0.39508 Train Acc: 0.89013\n",
      "Epoch: 99/100 Iteration: 1972 Training loss: 0.38882 Train Acc: 0.89968\n",
      "Epoch: 99/100 Iteration: 1973 Training loss: 0.39213 Train Acc: 0.88854\n",
      "Epoch: 99/100 Iteration: 1974 Training loss: 0.38292 Train Acc: 0.89968\n",
      "Epoch: 99/100 Iteration: 1975 Validation Acc: 0.8885\n",
      "Epoch: 99/100 Iteration: 1975 Training loss: 0.38786 Train Acc: 0.89331\n",
      "Epoch: 99/100 Iteration: 1976 Training loss: 0.41633 Train Acc: 0.89092\n",
      "Epoch: 99/100 Iteration: 1977 Training loss: 0.39078 Train Acc: 0.89092\n",
      "Epoch: 99/100 Iteration: 1978 Training loss: 0.38435 Train Acc: 0.88774\n",
      "Epoch: 99/100 Iteration: 1979 Training loss: 0.37685 Train Acc: 0.88615\n",
      "Epoch: 99/100 Iteration: 1980 Validation Acc: 0.8965\n",
      "Epoch: 100/100 Iteration: 1980 Training loss: 0.37406 Train Acc: 0.89331\n",
      "Epoch: 100/100 Iteration: 1981 Training loss: 0.38186 Train Acc: 0.89092\n",
      "Epoch: 100/100 Iteration: 1982 Training loss: 0.39174 Train Acc: 0.88376\n",
      "Epoch: 100/100 Iteration: 1983 Training loss: 0.39041 Train Acc: 0.88615\n",
      "Epoch: 100/100 Iteration: 1984 Training loss: 0.36049 Train Acc: 0.89172\n",
      "Epoch: 100/100 Iteration: 1985 Validation Acc: 0.8901\n",
      "Epoch: 100/100 Iteration: 1985 Training loss: 0.41121 Train Acc: 0.89889\n",
      "Epoch: 100/100 Iteration: 1986 Training loss: 0.40931 Train Acc: 0.88535\n",
      "Epoch: 100/100 Iteration: 1987 Training loss: 0.38181 Train Acc: 0.89252\n",
      "Epoch: 100/100 Iteration: 1988 Training loss: 0.38162 Train Acc: 0.88217\n",
      "Epoch: 100/100 Iteration: 1989 Training loss: 0.39854 Train Acc: 0.88854\n",
      "Epoch: 100/100 Iteration: 1990 Validation Acc: 0.8838\n",
      "Epoch: 100/100 Iteration: 1990 Training loss: 0.40536 Train Acc: 0.88217\n",
      "Epoch: 100/100 Iteration: 1991 Training loss: 0.40167 Train Acc: 0.87102\n",
      "Epoch: 100/100 Iteration: 1992 Training loss: 0.40715 Train Acc: 0.87898\n",
      "Epoch: 100/100 Iteration: 1993 Training loss: 0.37216 Train Acc: 0.88217\n",
      "Epoch: 100/100 Iteration: 1994 Training loss: 0.41024 Train Acc: 0.87500\n",
      "Epoch: 100/100 Iteration: 1995 Validation Acc: 0.8734\n",
      "Epoch: 100/100 Iteration: 1995 Training loss: 0.39175 Train Acc: 0.87978\n",
      "Epoch: 100/100 Iteration: 1996 Training loss: 0.42129 Train Acc: 0.88455\n",
      "Epoch: 100/100 Iteration: 1997 Training loss: 0.38374 Train Acc: 0.88217\n",
      "Epoch: 100/100 Iteration: 1998 Training loss: 0.39117 Train Acc: 0.87978\n",
      "Epoch: 100/100 Iteration: 1999 Training loss: 0.38464 Train Acc: 0.88455\n",
      "Epoch: 100/100 Iteration: 2000 Validation Acc: 0.8822\n",
      "That took 619.475370s\n"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "train_loss_hist = []\n",
    "train_acc_history = []\n",
    "val_loss_hist = []\n",
    "val_acc_hist = []\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    tic = time.time()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for e in range(epochs):\n",
    "        for x, y in get_batches(train_x, train_y, n_batches):\n",
    "            #print(x[0:1])\n",
    "            feed = {image: x,\n",
    "                    label: y,\n",
    "                    dropout: 0.5}\n",
    "            #print(e, x.shape, y.shape)\n",
    "            train_loss, _ = sess.run([loss, optimize], feed_dict=feed)\n",
    "            train_loss_hist.append(train_loss)\n",
    "            train_accuracy = sess.run(accuracy, {image: val_x, label: val_y, dropout: 1.0})\n",
    "            train_acc_history.append(train_accuracy)\n",
    "            #acc_hist.append(acc)\n",
    "            print(\"Epoch: {}/{}\".format(e+1, epochs),\n",
    "                  \"Iteration: {}\".format(iteration),\n",
    "                  \"Training loss: {:.5f}\".format(train_loss),\n",
    "                  \"Train Acc: {:.5f}\".format(train_accuracy))\n",
    "            iteration += 1\n",
    "            \n",
    "            \n",
    "            if iteration % 5 == 0:\n",
    "                #val_loss = sess.run(loss, feed_dict=feed)\n",
    "                #val_loss_hist.append(val_loss)\n",
    "                feed = {image: val_x,\n",
    "                        label: val_y,\n",
    "                        dropout: 1.0}\n",
    "                val_acc = sess.run(accuracy, feed_dict=feed)\n",
    "                val_acc_hist.append(val_acc)                \n",
    "                print(\"Epoch: {}/{}\".format(e+1, epochs),\n",
    "                      \"Iteration: {}\".format(iteration),\n",
    "                      #\"Training loss: {:.5f}\".format(val_loss),\n",
    "                      \"Validation Acc: {:.4f}\".format(val_acc))\n",
    "    #print(val_acc_hist)\n",
    "    toc = time.time()\n",
    "    print('That took %fs' % (toc - tic))\n",
    "    saver.save(sess, \"checkpoints/ticker.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAACgCAYAAADjNXB5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3Xd4VHXWwPHvSQIBpJNQBDRUBQugoShlQZSmgmVXcXXturq2dVf3RVHXhrKufdV1seuCWFEUWFEEQamhg1QhQOhNWkhIOe8f987kzmRmUieFnM/z5GHmzp17D3eSe+bXRVUxxhhjAGLKOwBjjDEVhyUFY4wxfpYUjDHG+FlSMMYY42dJwRhjjJ8lBWOMMX6WFIwpBhG5XkR+jPD6FBG5rixjMqY0WFIwlZqIpIrI+eUdRzBVHayq7xW0n4ioiLQti5iMKQxLCsZUUiISV94xmOOPJQVz3BKRW0RkvYjsE5GJInKiu11E5AUR2SUiB0RkmYic7r42RER+FpFDIrJVRO4r4BzPish+EdkoIoM922eIyM3u47Yi8oN7rj0i8pG7faa7+1IROSwiV0aK231NReQOEVkHrBORV0XkuaCYvhKRP5f8CpqqyJKCOS6JyHnA08AVQDNgEzDefXkA0AdoD9QHrgT2uq+9BfxRVesApwPfRzhNd2ANkAA8A7wlIhJivyeAqUADoAXwLwBV7eO+3klVa6vqRwXE7XOJe+6OwHvAVSIS4/6/E4D+wIcR4jYmLEsK5nh1NfC2qi5S1UzgAeAcEUkCsoA6wKmAqOoqVd3uvi8L6CgidVV1v6ouinCOTar6hqrm4NycmwFNQuyXBZwMnKiqGaoatoG6gLh9nlbVfap6VFXnAwdwEgHAcGCGqu6McA5jwrKkYI5XJ+J8ywZAVQ/jlAaaq+r3wCvAq8BOERkjInXdXS8HhgCb3CqfcyKcY4fn+Onuw9oh9vsbIMB8EVkpIjcWJ27PPluC3vMecI37+BrggwjHNyYiSwrmeLUN59s5ACJyAtAI2Aqgqi+r6tnAaTjVSPe72xeo6jCgMfAF8HFJA1HVHap6i6qeCPwReC1Cj6OIcfsOGfSe/wLDRKQT0MGN25hisaRgjgfVRKSG5ycOGAfcICKdRSQeeAqYp6qpItJVRLqLSDXgCJAB5IhIdRG5WkTqqWoWcBDIKWlwIvI7EWnhPt2Pc1P3HXcn0Nqze9i4wx1fVdOABTglhM9U9WhJYzZVlyUFczyYDBz1/DyqqtOAh4HPgO1AG5z6doC6wBs4N+hNONUzz7qv/QFIFZGDwG3kVcuURFdgnogcBiYC96jqRve1R4H3RORXEbmigLgjeQ84A6s6MiUktsiOMZWfiPTBqUZKUtXc8o7HVF5WUjCmknOrwe4B3rSEYErKkoIxlZiIdAB+xekO+2I5h2OOA1Z9ZIwxxs9KCsYYY/wsKRhjjPGrdLMsJiQkaFJSUnmHYYwxlcrChQv3qGpiQftFNSmIyCDgJSAWp2fE6KDXXwD6uU9rAY1VtX6kYyYlJZGSkhKNcI0x5rglIpsK3iuKSUFEYnHmlrkASAMWiMhEVf3Zt4+q3uvZ/y6gS7TiMcYYU7Botil0A9ar6gZVPYYz/e+wCPtfRRlM97tmx6Fon8IYYyqtaCaF5gTO5phG4EyPfiJyMtCKyHPXl9j/Vuxg4Isz+XrZtmiexhhjKq1oJoVQi42EGxQxHPjUnZc+/4FEbhWRFBFJ2b17d7GCOZSRxXNT1wCwbufhYh3DGGOOd9FMCmlAS8/zFjjTAocynAhVR6o6RlWTVTU5MbHAxvOQxszcwLpdTjKoFhsqXxljjIlmUlgAtBORViJSHefGPzF4JxE5BWeZwjlRjIXLzmrhf7x+12FufT+FrBybJsYYY7yilhRUNRu4E/gGWAV8rKorReRxERnq2fUqYLxGeb6NhidU9z/+Ysk2pv68k0tf+4kdBzKieVpjjKlUKt3cR8nJyVqccQq5uUrrByeHfC119IUlDcsYYyo0EVmoqskF7VdlprmIiREWjDw/5Gs7D1ppwRhjoAolBYDEOvHExeRvZO7+1DQWb97P4cxsa2cwxlRplW7uo5LKzg1dXXbpa7MB6N0ugQ9u6l6WIRljTIVRpUoKhTFr3R5GfLaMH9ftKe9QjDGmzFW5pHC5p2tqOOMXbOGat+aVQTTGGFOxVLmkUKt6bHmHYIwxFVaVSwotGtQs7xCMMabCqnJJ4YaerQq9797DmVGMxBhjKp4qlxSqx8Uw9ubuvHxVwUs3nP3kdxzJzC6DqIwxpmKockkBoGfbBIZ2OpEBHZsUuO+H8zeXQUTGGFMxVMmk4DPm2gJHfBtjTJVSpZNCYYjYNNvGmKqjyieFm3q1YuSQDmFft5RgjKlKqnxSePiijtzSp3V5h2GMMRVClU8KBbEJ8owxVYklhQI8PWU117w5j22/Hi3vUIwxJuosKbh+GnEeCbWrh3ztx/V7OHf09yzd8msZR2WMMWUrqklBRAaJyBoRWS8iI8Lsc4WI/CwiK0VkXDTjiaR5/ZqkPHRBxH0mLd/uf7zrUAa5YabhNsaYyipqSUFEYoFXgcFAR+AqEekYtE874AGgp6qeBvw5WvGUhhw3CWzcc4Ruo6bxzuzU8g3IGGNKWTRLCt2A9aq6QVWPAeOBYUH73AK8qqr7AVR1VxTjKZSebRuFfc2XFJalOdVIizbtB2DK8u0cSM+KfnDGGBNl0UwKzYEtnudp7jav9kB7EflJROaKyKAoxlMo71zfLexr785OZeLSbWRk5QBOdVLqniPcPnYRd49fXFYhGmNM1EQzKYQa9xVcCR8HtAP6AlcBb4pI/XwHErlVRFJEJGX37t2lHqhX9bjIl+T1Gb/g7aXa99kZAGzZnx7FqIwxpmxEMymkAS09z1sA20Ls86WqZqnqRmANTpIIoKpjVDVZVZMTExOjFrDPi1d25s5+bUO+tutQJg9OWJ5v+4bdR6x3kjGm0otmUlgAtBORViJSHRgOTAza5wugH4CIJOBUJ22IYkyFckmX5tw38BTO79A432t7IqyxMOzVn6IZljHGRF3UkoKqZgN3At8Aq4CPVXWliDwuIkPd3b4B9orIz8B04H5V3RutmIrquSs6F/k9/527KQqRGGNM2RDVytXXPjk5WVNSUsrsfLe8n8K3P+8s9P4dm9Vl8j29oxiRMcYUnYgsVNUC1wuwEc0FGPOHs4u0vwKVLdEaY4yPJYUCiAidWtQr9P6rth+k66hp+bYfPZZDtk2uZ4yp4CwpFEJMTNFWVfA1Ro+dt4nRU1YD0OGR/3H72EWlHpsxxpQmSwqFUNyFdkZOWMHrP/zif16UtgljjCkPlhQKoThLci6xMQvGmEqoUElBRNqISLz7uK+I3B1q5PHxqlurhv7HCx86n/WjBhf4nks8YxbaPzTF/3jC4jT/HErGGFPRxBVyv8+AZBFpC7yFMwhtHDAkWoFVJPcNOIVTm9bh3DYJNKodX+T3H8vOa2C+96OlzFizm5eGdynNEI0xplQUtvoo1x2MdinwoqreCzSLXlgVS2yMMKxzcxLrFD0hhPLlkuDZPowxpmIobFLIEpGrgOuAr91t1aITUtX15ZKtDHpxZnmHYYypwgqbFG4AzgFGqepGEWkF/Dd6YVUtR4/lsP/IMe4Zv4TVOw4VaUW3jKwcnp+6xj+dtzHGlEShkoKq/qyqd6vqhyLSAKijqqOjHFul8MFN4ddfiOTRiSv5YE4qCzftZ+grP9LliW/9r01YvLXQx3lz1gZe/n49789JLVYcxhjjVdjeRzNEpK6INASWAu+IyPPRDa1y6NkmgbvPCz3NdiTvzk7l4S9Xcvm/Z7Nu1+GA1/76yVJ2HswI2LbrUAaPfLmCrKBR0enHnBJCVo71aDLGlFxhq4/qqepB4DLgHVU9Gzg/emFVfG0b1wac0c73XtCeFY8NLNXjB0+f9OjElbw/ZxMfp2wJ2O6raSrGUApjjMmnsEkhTkSaAVeQ19BcpX10aw8+urUH4Axuqx1f2N69hRMT9Mn4ksTICSsCtue6L8RYVjDGlILC3skex1n74CdVXSAirYF10Qur4mtUO75YYxYKTWHOL3s5lJHF9gMZbP31aMjdfI3SRZyeyRhjQipUUlDVT4BPPM83AJdHK6jK7qs7e3HxKz+W6BjXvDWPtTsPF7ifr/qotEsK63YeIrFOPPVrVS/V4xpjKrbCNjS3EJEJIrJLRHaKyGci0iLawVVWZ7Sox3mnOkt5Frd3UqSEcO9HSwCnK+sHc1MBeHLSKv/rWTm57DqUQddR37Fi64Finf+CF2YGTNVhjKkaCtum8A7O1BYnAs2Br9xtEYnIIBFZIyLrRWREiNevF5HdIrLE/bm5KMFXND+NOI9Jd/cC4O3ru5I6+kJ6t0ss9fP4uqw+O3VNyF5HA1+YSbdR09h9KJPfvzGXcfM2F+s8qXvTSxSnMabyKWxSSFTVd1Q12/15F4h4txORWOBVYDDQEbhKRDqG2PUjVe3s/rxZlOArmub1a3LaieEX5LmhZ1KpnWvP4Uz2px8L2Ja2P52kEZPYsOeIf9vBjGwenLCczXvTyclVDmdmkzRiUkCi2HUwg+9X27TexpjCJ4U9InKNiMS6P9cAewt4TzdgvapuUNVjwHhgWEmCrexGDD6V7/7Sp1SO9fTk1fm2DX0lfHVPn39O56Vp61ie5lQnjZn5C7m5ynVvz6fbU9O48d0U/jR2oSUHY6q4wiaFG3G6o+4AtgO/xZn6IpLmgLdTfZq7LdjlIrJMRD4VkZahDiQit4pIioik7N69u5AhVzzVY2No27hOqRzrs0VpfL4ocOTzviPHwuztmL9xL/d/uhRwqoYOZWbzw9q86zl5+Q5ufDelVOIzxlROhZ3mYrOqDlXVRFVtrKqX4AxkiyRUd5jgCvCvgCRVPRP4DngvzPnHqGqyqiYnJpZ+HX20ndumEZC3WM9DF3bgnv7tyjyOuJgYMrI8I6LDDIL+af2eiMc5nJld7AZsY0zFVpIRV38BXozwehrg/ebfAgiYM1pVvVVQbwD/KEE8Fdbb13flYEaW//nNvVsD8Mvuw3y9bHuZxREXG5inNUxWWLhpf8jtqsqsdXt4dfp65m3cx+onBlGjWmypx2mMKT8lWY6zoI7xC4B2ItJKRKoDw3F6MOUdwBkl7TMUWMVxqEa1WBrXqZFve1wZjzgLPt+Bo1lh9gxt6s87ufbt+czbuA+ATLfUkZGVQ9KISXy8YEukt3Pd2/OL3RPKGFM2SpIUIs7A5i7KcyfOSOhVwMequlJEHheRoe5ud4vIShFZCtwNXF+CeCqdmGIkhf8bdGqxz/fdql3sOZzpf340zHTbuUETL/V+5ntGTfqZLfsCu6hm5TpJwdeW8bfPljFywnKygybt8/lh7W4enLA8YNu2X4+yeHPokokxpuxFTAoickhEDob4OYQzZiEiVZ2squ1VtY2qjnK3PaKqE93HD6jqaaraSVX7qWr+LjXHsUs6h2p3j+z2vm24f+AppXJ+7zKhXt7qowmL09iy7yhvzNpIbFAS+2n9HvYczgwogYydt5nFW34tdAz9n/uBS1+bDcDUlTvYFTQ7rDGmbEVMCqpaR1Xrhvipo6qlOwNcFdSnfSINTyj6NBK+huuSStsfej6lWevyGprv/Wip/3Fw9dM945dw+b9n53u/b3rv1TsO0vnxqXy5JLCX1PPfruX6d+YDeaWVV6ev59YPFjL8jbn+/dbuPMRjX61Eg6eMLSXhkqIxVVlJqo9MKZg94jxmjzjP/3zj00PY8NQQPrv9HBY9fEHI9wT0ICqBP41dVKT9P12Uf/GfTXvT2XUoM2Dby9PWsXbnIQa9OItf07O4Z/ySfK/PWBPYtfif36wBYMPuIySNmEROrnLtW/N556dUdoQpPeTmar4qrcLasi+d9g9N4ZOUyO0gqXuOhFzV7vUffmHuhoKG6hhT+VhSKGc1qsVSp4ZT6DqheiwiQkyMcPbJDcOWInz7l7WlYaqFLvpX4OR/czfs49KgeZP+79NlRTpXTq6S7bZZxMYIubnKjgOByeHV6evp/cx0NnpGcBfWul2HAJi0fDsZWTlc/K8fWbhpX8A+ublK32dncPt/Fzr7LtvOpr3OuUZPWc3wMXMpTwczsvyDDQ8czeK/czdFrVRlqg5LChWAr66+Sb38PZRm3NeXZY8O4JnfnsnUe53R0Kc3Dz+VRkVx5Fjgt+uPQnwjj3QDy1UlJzdvrYgXv1tLj6ensc0zhfiP7niK7QeO8sPa3SSNmFTokoO4nedUYf2uwyzfeoBHvlwZsE+OG990t1Rzx7hFDH5pVr5jHUgvWi8ur+mrd/HBnNRivfcvHy3hxndT2PrrUR74fBkPfbGCpWk2fsSUjCWFCqBW9ThevLIz427uke+1pIQTqFujGlckt6R9k7zR0O/c0DXksZrXr8knt50TtVhLU6sHJod9zSkpODflvv+cwcvfrwecOZ9e/M5pk/CllIysHH81UEGN3DsPZpA0YhJfLXWGzHjTUq7CA58vI2nEJJanHchXLQbO8qfem/jHC7bQ6fGprN15KN++f3hrHnd9uDjf9oWb9vtHkt/w7gIeDkpGkRzxDBzcsNsptRw9lsPew04PsFBVXcWVm6vc/8lSG6hYxVhSqCAu6dKcpiFKCuGc2jT0dBndWjWka1JD7uxX9HWjK5IcVf8CQoczs/3bnVKD0yYx3x0vceO7Kf5BgHd/uJikEZNIGjGJzXvT2fbrUTo9NpU7xy1i58EMf8P4F27jt6r616JQVT6c7ySXW95P4bq35/vP6y3VeG/i09zqm1XbD+ZbP3vWuj18tXQb6ceyuWPcIn/Pqsv/PTvg2D4LN+1n/PzI4zjuHLeIi/71I0eP5XhGCuX9H4K7E5fEjoMZfLIwjVvft6lPqhLrQVRJNatXk4//eA5nNK/H/vRjnDv6ewBGXXo64HRdfWX6+nzvqx4XUyl63eTmqr/6prj6/HM6d/Rrw4GjWXy9bDvrdh7297iqHR/HwYxsZq3bw939s/O9N1c1oK0iXLtFpnst7xm/hOe/XUu9mtWoVT2W567o7N/ni8XbmLRsO3Xi4xh9+Zlh4/UlrOHdTgq7T0qq0134WE6uPyeoetboLsUmBd8I+GMhpmc3xy8rKVRi3Vo1pGb1WH+bRP1a1ahV3cnz4VZiW/b3Abx1XXKZxVhcT05aFbKXVfqxolWPvDFzo//xGk8Vz8GMvERw3ydOt1vvlOO7DmX62zQABr2Yvy0BCOhFtWlvOsvSDjB3wz56ukka8qYTKc36/txc9c+lpeQlBcUp1XgHKZb0S4CvwX/3oUx/aejnbQf9I+LTj2WHHbBoKh9LCseBUAkgVE74+8UdqVEtlh6tCzfOoXpc+f16fLowLeT2K/4zp0jHOVaIm9UmdzGhSDfPwhwnnENuAlq1/WDA9jm/FKNLq/u5BldV+eS6VWDJT37Hos37eeenjbR/aArL0n7lw/mb+cf/Ch4f+u3POzmSmY2bC8jOUbJycuk66jv+5vYiG/LyLDo9NpVpq3bS8ZFvuOk9q2I6XlhSOA4EjzSG/EnhtavP4oaerYDAm31So1phjzuiBFNqmDyjp+TdiN+ctcH/+CrPQL3fhhgE6PPSd+tIGjEpYFtWrrJ+l7Nk6/YDGfy03kkwf/14Kd+tcto5LnttNo999TPgrLXxwOfL+feMX/hh7W5UlWmrdvq/4asqBzOyWL/rELe8n8KIz5f7q+8OZ2b7S2iTlm9n5ba8Eo8vGXinYC8Nk5Zt56nJpTMVmjfZH3L/j+Vh/PzNfLE4/1ifisaSwnEgVEVRcOkhsU68/7F3ZPKzv+sU8ph/vaA9Z7So+F1fKxvvWtpeKUEz0y7d8itJIyax62AGL3y3FoDznp1Btlu/762e8jZa7zqUyferd0WMYeKSbcxYs5ub3kuh7cgpTFq2nVYPTObMR6eSuscpNX21dBtpnu69vm63qsodBQx6fP2HX1iWVvipTkK5Y9wixszcEHGfZWm/stvtIbbvyDGn8T3IF4u30v6hKf42oavfnMf5z88sdBwb9xwJqEYsiRGfL+fPHy0peMdyZknhOFUtNob3b+zG/Af7M/bm7nRNauh/TTwJI9yYh7v6tyOxdnzI10z0DXMH/3V7app/24Y9R8JOYlgUny1K45uVO/zP7xiXd5N/b06q//HVb87zP/aVGnK14BH1o6esDlgFMDdX+XLJ1og31zdnbWB6Acks2NBXfuJid+DkWU98yyXuNcvJVTbsdkpR/1vh/D9Xu1V3y0K06xxIz8o351ZurjJ15Q76PTuD5Ce/zTdwsiTSj2WTuueIP8aKxpLCcSDW7SXSvH7NgO192ifSuG4NerZNCPte73oIH90aOE4iKeEEJt/dm3WjBhcYwzU9wveYMUXjrZ4pjjB9DAKMDzPNuXfeq2zPTXzycqfLb06uhp12ZNCLMxn2St7o9qcnryIzO4ex8zdzz/gljJu3yf/a1JU7+NDtfjv7lz08OWkVN7y7IN/NObjabMXWAxxIz/J3EfbG4utIcPN7CzjvuR/YuOcIMe4dLrgn29wNe5m+eheTl2+n0+NT6fbUNPYfOcaB9Cy27EtnzKwN3PqBM5J9f3oW177tJMgvl2xlq2cAZU6uFrkhv+Mj39D32Rmc99wPRXpfWbEuqceBujWq8drVZwWUBoqje4gG6I4n1gXgqm4tSd2Tzhx3vp+xN3cP/CZZgs4nw7u2ZPyCLfzu7BZ8EqaBuSq58OUfC94pgmoxMSVqGA/FNzdVJKt3BNbV/2fmBpISTmC3e+Pe61ku1nfDzc5VHv5ihX/7Ja/+xOwH+gcc5zf/nM5fB5zC0E4nctG/fqRDs7pM+NO5YePwjUDf/utRfzXqroOZTPIsaBVqipKnp6zi+9W72XM4k8GnNw14bceBDHJzlXvGL6FZvRrMcWP84wcpfLdqF7f2aU3yyQ0YcFrTfMd1zh++pPHU5FVsP5DBv67qEnaf9GPZ7E/PyvfFLxqspHCcGHJGs4B2g+J678ZujLu5e77tT192Jh96ShI92yb4v5HeN6A9CbXz5mkaeFqTgPeG+uZaJz7v+8iFZzYjdfSFJCWcUMLoDZSsp1Rp23Egw9/9N0aEjKwcHvoib00Nb0IA2BaimmbT3nTu/nCxv3SwavvBgPYD72JR3kGGv39znj8pPP71zwHVZKF8nJIW0JXXKztX/euHbPfE+N0qp8przMy8kkUowdO+eI2ZucE/wj6cq9+cF9COFE2WFKqoG3omMfqyM/Jt/037RM6NUN3k9cYfkunVNoE7+rXlzvPa0rRuDWIEXv39WQH7ndq0br73vji8c75t13Q/mXaNaxd43qGdClzKw1QQL01bx7uzUwFnyvRPF6bx37mRR20/9lXoaT96PzPd/9h3gwbo9NhU/+OdBwNv6qF65hXGlBU7Ap6nH8thxdbALsVjPdVhPv9bEbi87ow1u5i2ameBs/ECjAxagOrvX67gjEe/AWDx5pI13BdFVKuPRGQQ8BIQC7ypqqPD7Pdb4BOgq6pah+cy8PeLTyvxMc7v2ITzOzqlgvi4WOY+2D/fPg9d2IGhnU7kpWnrWLT5V9bsOEiuwqnN6tKrbYJ/UjuAerWq8e1ffsOoST/zxqyN+Y7l8+KVnZkY4ptV9dgYLujYhElu/fflZ7Xgs0VWHVWRFGaQ2zs/pYbc7l3/49ynQ39r7vH0tIDnE0qxC2jw2iEjJ6zIt89t/3VKI7f0bsVNvVpz/TsLIh5zQWrezLxj522my0kNWLfrEA8M7sB7cza551ke7u1REbWSgojEAq8Cg4GOwFUi0jHEfnVwluKcF/yaKRvXn5tUomU+I/l995NoXLcGoy49gyn39KZFA2dchPfmEG42iwcG54/pizt6EhMjXN09f8P2teeczFOe0o93hbrp9/UNG+Nv2idG/D/8ocfJEV83hVdaM2Zkl1I30eIKVUrwemPWRm4fG746yed3rwcOxrzvk6X854cN9PD0OhvrWde8LKZGj2b1UTdgvapuUNVjwHhgWIj9ngCeAWwdxnLy6NDTuL1vm6gcO3i8xLs3dOXq7if5k0Mo3ukbvMb84Ww6t6wPwODTm+V7X3pWDnVrxNH/1MZceGYzmtSNp30TpzrqSGZ2QNvGO9fnzTLboVn+6i0vX2kokieGlbzkVRU88fXP5R1CqQhVSghWkiqfsAtLlUEujGb1UXPAW5GWBgS0YIpIF6Clqn4tIvdFMRZTSibe2ZMjmYXvKx+cFFon1mbUpc63+XBdJ70TvflsfHpIwPiKUMbN28xTl57BW54b/kvDu/D8t2tp36QOvdslMtMdedvv1Ma8dvVZTFi8Nd8yoz6PDT2N5vVrRixJXJnckn/81pnkrk3j2ny1dJt/plVjSlt2bi6xMbEF71gC0SwphPpL8/+Zi0gM8ALw1wIPJHKriKSISMru3aU7nN4UzZkt6nNOEdaILk47X4uGTimiWb0a/N6tJgpOCBpiOlBvDyifDs3q8sa1yVSPi/Hf/Hu3cxrSh5zRjDeuTfZ3uw12VbeTAkoJ3Vo1ZH5Qu8ld/fOmKD+3TQJPXxZ+FtTPI3SjNKYwSmt0dSTRLCmkAS09z1sA3tbBOsDpwAz3D74pMFFEhgY3NqvqGGAMQHJyss3jWwl8cUdPvl66rVC9P4I/0Ku7nUSLBjXp2z6RYZ1P5Mlhp4d9b72a1fxdEgtaj6JX2wS+X72Lhy8KbNoackYzpt7bhwEvONMfPHnJ6VwT1I6w5slBxIoQFxtD6ugLC/w/ea0fNZjDmdnUrxV6eVWAFg1qBjSkAvzrqi68+ePGfMug3tAzKWxjbEE6tawfdllVU/GlH8vxz4QcLdEsKSwA2olIKxGpDgwHJvpeVNUDqpqgqkmqmgTMBfIlBFM5dW5Zn4cu6lhglU8oMTFCv1MaIyL+NauDtWvsLDL06NCOfHb7OSTUjuf+gZEby2/omcScB84LWMHOp32TOvyxT2tqx8eFbMSOj4slLrZwfy7BA5/iYmPyJYQ/uW04r19zNiseG8iEP/XkreuSWfvkYGq6o8xzPQsN+dw/8BT+fvFp/kFM8YWYybZEy2lfAAANhElEQVRjs7q8dvVZ/OcPZ/PlHT3922/p3YoHh9ikh5XJG7MizwdVGqKWFFQ1G7gT+AZYBXysqitF5HERGRqt85rK49Ghp9HvlES6tyr6SOym9WqQOvpCLu3SgrNPbkjKQ+cX2ItIRGhWL/yI0AeGdGDFYwOLlci8XriyM9/82VlP+/pzkwJee+53nbipVyv+NuhUUkdfyKDTm1I7Po7EOvH079CE6nExTLyzJ20ST+A37RP9U2R/fVcvUkdfyB3uinp/Pr8d4Az8m/Cnc5k94jzG3ZLXZPf9X3/jfzys84kMOaMZA4NG257StC5N6ha82t+P/9evwH1aNCj6SNuiTM1enOOHPGdQYg/+fCq6fYePFbxTCUW1HKKqk4HJQdseCbNv32jGYiqeNom1eeeGbuUdRqmrUS2WU5rWCVnNdPnZLbi8gPe3a1KHaX/tC+R1vawWdDPzJq4uJzUA4ETPFAitE/MGAf7xN4E9y6bf15cFqfu4/KzmgLNqHDillr1HMklqdELAFCbheop1TWrAAncluNrxoW8l57Ru5J8aJdjA05rmG8nrrQ706tCsbr7qteJ454au/Lh+D/+e8QvgjKMZfHpTToiP4yJ3cr3U0Rey82AG3Z+alu/9KQ+dT/KT35U4juIa1rl51M9hI5qNqcB6uaPLG4VoRA/l7xd39K+sN39kfxY/fEG+fVolnMAVyS391XNzHjiPFY8NZNDpTbm6+8n0bJvAP90eVSe76218cFM3buzZitVPDGLFYwM5t00jHve09fRo3YgPb+mR71w3927lf/zvqwNHuj/7uzOZcV/fgJH179+Y9yWhtWfaE2+V3O9DVO8F639q44DnSx8ZwNd39aJn2wTuPs8pZcXFOG1E3Vs3yjdbsLcEtezRAYBTVZdQSjMHX9al4Jt7wxMCP/O4GKFXu8LNNlASlhSMqcBGXtiBH/+vX76b0VknOeM1Lg6a8uOGnq3o38HpMdW4Tg0anFBwMmlWr2a+b/q/S27JqscHMfVepxqsd7tEHnFX7qsdH8e4W3oEjO8YeWEHOrV0bqwDOjbxt4v4YgEYfEbe2JI6NeKIj4slKeEEhnc7iTVPDmLy3b3p1LI+Nao5tyXv5HKxMcJNvZwE410Yqpun6vH5K/LWBlGcRnWAhNrx1KtVzX/jr+bOKnxqs/xtS6HUrVGNuQ/0Z27QRH3e840c0sH/2PtZLQqRlGf9rR/Ped4brmrs09vOKVR8pc1mSTWmAqsWGxOy+qZ1Yu0i94IqqprVC98fvlpsDNViY5h6bx9aNqjFwYws/wI4b12X7J84rk58HIcys/ns9sDuufFxsf6uwZ1b1mfuhn30aZ/A3sOZfLIwjYTa8eS6A1e8Y1+6JTWkYa3qXNSpmb8aDaBdk9rcdmoTrvjPnHw33bjYGMbd0p0OIebkahtm7q3gnm114uMY1rk5Czft56puJ3F683qMcleK806qF/xtH6Cl2+U6qVEtUvemM/7WHjStW4O2I6cwrPOJfLnEqVKrHhdDQu3q7Dl8jE4t6/PoxfkmhIgKSwrGmGJ75vIz2XMk7ybo69lVs3qsvwqmf4cm/hLDF3f2ZM4ve0P2AAvl6cvOYMiZzejZNoGTG9UiJXU/l3RpTvsmdbj27fnc0qc19WpWA/DPnDq004ncN+AUft7mTGAXamqIc9vkr4ZZ/cSggC7Ujw09jTaJ+ZPEiscGEiNO6cU3EBPg5l6t2Hkok8vOas6jE1cyNmi24fZNarN2Z97COp/cdi5rdx7yJ/0FI8+nfq1qPDikA5OWbadFg1qc1LAWew4f45GLOgQkvWiypGCMKbYrurYseCePNom1Q95ow4mLjaHfKU77QIsGtfjqrl6As4BUcEmpZvXYgG2+qeQjLTLl5V1wCuC6MD2TwjWqP+QZ/9Lv/sb5Xp94Zy8yPavWJdaJD5ju3ve4Sd0a3OhWlfmSVFnOhm5JwRhTofi/2JdwmOqJ9Wsy62/9Anpllaca1WLzJZ6CPH9FZ16bsd7fhlQWLCkYY45bvvr7yqplw1oRp06JBut9ZIypUHxdTts2KXw1U0V2d/92nBZmfq2KSMpifu7SlJycrCkpNhOGMcYUhYgsVNXkgvazkoIxxhg/SwrGGGP8LCkYY4zxq3RtCiKyG4i8QGp4CcCeAvcqexZX0VTUuKDixmZxFc3xGNfJqhp5KmEqYVIoCRFJKUxDS1mzuIqmosYFFTc2i6toqnJcVn1kjDHGz5KCMcYYv6qWFMaUdwBhWFxFU1Hjgoobm8VVNFU2rirVpmCMMSayqlZSMMYYE0GVSQoiMkhE1ojIehEZUcbnbiki00VklYisFJF73O2PishWEVni/gzxvOcBN9Y1IjIwirGlishy9/wp7raGIvKtiKxz/23gbhcRedmNa5mInBX56MWO6RTPNVkiIgdF5M/lcb1E5G0R2SUiKzzbinx9ROQ6d/91InJdlOL6p4isds89QUTqu9uTROSo57q97nnP2e7nv96NXUKdr4RxFflzK+2/1zBxfeSJKVVElrjby/J6hbs3lN/vmKoe9z9ALPAL0BqoDiwFOpbh+ZsBZ7mP6wBrgY7Ao8B9Ifbv6MYYD7RyY4+NUmypQELQtmeAEe7jEcA/3MdDgCmAAD2AeWX02e0ATi6P6wX0Ac4CVhT3+gANgQ3uvw3cxw2iENcAIM59/A9PXEne/YKOMx84x415CjA4CnEV6XOLxt9rqLiCXn8OeKQcrle4e0O5/Y5VlZJCN2C9qm5Q1WPAeGBYWZ1cVber6iL38SFgFRBp5e5hwHhVzVTVjcB6nP9DWRkGvOc+fg+4xLP9fXXMBeqLSLNQByhF/YFfVDXSgMWoXS9VnQnsC3G+olyfgcC3qrpPVfcD3wKDSjsuVZ2qqtnu07lAi0jHcGOrq6pz1LmzvO/5v5RaXBGE+9xK/e81Ulzut/0rgA8jHSNK1yvcvaHcfseqSlJoDmzxPE8j8k05akQkCegCzHM33ekWA9/2FREp23gVmCoiC0XkVndbE1XdDs4vLeBbRqo8ruNwAv9Yy/t6QdGvT3lctxtxvlH6tBKRxSLyg4j0drc1d2Mpi7iK8rmV9fXqDexU1XWebWV+vYLuDeX2O1ZVkkKoer8y73YlIrWBz4A/q+pB4N9AG6AzsB2nCAtlG29PVT0LGAzcISJ9IuxbptdRRKoDQ4FP3E0V4XpFEi6Osr5uI4FsYKy7aTtwkqp2Af4CjBORumUYV1E/t7L+PK8i8ItHmV+vEPeGsLuGiaHUYqsqSSEN8C4m2wLYVpYBiEg1nA99rKp+DqCqO1U1R1VzgTfIq/Ios3hVdZv77y5gghvDTl+1kPvvrrKOyzUYWKSqO90Yy/16uYp6fcosPreB8SLgareKA7d6Zq/7eCFOfX17Ny5vFVNU4irG51aW1ysOuAz4yBNvmV6vUPcGyvF3rKokhQVAOxFp5X77HA5MLKuTu3WWbwGrVPV5z3ZvffylgK9nxERguIjEi0groB1OA1dpx3WCiNTxPcZpqFzhnt/Xe+E64EtPXNe6PSB6AAd8RdwoCfgGV97Xy6Oo1+cbYICINHCrTga420qViAwC/g8Yqqrpnu2JIhLrPm6Nc302uLEdEpEe7u/otZ7/S2nGVdTPrSz/Xs8HVquqv1qoLK9XuHsD5fk7VpKW88r0g9NqvxYn648s43P3winKLQOWuD9DgA+A5e72iUAzz3tGurGuoYQ9HCLE1RqnZ8dSYKXvugCNgGnAOvffhu52AV5141oOJEfxmtUC9gL1PNvK/HrhJKXtQBbOt7GbinN9cOr417s/N0QprvU49cq+37HX3X0vdz/fpcAi4GLPcZJxbtK/AK/gDmgt5biK/LmV9t9rqLjc7e8CtwXtW5bXK9y9odx+x2xEszHGGL+qUn1kjDGmECwpGGOM8bOkYIwxxs+SgjHGGD9LCsYYY/wsKZgqS0QOu/8micjvS/nYDwY9n12axzcmWiwpGOPMilmkpOAb3BRBQFJQ1XOLGJMx5cKSgjEwGugtztz594pIrDhrEyxwJ3H7I4CI9BVn7vtxOAOHEJEv3MkEV/omFBSR0UBN93hj3W2+Uom4x14hzrz8V3qOPUNEPhVnTYSx7mhXY8pUXHkHYEwFMAJnvv+LANyb+wFV7Soi8cBPIjLV3bcbcLo6Uz0D3Kiq+0SkJrBARD5T1REicqeqdg5xrstwJobrBCS475npvtYFOA1nzpqfgJ7Aj6X/3zUmPCspGJPfAJz5ZZbgTGPcCGf+G4D5noQAcLeILMVZv6ClZ79wegEfqjNB3E7gB6Cr59hp6kwctwSnWsuYMmUlBWPyE+AuVQ2YUExE+gJHgp6fD5yjqukiMgOoUYhjh5PpeZyD/X2acmAlBWPgEM5SiD7fALe7UxojIu3dWWSD1QP2uwnhVJzlEX2yfO8PMhO40m23SMRZJjKaM7oaUyT2TcQYZ4bKbLca6F3gJZyqm0VuY+9uQi+7+D/gNhFZhjPL51zPa2OAZSKySFWv9myfgLPG71Kc2TH/pqo73KRiTLmzWVKNMcb4WfWRMcYYP0sKxhhj/CwpGGOM8bOkYIwxxs+SgjHGGD9LCsYYY/wsKRhjjPGzpGCMMcbv/wHRk00gzLOdfQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f31c54bdb00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss function and train / validation accuracies\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(train_loss_hist)\n",
    "plt.title('Loss history')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "\n",
    "Below you see the test accuracy. You can also see the predictions returned for images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/ticker.ckpt\n",
      "Epoch: 1/100 Iteration: 0 Test Acc: 0.8871\n",
      "Epoch: 1/100 Iteration: 5 Test Acc: 0.9194\n",
      "Epoch: 1/100 Iteration: 10 Test Acc: 0.9032\n",
      "Epoch: 1/100 Iteration: 15 Test Acc: 0.8710\n",
      "Epoch: 2/100 Iteration: 20 Test Acc: 0.8548\n",
      "Epoch: 2/100 Iteration: 25 Test Acc: 0.9355\n",
      "Epoch: 2/100 Iteration: 30 Test Acc: 0.9032\n",
      "Epoch: 2/100 Iteration: 35 Test Acc: 0.8226\n",
      "Epoch: 3/100 Iteration: 40 Test Acc: 0.8871\n",
      "Epoch: 3/100 Iteration: 45 Test Acc: 0.8871\n",
      "Epoch: 3/100 Iteration: 50 Test Acc: 0.8871\n",
      "Epoch: 3/100 Iteration: 55 Test Acc: 0.8387\n",
      "Epoch: 4/100 Iteration: 60 Test Acc: 0.8710\n",
      "Epoch: 4/100 Iteration: 65 Test Acc: 0.9355\n",
      "Epoch: 4/100 Iteration: 70 Test Acc: 0.9032\n",
      "Epoch: 4/100 Iteration: 75 Test Acc: 0.8548\n",
      "Epoch: 5/100 Iteration: 80 Test Acc: 0.8226\n",
      "Epoch: 5/100 Iteration: 85 Test Acc: 0.8871\n",
      "Epoch: 5/100 Iteration: 90 Test Acc: 0.8710\n",
      "Epoch: 5/100 Iteration: 95 Test Acc: 0.8226\n",
      "Epoch: 6/100 Iteration: 100 Test Acc: 0.9032\n",
      "Epoch: 6/100 Iteration: 105 Test Acc: 0.8710\n",
      "Epoch: 6/100 Iteration: 110 Test Acc: 0.8871\n",
      "Epoch: 6/100 Iteration: 115 Test Acc: 0.8710\n",
      "Epoch: 7/100 Iteration: 120 Test Acc: 0.8710\n",
      "Epoch: 7/100 Iteration: 125 Test Acc: 0.8710\n",
      "Epoch: 7/100 Iteration: 130 Test Acc: 0.9194\n",
      "Epoch: 7/100 Iteration: 135 Test Acc: 0.8226\n",
      "Epoch: 8/100 Iteration: 140 Test Acc: 0.8871\n",
      "Epoch: 8/100 Iteration: 145 Test Acc: 0.9355\n",
      "Epoch: 8/100 Iteration: 150 Test Acc: 0.8871\n",
      "Epoch: 8/100 Iteration: 155 Test Acc: 0.8710\n",
      "Epoch: 9/100 Iteration: 160 Test Acc: 0.8710\n",
      "Epoch: 9/100 Iteration: 165 Test Acc: 0.9032\n",
      "Epoch: 9/100 Iteration: 170 Test Acc: 0.8710\n",
      "Epoch: 9/100 Iteration: 175 Test Acc: 0.8710\n",
      "Epoch: 10/100 Iteration: 180 Test Acc: 0.8548\n",
      "Epoch: 10/100 Iteration: 185 Test Acc: 0.9516\n",
      "Epoch: 10/100 Iteration: 190 Test Acc: 0.9194\n",
      "Epoch: 10/100 Iteration: 195 Test Acc: 0.8710\n",
      "Epoch: 11/100 Iteration: 200 Test Acc: 0.8710\n",
      "Epoch: 11/100 Iteration: 205 Test Acc: 0.9355\n",
      "Epoch: 11/100 Iteration: 210 Test Acc: 0.8871\n",
      "Epoch: 11/100 Iteration: 215 Test Acc: 0.8226\n",
      "Epoch: 12/100 Iteration: 220 Test Acc: 0.8548\n",
      "Epoch: 12/100 Iteration: 225 Test Acc: 0.9194\n",
      "Epoch: 12/100 Iteration: 230 Test Acc: 0.8871\n",
      "Epoch: 12/100 Iteration: 235 Test Acc: 0.8387\n",
      "Epoch: 13/100 Iteration: 240 Test Acc: 0.8871\n",
      "Epoch: 13/100 Iteration: 245 Test Acc: 0.9032\n",
      "Epoch: 13/100 Iteration: 250 Test Acc: 0.8387\n",
      "Epoch: 13/100 Iteration: 255 Test Acc: 0.8548\n",
      "Epoch: 14/100 Iteration: 260 Test Acc: 0.8710\n",
      "Epoch: 14/100 Iteration: 265 Test Acc: 0.9194\n",
      "Epoch: 14/100 Iteration: 270 Test Acc: 0.9032\n",
      "Epoch: 14/100 Iteration: 275 Test Acc: 0.8387\n",
      "Epoch: 15/100 Iteration: 280 Test Acc: 0.8710\n",
      "Epoch: 15/100 Iteration: 285 Test Acc: 0.9194\n",
      "Epoch: 15/100 Iteration: 290 Test Acc: 0.9194\n",
      "Epoch: 15/100 Iteration: 295 Test Acc: 0.7903\n",
      "Epoch: 16/100 Iteration: 300 Test Acc: 0.8548\n",
      "Epoch: 16/100 Iteration: 305 Test Acc: 0.9032\n",
      "Epoch: 16/100 Iteration: 310 Test Acc: 0.8710\n",
      "Epoch: 16/100 Iteration: 315 Test Acc: 0.8065\n",
      "Epoch: 17/100 Iteration: 320 Test Acc: 0.9032\n",
      "Epoch: 17/100 Iteration: 325 Test Acc: 0.8871\n",
      "Epoch: 17/100 Iteration: 330 Test Acc: 0.9032\n",
      "Epoch: 17/100 Iteration: 335 Test Acc: 0.8548\n",
      "Epoch: 18/100 Iteration: 340 Test Acc: 0.8548\n",
      "Epoch: 18/100 Iteration: 345 Test Acc: 0.9032\n",
      "Epoch: 18/100 Iteration: 350 Test Acc: 0.8710\n",
      "Epoch: 18/100 Iteration: 355 Test Acc: 0.8548\n",
      "Epoch: 19/100 Iteration: 360 Test Acc: 0.8548\n",
      "Epoch: 19/100 Iteration: 365 Test Acc: 0.9194\n",
      "Epoch: 19/100 Iteration: 370 Test Acc: 0.8548\n",
      "Epoch: 19/100 Iteration: 375 Test Acc: 0.8387\n",
      "Epoch: 20/100 Iteration: 380 Test Acc: 0.8871\n",
      "Epoch: 20/100 Iteration: 385 Test Acc: 0.9032\n",
      "Epoch: 20/100 Iteration: 390 Test Acc: 0.9194\n",
      "Epoch: 20/100 Iteration: 395 Test Acc: 0.8710\n",
      "Epoch: 21/100 Iteration: 400 Test Acc: 0.8387\n",
      "Epoch: 21/100 Iteration: 405 Test Acc: 0.9194\n",
      "Epoch: 21/100 Iteration: 410 Test Acc: 0.8710\n",
      "Epoch: 21/100 Iteration: 415 Test Acc: 0.8548\n",
      "Epoch: 22/100 Iteration: 420 Test Acc: 0.8548\n",
      "Epoch: 22/100 Iteration: 425 Test Acc: 0.9194\n",
      "Epoch: 22/100 Iteration: 430 Test Acc: 0.9355\n",
      "Epoch: 22/100 Iteration: 435 Test Acc: 0.8065\n",
      "Epoch: 23/100 Iteration: 440 Test Acc: 0.8710\n",
      "Epoch: 23/100 Iteration: 445 Test Acc: 0.8710\n",
      "Epoch: 23/100 Iteration: 450 Test Acc: 0.8710\n",
      "Epoch: 23/100 Iteration: 455 Test Acc: 0.8387\n",
      "Epoch: 24/100 Iteration: 460 Test Acc: 0.8871\n",
      "Epoch: 24/100 Iteration: 465 Test Acc: 0.9355\n",
      "Epoch: 24/100 Iteration: 470 Test Acc: 0.9194\n",
      "Epoch: 24/100 Iteration: 475 Test Acc: 0.8548\n",
      "Epoch: 25/100 Iteration: 480 Test Acc: 0.8710\n",
      "Epoch: 25/100 Iteration: 485 Test Acc: 0.8871\n",
      "Epoch: 25/100 Iteration: 490 Test Acc: 0.9355\n",
      "Epoch: 25/100 Iteration: 495 Test Acc: 0.8387\n",
      "Epoch: 26/100 Iteration: 500 Test Acc: 0.8710\n",
      "Epoch: 26/100 Iteration: 505 Test Acc: 0.8871\n",
      "Epoch: 26/100 Iteration: 510 Test Acc: 0.8871\n",
      "Epoch: 26/100 Iteration: 515 Test Acc: 0.8065\n",
      "Epoch: 27/100 Iteration: 520 Test Acc: 0.8710\n",
      "Epoch: 27/100 Iteration: 525 Test Acc: 0.9032\n",
      "Epoch: 27/100 Iteration: 530 Test Acc: 0.9194\n",
      "Epoch: 27/100 Iteration: 535 Test Acc: 0.8226\n",
      "Epoch: 28/100 Iteration: 540 Test Acc: 0.8710\n",
      "Epoch: 28/100 Iteration: 545 Test Acc: 0.9032\n",
      "Epoch: 28/100 Iteration: 550 Test Acc: 0.8871\n",
      "Epoch: 28/100 Iteration: 555 Test Acc: 0.8387\n",
      "Epoch: 29/100 Iteration: 560 Test Acc: 0.8548\n",
      "Epoch: 29/100 Iteration: 565 Test Acc: 0.9032\n",
      "Epoch: 29/100 Iteration: 570 Test Acc: 0.8871\n",
      "Epoch: 29/100 Iteration: 575 Test Acc: 0.8871\n",
      "Epoch: 30/100 Iteration: 580 Test Acc: 0.8548\n",
      "Epoch: 30/100 Iteration: 585 Test Acc: 0.9194\n",
      "Epoch: 30/100 Iteration: 590 Test Acc: 0.9194\n",
      "Epoch: 30/100 Iteration: 595 Test Acc: 0.8548\n",
      "Epoch: 31/100 Iteration: 600 Test Acc: 0.8710\n",
      "Epoch: 31/100 Iteration: 605 Test Acc: 0.9194\n",
      "Epoch: 31/100 Iteration: 610 Test Acc: 0.9032\n",
      "Epoch: 31/100 Iteration: 615 Test Acc: 0.8871\n",
      "Epoch: 32/100 Iteration: 620 Test Acc: 0.8548\n",
      "Epoch: 32/100 Iteration: 625 Test Acc: 0.9516\n",
      "Epoch: 32/100 Iteration: 630 Test Acc: 0.8871\n",
      "Epoch: 32/100 Iteration: 635 Test Acc: 0.8387\n",
      "Epoch: 33/100 Iteration: 640 Test Acc: 0.8387\n",
      "Epoch: 33/100 Iteration: 645 Test Acc: 0.9032\n",
      "Epoch: 33/100 Iteration: 650 Test Acc: 0.9032\n",
      "Epoch: 33/100 Iteration: 655 Test Acc: 0.8387\n",
      "Epoch: 34/100 Iteration: 660 Test Acc: 0.8710\n",
      "Epoch: 34/100 Iteration: 665 Test Acc: 0.9516\n",
      "Epoch: 34/100 Iteration: 670 Test Acc: 0.8871\n",
      "Epoch: 34/100 Iteration: 675 Test Acc: 0.8548\n",
      "Epoch: 35/100 Iteration: 680 Test Acc: 0.8871\n",
      "Epoch: 35/100 Iteration: 685 Test Acc: 0.9516\n",
      "Epoch: 35/100 Iteration: 690 Test Acc: 0.9355\n",
      "Epoch: 35/100 Iteration: 695 Test Acc: 0.8710\n",
      "Epoch: 36/100 Iteration: 700 Test Acc: 0.8387\n",
      "Epoch: 36/100 Iteration: 705 Test Acc: 0.9194\n",
      "Epoch: 36/100 Iteration: 710 Test Acc: 0.8710\n",
      "Epoch: 36/100 Iteration: 715 Test Acc: 0.8548\n",
      "Epoch: 37/100 Iteration: 720 Test Acc: 0.8710\n",
      "Epoch: 37/100 Iteration: 725 Test Acc: 0.9194\n",
      "Epoch: 37/100 Iteration: 730 Test Acc: 0.8710\n",
      "Epoch: 37/100 Iteration: 735 Test Acc: 0.8548\n",
      "Epoch: 38/100 Iteration: 740 Test Acc: 0.8871\n",
      "Epoch: 38/100 Iteration: 745 Test Acc: 0.9032\n",
      "Epoch: 38/100 Iteration: 750 Test Acc: 0.8710\n",
      "Epoch: 38/100 Iteration: 755 Test Acc: 0.8387\n",
      "Epoch: 39/100 Iteration: 760 Test Acc: 0.8548\n",
      "Epoch: 39/100 Iteration: 765 Test Acc: 0.9032\n",
      "Epoch: 39/100 Iteration: 770 Test Acc: 0.9032\n",
      "Epoch: 39/100 Iteration: 775 Test Acc: 0.8548\n",
      "Epoch: 40/100 Iteration: 780 Test Acc: 0.8710\n",
      "Epoch: 40/100 Iteration: 785 Test Acc: 0.9194\n",
      "Epoch: 40/100 Iteration: 790 Test Acc: 0.9194\n",
      "Epoch: 40/100 Iteration: 795 Test Acc: 0.8226\n",
      "Epoch: 41/100 Iteration: 800 Test Acc: 0.8387\n",
      "Epoch: 41/100 Iteration: 805 Test Acc: 0.9194\n",
      "Epoch: 41/100 Iteration: 810 Test Acc: 0.9032\n",
      "Epoch: 41/100 Iteration: 815 Test Acc: 0.8387\n",
      "Epoch: 42/100 Iteration: 820 Test Acc: 0.8548\n",
      "Epoch: 42/100 Iteration: 825 Test Acc: 0.9032\n",
      "Epoch: 42/100 Iteration: 830 Test Acc: 0.8710\n",
      "Epoch: 42/100 Iteration: 835 Test Acc: 0.8548\n",
      "Epoch: 43/100 Iteration: 840 Test Acc: 0.8710\n",
      "Epoch: 43/100 Iteration: 845 Test Acc: 0.8710\n",
      "Epoch: 43/100 Iteration: 850 Test Acc: 0.8548\n",
      "Epoch: 43/100 Iteration: 855 Test Acc: 0.8065\n",
      "Epoch: 44/100 Iteration: 860 Test Acc: 0.8548\n",
      "Epoch: 44/100 Iteration: 865 Test Acc: 0.9032\n",
      "Epoch: 44/100 Iteration: 870 Test Acc: 0.8548\n",
      "Epoch: 44/100 Iteration: 875 Test Acc: 0.8226\n",
      "Epoch: 45/100 Iteration: 880 Test Acc: 0.8871\n",
      "Epoch: 45/100 Iteration: 885 Test Acc: 0.8871\n",
      "Epoch: 45/100 Iteration: 890 Test Acc: 0.9032\n",
      "Epoch: 45/100 Iteration: 895 Test Acc: 0.8226\n",
      "Epoch: 46/100 Iteration: 900 Test Acc: 0.8710\n",
      "Epoch: 46/100 Iteration: 905 Test Acc: 0.8871\n",
      "Epoch: 46/100 Iteration: 910 Test Acc: 0.8871\n",
      "Epoch: 46/100 Iteration: 915 Test Acc: 0.8710\n",
      "Epoch: 47/100 Iteration: 920 Test Acc: 0.8548\n",
      "Epoch: 47/100 Iteration: 925 Test Acc: 0.8871\n",
      "Epoch: 47/100 Iteration: 930 Test Acc: 0.9032\n",
      "Epoch: 47/100 Iteration: 935 Test Acc: 0.8548\n",
      "Epoch: 48/100 Iteration: 940 Test Acc: 0.9032\n",
      "Epoch: 48/100 Iteration: 945 Test Acc: 0.9355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48/100 Iteration: 950 Test Acc: 0.9032\n",
      "Epoch: 48/100 Iteration: 955 Test Acc: 0.7903\n",
      "Epoch: 49/100 Iteration: 960 Test Acc: 0.8387\n",
      "Epoch: 49/100 Iteration: 965 Test Acc: 0.9355\n",
      "Epoch: 49/100 Iteration: 970 Test Acc: 0.9032\n",
      "Epoch: 49/100 Iteration: 975 Test Acc: 0.8548\n",
      "Epoch: 50/100 Iteration: 980 Test Acc: 0.8871\n",
      "Epoch: 50/100 Iteration: 985 Test Acc: 0.9194\n",
      "Epoch: 50/100 Iteration: 990 Test Acc: 0.9194\n",
      "Epoch: 50/100 Iteration: 995 Test Acc: 0.8548\n",
      "Epoch: 51/100 Iteration: 1000 Test Acc: 0.8548\n",
      "Epoch: 51/100 Iteration: 1005 Test Acc: 0.8871\n",
      "Epoch: 51/100 Iteration: 1010 Test Acc: 0.9032\n",
      "Epoch: 51/100 Iteration: 1015 Test Acc: 0.8710\n",
      "Epoch: 52/100 Iteration: 1020 Test Acc: 0.8871\n",
      "Epoch: 52/100 Iteration: 1025 Test Acc: 0.8871\n",
      "Epoch: 52/100 Iteration: 1030 Test Acc: 0.8871\n",
      "Epoch: 52/100 Iteration: 1035 Test Acc: 0.8548\n",
      "Epoch: 53/100 Iteration: 1040 Test Acc: 0.8387\n",
      "Epoch: 53/100 Iteration: 1045 Test Acc: 0.9032\n",
      "Epoch: 53/100 Iteration: 1050 Test Acc: 0.9355\n",
      "Epoch: 53/100 Iteration: 1055 Test Acc: 0.8710\n",
      "Epoch: 54/100 Iteration: 1060 Test Acc: 0.8710\n",
      "Epoch: 54/100 Iteration: 1065 Test Acc: 0.9194\n",
      "Epoch: 54/100 Iteration: 1070 Test Acc: 0.8710\n",
      "Epoch: 54/100 Iteration: 1075 Test Acc: 0.8387\n",
      "Epoch: 55/100 Iteration: 1080 Test Acc: 0.8871\n",
      "Epoch: 55/100 Iteration: 1085 Test Acc: 0.8871\n",
      "Epoch: 55/100 Iteration: 1090 Test Acc: 0.8871\n",
      "Epoch: 55/100 Iteration: 1095 Test Acc: 0.8548\n",
      "Epoch: 56/100 Iteration: 1100 Test Acc: 0.8710\n",
      "Epoch: 56/100 Iteration: 1105 Test Acc: 0.9032\n",
      "Epoch: 56/100 Iteration: 1110 Test Acc: 0.8871\n",
      "Epoch: 56/100 Iteration: 1115 Test Acc: 0.8387\n",
      "Epoch: 57/100 Iteration: 1120 Test Acc: 0.8710\n",
      "Epoch: 57/100 Iteration: 1125 Test Acc: 0.9355\n",
      "Epoch: 57/100 Iteration: 1130 Test Acc: 0.9032\n",
      "Epoch: 57/100 Iteration: 1135 Test Acc: 0.8387\n",
      "Epoch: 58/100 Iteration: 1140 Test Acc: 0.8548\n",
      "Epoch: 58/100 Iteration: 1145 Test Acc: 0.9194\n",
      "Epoch: 58/100 Iteration: 1150 Test Acc: 0.9194\n",
      "Epoch: 58/100 Iteration: 1155 Test Acc: 0.8548\n",
      "Epoch: 59/100 Iteration: 1160 Test Acc: 0.8710\n",
      "Epoch: 59/100 Iteration: 1165 Test Acc: 0.9355\n",
      "Epoch: 59/100 Iteration: 1170 Test Acc: 0.9032\n",
      "Epoch: 59/100 Iteration: 1175 Test Acc: 0.8548\n",
      "Epoch: 60/100 Iteration: 1180 Test Acc: 0.8710\n",
      "Epoch: 60/100 Iteration: 1185 Test Acc: 0.9032\n",
      "Epoch: 60/100 Iteration: 1190 Test Acc: 0.8871\n",
      "Epoch: 60/100 Iteration: 1195 Test Acc: 0.8548\n",
      "Epoch: 61/100 Iteration: 1200 Test Acc: 0.8871\n",
      "Epoch: 61/100 Iteration: 1205 Test Acc: 0.9194\n",
      "Epoch: 61/100 Iteration: 1210 Test Acc: 0.8871\n",
      "Epoch: 61/100 Iteration: 1215 Test Acc: 0.8710\n",
      "Epoch: 62/100 Iteration: 1220 Test Acc: 0.9032\n",
      "Epoch: 62/100 Iteration: 1225 Test Acc: 0.8871\n",
      "Epoch: 62/100 Iteration: 1230 Test Acc: 0.8548\n",
      "Epoch: 62/100 Iteration: 1235 Test Acc: 0.8548\n",
      "Epoch: 63/100 Iteration: 1240 Test Acc: 0.8710\n",
      "Epoch: 63/100 Iteration: 1245 Test Acc: 0.9032\n",
      "Epoch: 63/100 Iteration: 1250 Test Acc: 0.8871\n",
      "Epoch: 63/100 Iteration: 1255 Test Acc: 0.8710\n",
      "Epoch: 64/100 Iteration: 1260 Test Acc: 0.8387\n",
      "Epoch: 64/100 Iteration: 1265 Test Acc: 0.9032\n",
      "Epoch: 64/100 Iteration: 1270 Test Acc: 0.9355\n",
      "Epoch: 64/100 Iteration: 1275 Test Acc: 0.8387\n",
      "Epoch: 65/100 Iteration: 1280 Test Acc: 0.8548\n",
      "Epoch: 65/100 Iteration: 1285 Test Acc: 0.9194\n",
      "Epoch: 65/100 Iteration: 1290 Test Acc: 0.9194\n",
      "Epoch: 65/100 Iteration: 1295 Test Acc: 0.8710\n",
      "Epoch: 66/100 Iteration: 1300 Test Acc: 0.8710\n",
      "Epoch: 66/100 Iteration: 1305 Test Acc: 0.9194\n",
      "Epoch: 66/100 Iteration: 1310 Test Acc: 0.9032\n",
      "Epoch: 66/100 Iteration: 1315 Test Acc: 0.8871\n",
      "Epoch: 67/100 Iteration: 1320 Test Acc: 0.8548\n",
      "Epoch: 67/100 Iteration: 1325 Test Acc: 0.9194\n",
      "Epoch: 67/100 Iteration: 1330 Test Acc: 0.8871\n",
      "Epoch: 67/100 Iteration: 1335 Test Acc: 0.8548\n",
      "Epoch: 68/100 Iteration: 1340 Test Acc: 0.8871\n",
      "Epoch: 68/100 Iteration: 1345 Test Acc: 0.9032\n",
      "Epoch: 68/100 Iteration: 1350 Test Acc: 0.9032\n",
      "Epoch: 68/100 Iteration: 1355 Test Acc: 0.8548\n",
      "Epoch: 69/100 Iteration: 1360 Test Acc: 0.8548\n",
      "Epoch: 69/100 Iteration: 1365 Test Acc: 0.9194\n",
      "Epoch: 69/100 Iteration: 1370 Test Acc: 0.9032\n",
      "Epoch: 69/100 Iteration: 1375 Test Acc: 0.8548\n",
      "Epoch: 70/100 Iteration: 1380 Test Acc: 0.9194\n",
      "Epoch: 70/100 Iteration: 1385 Test Acc: 0.9194\n",
      "Epoch: 70/100 Iteration: 1390 Test Acc: 0.8710\n",
      "Epoch: 70/100 Iteration: 1395 Test Acc: 0.8387\n",
      "Epoch: 71/100 Iteration: 1400 Test Acc: 0.8710\n",
      "Epoch: 71/100 Iteration: 1405 Test Acc: 0.9032\n",
      "Epoch: 71/100 Iteration: 1410 Test Acc: 0.9194\n",
      "Epoch: 71/100 Iteration: 1415 Test Acc: 0.8226\n",
      "Epoch: 72/100 Iteration: 1420 Test Acc: 0.8871\n",
      "Epoch: 72/100 Iteration: 1425 Test Acc: 0.9355\n",
      "Epoch: 72/100 Iteration: 1430 Test Acc: 0.9032\n",
      "Epoch: 72/100 Iteration: 1435 Test Acc: 0.8548\n",
      "Epoch: 73/100 Iteration: 1440 Test Acc: 0.8710\n",
      "Epoch: 73/100 Iteration: 1445 Test Acc: 0.9032\n",
      "Epoch: 73/100 Iteration: 1450 Test Acc: 0.8871\n",
      "Epoch: 73/100 Iteration: 1455 Test Acc: 0.8548\n",
      "Epoch: 74/100 Iteration: 1460 Test Acc: 0.8548\n",
      "Epoch: 74/100 Iteration: 1465 Test Acc: 0.9194\n",
      "Epoch: 74/100 Iteration: 1470 Test Acc: 0.8871\n",
      "Epoch: 74/100 Iteration: 1475 Test Acc: 0.8548\n",
      "Epoch: 75/100 Iteration: 1480 Test Acc: 0.8871\n",
      "Epoch: 75/100 Iteration: 1485 Test Acc: 0.9194\n",
      "Epoch: 75/100 Iteration: 1490 Test Acc: 0.9194\n",
      "Epoch: 75/100 Iteration: 1495 Test Acc: 0.8710\n",
      "Epoch: 76/100 Iteration: 1500 Test Acc: 0.8710\n",
      "Epoch: 76/100 Iteration: 1505 Test Acc: 0.9032\n",
      "Epoch: 76/100 Iteration: 1510 Test Acc: 0.9194\n",
      "Epoch: 76/100 Iteration: 1515 Test Acc: 0.8710\n",
      "Epoch: 77/100 Iteration: 1520 Test Acc: 0.8871\n",
      "Epoch: 77/100 Iteration: 1525 Test Acc: 0.9355\n",
      "Epoch: 77/100 Iteration: 1530 Test Acc: 0.8548\n",
      "Epoch: 77/100 Iteration: 1535 Test Acc: 0.8387\n",
      "Epoch: 78/100 Iteration: 1540 Test Acc: 0.8710\n",
      "Epoch: 78/100 Iteration: 1545 Test Acc: 0.9032\n",
      "Epoch: 78/100 Iteration: 1550 Test Acc: 0.8871\n",
      "Epoch: 78/100 Iteration: 1555 Test Acc: 0.8548\n",
      "Epoch: 79/100 Iteration: 1560 Test Acc: 0.8710\n",
      "Epoch: 79/100 Iteration: 1565 Test Acc: 0.9355\n",
      "Epoch: 79/100 Iteration: 1570 Test Acc: 0.8710\n",
      "Epoch: 79/100 Iteration: 1575 Test Acc: 0.8387\n",
      "Epoch: 80/100 Iteration: 1580 Test Acc: 0.9032\n",
      "Epoch: 80/100 Iteration: 1585 Test Acc: 0.9194\n",
      "Epoch: 80/100 Iteration: 1590 Test Acc: 0.8871\n",
      "Epoch: 80/100 Iteration: 1595 Test Acc: 0.8710\n",
      "Epoch: 81/100 Iteration: 1600 Test Acc: 0.8548\n",
      "Epoch: 81/100 Iteration: 1605 Test Acc: 0.9032\n",
      "Epoch: 81/100 Iteration: 1610 Test Acc: 0.9194\n",
      "Epoch: 81/100 Iteration: 1615 Test Acc: 0.8226\n",
      "Epoch: 82/100 Iteration: 1620 Test Acc: 0.8710\n",
      "Epoch: 82/100 Iteration: 1625 Test Acc: 0.9032\n",
      "Epoch: 82/100 Iteration: 1630 Test Acc: 0.8548\n",
      "Epoch: 82/100 Iteration: 1635 Test Acc: 0.8387\n",
      "Epoch: 83/100 Iteration: 1640 Test Acc: 0.8871\n",
      "Epoch: 83/100 Iteration: 1645 Test Acc: 0.9032\n",
      "Epoch: 83/100 Iteration: 1650 Test Acc: 0.8871\n",
      "Epoch: 83/100 Iteration: 1655 Test Acc: 0.8548\n",
      "Epoch: 84/100 Iteration: 1660 Test Acc: 0.8871\n",
      "Epoch: 84/100 Iteration: 1665 Test Acc: 0.9194\n",
      "Epoch: 84/100 Iteration: 1670 Test Acc: 0.9032\n",
      "Epoch: 84/100 Iteration: 1675 Test Acc: 0.8548\n",
      "Epoch: 85/100 Iteration: 1680 Test Acc: 0.8710\n",
      "Epoch: 85/100 Iteration: 1685 Test Acc: 0.8710\n",
      "Epoch: 85/100 Iteration: 1690 Test Acc: 0.8710\n",
      "Epoch: 85/100 Iteration: 1695 Test Acc: 0.8548\n",
      "Epoch: 86/100 Iteration: 1700 Test Acc: 0.8548\n",
      "Epoch: 86/100 Iteration: 1705 Test Acc: 0.9194\n",
      "Epoch: 86/100 Iteration: 1710 Test Acc: 0.8710\n",
      "Epoch: 86/100 Iteration: 1715 Test Acc: 0.8548\n",
      "Epoch: 87/100 Iteration: 1720 Test Acc: 0.8871\n",
      "Epoch: 87/100 Iteration: 1725 Test Acc: 0.9355\n",
      "Epoch: 87/100 Iteration: 1730 Test Acc: 0.9032\n",
      "Epoch: 87/100 Iteration: 1735 Test Acc: 0.8548\n",
      "Epoch: 88/100 Iteration: 1740 Test Acc: 0.8871\n",
      "Epoch: 88/100 Iteration: 1745 Test Acc: 0.8871\n",
      "Epoch: 88/100 Iteration: 1750 Test Acc: 0.8710\n",
      "Epoch: 88/100 Iteration: 1755 Test Acc: 0.8548\n",
      "Epoch: 89/100 Iteration: 1760 Test Acc: 0.8710\n",
      "Epoch: 89/100 Iteration: 1765 Test Acc: 0.9032\n",
      "Epoch: 89/100 Iteration: 1770 Test Acc: 0.9355\n",
      "Epoch: 89/100 Iteration: 1775 Test Acc: 0.8387\n",
      "Epoch: 90/100 Iteration: 1780 Test Acc: 0.8710\n",
      "Epoch: 90/100 Iteration: 1785 Test Acc: 0.9032\n",
      "Epoch: 90/100 Iteration: 1790 Test Acc: 0.9194\n",
      "Epoch: 90/100 Iteration: 1795 Test Acc: 0.8226\n",
      "Epoch: 91/100 Iteration: 1800 Test Acc: 0.8871\n",
      "Epoch: 91/100 Iteration: 1805 Test Acc: 0.9194\n",
      "Epoch: 91/100 Iteration: 1810 Test Acc: 0.9355\n",
      "Epoch: 91/100 Iteration: 1815 Test Acc: 0.8710\n",
      "Epoch: 92/100 Iteration: 1820 Test Acc: 0.9032\n",
      "Epoch: 92/100 Iteration: 1825 Test Acc: 0.9355\n",
      "Epoch: 92/100 Iteration: 1830 Test Acc: 0.8710\n",
      "Epoch: 92/100 Iteration: 1835 Test Acc: 0.8548\n",
      "Epoch: 93/100 Iteration: 1840 Test Acc: 0.9032\n",
      "Epoch: 93/100 Iteration: 1845 Test Acc: 0.9194\n",
      "Epoch: 93/100 Iteration: 1850 Test Acc: 0.8871\n",
      "Epoch: 93/100 Iteration: 1855 Test Acc: 0.8387\n",
      "Epoch: 94/100 Iteration: 1860 Test Acc: 0.8871\n",
      "Epoch: 94/100 Iteration: 1865 Test Acc: 0.8871\n",
      "Epoch: 94/100 Iteration: 1870 Test Acc: 0.8871\n",
      "Epoch: 94/100 Iteration: 1875 Test Acc: 0.8226\n",
      "Epoch: 95/100 Iteration: 1880 Test Acc: 0.8710\n",
      "Epoch: 95/100 Iteration: 1885 Test Acc: 0.9194\n",
      "Epoch: 95/100 Iteration: 1890 Test Acc: 0.9032\n",
      "Epoch: 95/100 Iteration: 1895 Test Acc: 0.8387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 96/100 Iteration: 1900 Test Acc: 0.8387\n",
      "Epoch: 96/100 Iteration: 1905 Test Acc: 0.9194\n",
      "Epoch: 96/100 Iteration: 1910 Test Acc: 0.8871\n",
      "Epoch: 96/100 Iteration: 1915 Test Acc: 0.8710\n",
      "Epoch: 97/100 Iteration: 1920 Test Acc: 0.8710\n",
      "Epoch: 97/100 Iteration: 1925 Test Acc: 0.9194\n",
      "Epoch: 97/100 Iteration: 1930 Test Acc: 0.8710\n",
      "Epoch: 97/100 Iteration: 1935 Test Acc: 0.8710\n",
      "Epoch: 98/100 Iteration: 1940 Test Acc: 0.8387\n",
      "Epoch: 98/100 Iteration: 1945 Test Acc: 0.9032\n",
      "Epoch: 98/100 Iteration: 1950 Test Acc: 0.8548\n",
      "Epoch: 98/100 Iteration: 1955 Test Acc: 0.8548\n",
      "Epoch: 99/100 Iteration: 1960 Test Acc: 0.8710\n",
      "Epoch: 99/100 Iteration: 1965 Test Acc: 0.9032\n",
      "Epoch: 99/100 Iteration: 1970 Test Acc: 0.9355\n",
      "Epoch: 99/100 Iteration: 1975 Test Acc: 0.8226\n",
      "Epoch: 100/100 Iteration: 1980 Test Acc: 0.8548\n",
      "Epoch: 100/100 Iteration: 1985 Test Acc: 0.9032\n",
      "Epoch: 100/100 Iteration: 1990 Test Acc: 0.9032\n",
      "Epoch: 100/100 Iteration: 1995 Test Acc: 0.8710\n",
      "test finished\n"
     ]
    }
   ],
   "source": [
    "iteration = 0\n",
    "test_acc_history = []\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    \n",
    "    for e in range(epochs):  \n",
    "        #print(e)\n",
    "        for x, y in get_batches(test_x, test_y, n_batches):\n",
    "            if iteration % 5 == 0:\n",
    "                feed = {image: x,\n",
    "                        label: y,\n",
    "                        dropout: 1.0}\n",
    "                test_acc = sess.run(accuracy, feed_dict=feed)\n",
    "                test_acc_history.append(test_acc)\n",
    "                #print(\"Test accuracy: {:.4f}\".format(test_acc))\n",
    "                print(\"Epoch: {}/{}\".format(e+1, epochs),\n",
    "                      \"Iteration: {}\".format(iteration),\n",
    "                      #\"Training loss: {:.5f}\".format(val_loss),\n",
    "                      \"Test Acc: {:.4f}\".format(test_acc))\n",
    "            iteration += 1\n",
    "           \n",
    "#print(test_acc_history)\n",
    "print(\"test finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f31bd739630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(test_acc_history, label='test')\n",
    "plt.plot(val_acc_hist, label='val')\n",
    "plt.title('Classification accuracy history')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Clasification accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1]\tBao. W, Yue. J, Rao. Y PLoS ONE 12(7): e0180944. https://doi.org/10.1371/journal.pone.0180944. \n",
    "\n",
    "[2]\tHuang. W, Nakamori. Y, Wang. SY Computers & Operations Research. 2005; 32(10):2513–22. \n",
    "\n",
    "[3]\tMoghaddam. A, Moghaddam. M, Esfandyarica. M, Journal of Economics, Finance and Administrative Science (2016). https://doi.org/10.1016/j.jefas.2016.07.002. \n",
    "\n",
    "[4] Philip Xu's Blog; 2017; https://github.com/philipxjm/Convolutional-Neural-Stock-Market-Technical-Analyser"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
